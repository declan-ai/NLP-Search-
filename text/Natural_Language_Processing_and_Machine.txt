(IJCSIS) International Journal of Computer Science and Information Security,

Vol. 13, No. 9, September 2015

Natural Language Processing and Machine Learning:
A Review

Fateme Behzadi

Computer Engineering Department, Bahmanyar Institute of Higher Education
Kerman, [IRAN

Abstract—Natural language processing emerges as one of the
hottest topic in field of Speech and language technology. Also
Machine learning can comprehend how to perform important
NLP tasks. This is often achievable and cost-effective where
manual programming is not. This paper strives to Study NLP
and ML and gives insights into the essential characteristics of
both. It summarizes common NLP tasks in this comprehensive
field, then provides a brief description of common machine
learning approaches that are being used for different NLP tasks.
Also this paper presents a review on various approaches to NLP
and some related topics to NLP and ML.

Keywords-Natural Language Processing, Machine learning,
NEP, ML.

L INTRODUCTION

A. Natural Language Processing

Natural Language Processing is a hypothetically driven
range of calculative techniques for analyzing and representing
naturally texts at one or more levels of linguistic analysis in
order to achieve human-like language processing for a range of
tasks or applications [1].

The term Natural Language Processing surrounds a wide
set of techniques for automated generation, manipulation and
analysis of natural or human languages. NLP techniques are
affected by Linguistics and Artificial Intelligence, Machine
Learning, Computational Statistics and Cognitive Science.
Here is introduction of some basic terminology in NLP that
will be avail [2]:

e Token: Linguistic units of an input text, such as words,

punctuation, numbers or alphanumerics.
Sentence: An ordered sequence of tokens.

Tokenization: The process of separating a sentence into
its component tokens.

Corpus: A body of text, ordinarily containing a large
number of sentences.

Part-of-speech (POS) Tag: A symbol stands for a
lexical category, like NN(Noun), VB(Verb),
JJ(Adjective), AT(Article).

Parse Tree: Describes the syntactic structure of the
sentence as defined by a formal grammar.

101

Now let's consider some common NLP tasks:

POS Tagging: Assigning POS tags to each word in the
sentence.

Computational Morphology: Discovery and analysis of
the internal structure of words using computers.

Parsing: Constructing the parse tree given a sentence.

Machine Translation (MT): Translating the given text
in one natural language to fluent text in another
language with a computer, without any human in the
loop.

For more information, an overview of NLP tasks is
provided below [3]:

e Low-level NLP tasks: Sentence boundary detection,
Tokenization, POS tagging, Morphological
decomposition of compound words, Shallow parsing

(chunking), Problem-specific segmentation.

High-level NLP tasks: Spelling/grammatical error
identification and Recovery, Named entity recognition
(NER), Word sense disambiguation (WSD), Negation
and uncertainty identification, Relationship extraction,
Temporal inferences/relationship extraction,
Information extraction (IE).

A brief description about NLP, is shown in tables I and II.
Table I illustrates some of NLP characteristics [1]. Table II
presents levels of NLP [4].

 

 

 

 

 

TABLET. SOME OF NLP CHARACTERISTICS
Origins Computer Science; Linguistic; Cognitive Psychology.
Divisions Language Processing; Language Generation.
Approaches to | Symbolic Approach; Statistical Approach; Connectionist
NLP Approach.
NLP Information Retrieval (IR); Information Extraction (IE);
Applications Question-Answering; Summarization; Machine
Translation (MT); Dialogue Systems.

 

 

Google scholar

https://sites.google.com/site/ijcsis/
ISSN 1947-5500

 
(IJCSIS) International Journal of Computer Science and Information Security,

 

 

 

 

 

 

 

 

TABLE II. LEVELS OF NLP
Levels Of NLP Definition

Phonetics And Knowledge About Linguistic Sounds.

Phonology

Morphology Knowledge Of The Meaningful Components Of
Words.

Syntactic Knowledge Of The Structural Relationships
Between Words.

Semantic Knowledge Of Meaning.

Pragmatics Knowledge Of The Relationship Of Meaning To The
Intentions Of The Speaker.

Discourse Knowledge About Linguistic Units Larger Than A
Single Utterance.

 

 

 

B. Progression of NLP Research

There are three different areas for progression of NLP
research which will finally lead NLP research to grow into
natural language understanding. The areas are the following

[5]:

e = Syntax-centered NLP: Manage tasks such as
information retrieval and extraction, auto-
categorization, topic modeling, etc. Categories of this

area are keyword spotting, lexical affinity, statistical

methods.
e = Semantics-based NLP: Focuses on the inherent
meaning associated with natural language text.

Categories of this area are techniques that leverage on
external knowledge or semantic knowledge bases,
methods that exploit only intrinsic semantics of
documents.

Pragmatics-based NLP: Attempt to understand
narratives by leveraging on discourse structure,
argument-support hierarchies, plan graphs, and
common-sense reasoning.

C. Machine Learning

With advances in computer technology, we presently have
the ability to store and process enormous amounts of data, and
likewise to access it from physically far locations over a
computer network. Most data acquisition devices are digital
now and record dependable data. There is a process that
explains the data that is observed.

Though the details of the process underlying the generation
of data are unknown, it may not be feasible to identify the
process entirely, but it can construct a good and helpful
approximation. Though identifying the complete process may
not be possible, it can still be suitable to detect specific patterns

102

Vol. 13, No. 9, September 2015
or regularities. This is the role of machine learning. Such
patterns can help to comprehend the process, or use those
patterns to make predictions.

Application of machine learning methods to large databases
is called data mining. In data mining, a large volume of data is
processed to construct a simple model with valuable use. But
machine learning is not just a database problem; it is also a part
of artificial intelligence. To be intelligent, a system that is in a
changing environment should have the ability to learn. If the
system can learn and adapt to these changes, the system
designer needs no predict and provides solutions for all proper
situations. Machine learning also helps to find solutions for
many problems in vision, speech recognition, and robotics.

Machine learning is programming computers to optimize a
performance criterion using example data or past experience.
There is a model defined up to some parameters, and learning
is the execution of a computer program to optimize the
parameters of the model using the training data or past
experience. The model may be predictive to make predictions
in the future, or descriptive to obtain knowledge from data, or
both.

Machine learning uses the theory of statistics in building
mathematical models, because the core task is making
inference from a sample. The role of computer science is
divided into two parts: First, in training, it is required the
effective algorithms to solve the optimization problem, and
also to store and process the enormous amount of data. Second,
once a model is learned, its representation and algorithmic
solution for inference needs to be efficient too. In particular
applications, the effectiveness of the learning or inference
algorithm, namely, its space and time complexity, perhaps are
as significant as its predictive accuracy [6].

II. MACHINE LEARNING IN NATURAL LANGUAGE

PROCESSING

Natural Language Processing (NLP) deals with real text
element processing. The text element is transformed into
machine format by NLP.

A system capable of obtaining and combining the
knowledge automatically is referred as machine learning [7].
Machine learning systems automatically learn programs from
data [8]. Here are shown some machine learning methods [9]:

e = Classifiers: Document classification, Disambiguation.

e Structured models: Tagging, Parsing, Extraction.

e = Unsupervised Generalization, Structure

induction.

learning:

The application of machine learning to natural language
processing is constantly increasing. Spam filtering is one where
spam generators on one side and filters on the other side keep
finding more and more talented ways to surpass each other.
Perhaps the most striking would be machine translation. After
decades of research on hand-coded translation rules, it has
become apparent lately that the most favorable way is to
provide a very large number of example pairs of translated

https://sites.google.com/site/ijcsis/
ISSN 1947-5500
(IJCSIS) International Journal of Computer Science and Information Security,

texts and have a program understand automatically the rules to
map one string of characters to another[6].

A. Machine Learning Models

Machine-learning models can be widely classified as either
generative or discriminative [3]. These models are briefed here:

® Generative methods: Create rich models of probability
distributions; like Naive Bayes classifiers and hidden

Markov models (HMMs).

Discriminative methods: Directly _ estimating
succeeding probabilities based on observations; like
Logistic regression and conditional random fields
(CRFs), Support vector machines (SVMs).

B. Some Statistical Machine Learning Approaches

There are a wide variety of learning forms in the machine
learning literature. However, the learning approaches other
than the HMMs have not been used so widely for the POS
tagging problem. However, all well-known learning forms have
been applied to POS tagging in some degree. The list of these
approaches is here. The interested reader can refer to them in
the companion wiki for further details.

Support vector machines (SVM)

Neural networks (NN)

Decision trees (DT)

Finite state machines

Genetic algorithms

Fuzzy set theory

Machine translation (MT)ideas

Others: Logical programming, dynamic Bayesian
networks and cyclic dependency networks, memory-based
learning, relaxation labeling, robust risk minimization,
conditional random fields, Markov random fields, and latent
semantic mapping [10].

I. CLASSICAL APPROACHES TO NATURAL LANGUAGE

PROCESSING

Text Preprocessing: text preprocessing is the task of
converting a raw text file, basically a sequence of digital bits,
into a well-defined sequence of linguistically definable units.
Text preprocessing is a main part of any NLP system, since the
characters, words, and sentences identified at this stage are the
fundamental units passed to all more processing stages, from
analysis and tagging components, such as morphological
analyzers and part-of-speech taggers, through applications,
such as information retrieval and machine translation systems.

Text preprocessing can be divided into two stages:
document triage and text segmentation. Document triage is the
process of transforming a set of digital files into well-defined
text documents. Text segmentation is the process of converting
a well-defined text corpus into its component words and
sentences.

Lexical Analysis: Words are the building blocks of natural
language texts. The techniques and mechanisms for performing
text analysis at the level of the word, is lexical analysis. A basic

103

. a Vol. 13, No. 9, September 2015
task of lexical analysis is to relate morphological variants to

their lemma that lies in a lemma dictionary bundled up with its
invariant semantic and syntactic information. The mapping of
string to lemma, as the only one side of lexical analysis, is the
parsing side. The other side is mapping from the lemma to a
string, morphological generation.

Syntactic Parsing: This approach presents basic techniques
for grammar-driven natural language parsing, that is, analyzing
a string of words (typically a sentence) to determine its
structural description as a formal grammar. In most conditions,
this is not an aim in itself but rather an intermediary step for the
goal of additional processing, such as the assignment of a
meaning to the sentence. Finally, the requested output of
grammar-driven parsing is typically a hierarchical, syntactic
structure appropriate for semantic interpretation. The string of
words comprising the input will usually have been processed in
separate phases of tokenization and lexical analysis, which is
therefore not part of parsing proper.

Semantic Analysis: In general linguistics, semantic analysis
refers to analyzing the meanings of words, fixed expressions,
whole sentences, and utterances in context. In practice, this
means translating original expressions into some kind of
semantic meta-language. There is a traditional division made
between lexical semantics, which involves itself with the
meanings of words and fixed word combinations, and supra-
lexical (combinational, or compositional) semantics, which
involves itself with the meanings of the unclearly large number
of word combinations-phrases and sentences-allowable under
the grammar.

Natural Language Generation: Natural language
generation (NLG) is the process by which thought is rendered
into language. It has been studied by philosophers,
neurologists, psycholinguists, child psychologists, and
linguists. The people who look at it from a computational
perspective study the generation in the fields of artificial
intelligence and computational linguistics. From this viewpoint,
the generator -the equivalent of a person with something to say-
is a computer program.

Its work begins with the initial intention to communicate,
and then on to determining the content of what will be said,
selecting the wording and rhetorical organization and fitting it
to a grammar, by way of formatting the words of a written text
or establishing the prosody of speech. The process of
generation is usually divided into three parts, often executed as
three distinct programs:

1) Identifying the goals of the expression.

2) Planning how the goals may be achieved by evaluating
the situation and available communicative resources.

3) Realizing the plans as a text [10].

TV. SOME EMPIRICAL AND STATISTICAL APPROACHES TO

NATURAL LANGUAGE PROCESSING

Corpus Creation: A corpus can be defined as a collection
of machine-readable reliable texts (including official copies of
spoken data) that is sampled to be representative of a certain
natural language or language variety. Corpora provide a
material basis and a test bed for building NLP systems. On the

https://sites.google.com/site/ijcsis/
ISSN 1947-5500
(IJCSIS) International Journal of Computer Science and Information Security,

other hand, NLP research has contributed considerably to
corpus development, especially in corpus annotation, for
example, part-of-speech tagging, syntactic parsing. Some
issues in corpus creation are such as corpus size,
representativeness, balance and sampling, data capture and
copyright, markup and annotation, multilingual and multimodal
corpora.

Treebank Annotation: The main use of tree-bank is in the
area of NLP, most often and significantly statistical parsing.
Tree-banks are used as the training data for supervised machine
learning (which might contain the automatic extraction of
grammars) and as test data for evaluating them. Corpus
annotation is not a self-contained task: it serves, among other
things, as:

1) A testing and training data resource for NLP.

2) Aninestimable test for linguistic theories on which the
annotation schemes are based.

3) Aresource of linguistic information for the build-up of
grammars and lexicons.

Part-of-Speech Tagging: One of the earliest steps within
this sequence is part-of-speech (POS) tagging. It is usually a
sentence based approach and given a sentence formed of a
sequence of words, POS tagging tries to label (tag) each word
with its correct part of speech (also named word category, word
class, or lexical category).

This process can be considered as a simplified form (or a
sub process) of morphological analysis. | Whereas
morphological analysis involves finding the internal structure
of a word (root form, affixes, etc.), POS tagging only deals
with assigning a POS tag to the given surface form word.

Nevertheless, Part-of-Speech problems are ambiguous
words and unknown words. POS tagging approaches are rule-
based approaches, Markov model approaches, and maximum
entropy approaches.

Statistical Parsing: Statistical parsing means techniques for
syntactic analysis that are based on statistical inference from
samples of natural language. Statistical inference perhaps
invoked for different aspects of the parsing process but is
mainly used as a technique for disambiguation, that is, for
selecting the most proper analysis of a sentence from a larger
set of possible analyses.

The task of a statistical parser is to map sentences in natural
language to their preferred syntactic representations, either by
providing a ranked list of candidate analyses or by selecting a
single optimal analysis.

Multiword Expressions: Languages are made up of words,
which combine via morpho-syntax to encode meaning in the
form of phrases and sentences. While it may appear relatively
harmless, the question of what constitutes a "word" is an
unexpectedly vexed one. To be able to regain the semantics of
these expressions, they must have lexical status of some form
in the mental lexicon, which encodes their specific semantics.
Expressions such as these that have surprising properties not
predicted by their unit words are referred to as multiword

104

. Vol. 13, No. 9, September 2015
expressions (MWEs). Types of MWEs are Nominal MWEs,

Verbal MWEs, and Prepositional MWEs [10].

Vv.

A classifier is a system that inputs a vector of discrete
and/or continuous feature values and outputs a single discrete
value, the class. The three components of learning algorithms
are [8]:

COMPONENTS OF LEARNING ALGORITHMS

e Representation: A classifier should be represented in

some formal language that the computer can handle.

Evaluation: An evaluation function (also called
objective function or scoring function) is needed to
differentiate good classifiers from bad ones.

Optimization: A method is needed to search among the
classifiers in the language for the highest-scoring one.

A. Machine Learning Algorithms for Sentiment
Classification

Sentiment classification or Polarity classification is the
binary classification task of labeling an opinionated document
as declaring either a totally positive or a totally negative
opinion and a technique for analyzing subjective information in
a large number of texts. A standard approach for sentiment
classification is to use machine learning algorithms.

One of the machine learning algorithms is taxonomy based
depending on result of the algorithm or type of input available.
Description of these algorithms is summarized here [7]:

Supervised learning: Creates a function which maps inputs
to expected outputs also named as labels, like Nave Bayes
classification, and support vector machines. Supervised
learning learns classification function from hand-labeled
instances.

Unsupervised learning: Unsupervised learning is learning
without a teacher. This learning Models a set of inputs, like
clustering, labels are not familiar during training. As an
explanation, one basic thing that you might want to do with
data is to visualize it. Sadly, it is difficult to visualize things in
more than two (or three) dimensions, and most data is in
hundreds of dimensions (or more). Dimensionality reduction is
the problem of taking high dimensional data and embedding it
in a lower dimension space. Another thing you might want to
do is automatically derive a partitioning of the data into clusters
[11].

Semi-supervised learning: One idea is to try to use the
unlabeled data to learn a better decision boundary. In a
discriminative setting, you can accomplish this by trying to find
decision boundaries that don’t pass too closely to unlabeled
data. In a generative setting, you can simply treat some of the
labels as observed and some as hidden. This is semi-supervised
learning [11]. Semi-supervised learning Generate an
appropriate function or classifier in which both labeled and
unlabeled examples are combined.

https://sites.google.com/site/ijcsis/
ISSN 1947-5500
(IJCSIS) International Journal of Computer Science and Information Security,

B. Domain Adaptation Algorithms

The concept of domain adaptation is almost related to
transfer learning. Transfer learning is a public term that refers
to a class of machine learning problems that include different
tasks or domains.

There are three general types of domain adaptation
algorithms [12]. It could be understood easily when represented
in a tabular form as given in table III:

 

 

 

 

 

 

 

 

 

 

 

 

TABLE IL. COMPARISON OF THREE CLASSES OF ALGORITHMS
Classi Class2 Class3
(FST) (PBA) dsw)
Name Feature Space Prior Based | Instance Selection/
Transformation Adaptation Weighting
Level
Feature Model Instance
Depend
ependeney Moderate Strong Weak
Domain Gap
Large Large Small
Extendability
of Domains Strong Strong Weak
VI. WORD SENSE DISAMBIGUATION IN BRIEF

Word Sense Disambiguation (WSD) is mainly a
classification problem. Suppose a word in a sentence and an
inventory of possible semantic tags for that word; which tag is
suitable for each individual instance of that word in context. In
many implementations, these labels are major sense numbers
from an online dictionary, but they may also match to topic or
subject codes, nodes in a semantic hierarchy, a set of feasible
foreign language translations, or even assignment to an
automatically induced sense partition. The nature of this given
sense inventory significantly determines the nature and
complexity of the sense disambiguation task [10].

Also applications of word sense disambiguation are
applications in machine translation and applications in
information retrieval.

An amount of robust disambiguation systems with more
simple requirements have been developed over the years. These
systems are designed to operate in a standalone mode and make
minimal hypothesizes about what information will be attainable
from other processes. In machine learning approaches, systems
are trained to do the task of word sense disambiguation. In
these approaches, what is learned is a classifier that can be used
to assign invisible examples, until now, to one of a fixed
number of senses [4].

VII. NLP (NATURAL LANGUAGE PROCESSING) FOR NLP

(NATURAL LANGUAGE PROGRAMMING)

Natural Language Processing and Programming Languages
are both based areas in the field of Computer Science. A
computer program is usually composed of sequences of action

105

. Vol. 13, No. 9, September 2015
statements that point out the operations to be performed.

Although they are both focused on a common idea -languages-,
through the years, there has been only little communication
between them. Here, the example below, tries to show how to
convert natural language text into computer programs [13].

Starting with the natural language text, "Write a program to
generate numbers between 0 to 10 and write these numbers out
to screen", the system is analyzing the text with the goal of
breaking it down into steps as the one shown below:

 

“Write a program to generate
numbers between 0 to 10 and
write these numbers out to
screen.”

 

1. Step Finder: identifies actions (verbs &objects).
2. Loop Finder: identifies repetitive statements.
3. Comment Identification: identifies descriptive

 

statements.
#include<stdio.h>
main (){
/*show numbers between 0 to 10*/
int num;

for (num=0 ; num<=10 ; + + num)
printf ("%d\n", num) ; }

9 —

Figure 1. The natural language (English) and programming language (C)
expressions for the same problem

 

 

VII. BIONLP: BIOMEDICAL NLP

BioNLP, also known as biomedical language processing or
biomedical text mining, is the application of natural language
processing techniques to biomedical data. The biomedical
domain presents a number of unique data types and tasks, but
concurrently has many aspects that are of interest to the
"mainstream" natural language processing community.
Moreover, there are moral issues in BioNLP that force an
attention to software quality assurance beyond the normal
attention that is paid to it in the mainstream academic NLP
community [10].

There are two basic user communities for BioNLP, and
many different user types within those two communities. The
two main communities are the clinical or medical community
on the one hand, and the biological community on the other.

https://sites.google.com/site/ijcsis/
ISSN 1947-5500
(IJCSIS) International Journal of Computer Science and Information Security,

IX.

Natural Language Processing is widely considered to be the
area of research and application, as compared to other
information technology approaches. There have been adequate
successes that propose NLP-based technologies will continue
to be a great area of research and development in information
systems now and in the future. Also Machine Learning is a
significant application in NLP that can never be ignored. ML is
truly a very important and elaborate, however a necessary task
in the NLP development applications.

CONCLUSION

The article is initiated with a brief review of Natural
Language Processing and Machine learning. Machine learning
models and approaches are defined in section II. There are
numerous possible benefits from utilizing every model. Some
classical and statistical approaches to NLP are introduced in
section III and IV.

Domain adaptation approaches in NLP tasks are presented
in section V that are dispersed to various classes. WORD sense
disambiguation is declared briefly in section VI. In section VII,
it is believed NLP for programmers will become main
technology in their information life. It will be a great event in
the ML history. NLP for NLP, appears to be a promising model
especially focusing on standardizing APIs, working on large
databases like calling functions just by speaking of humans to
machine, and improving IDEs for complex services. Hence
there is a scope for further research in these areas. At last,
BioNLP is showed in short.

ACKNOWLEDGMENT

The author would like to express her sincere thanks to
Dr.Khosravi for his valuable comments and his assistance on
this paper.

106

Vol. 13, No. 9, September 2015
REFERENCES

[1] Liddy, E. D, “Natural language processing",In Encyclopedia of Library

and Information Science, 2nd Ed,NY, Marcel Decker, Inc., 2001.
Madnani, Nitin,"Getting started on natural language processing with
python". Vol 13, pp. 1-3, 2013.

Nadkarni, Prakash M, Ohno-Machado, Lucila, and Chapman, Wendy W.
“Natural language processing: an introduction", Published by
group.bmj.com, pp. 545-547, 2011.

[2]

[3]

[4] Jurafsky, D. and Martin, J. H., "Speech and Language Processing: An
Introduction to Natural Language Processing, Speech Recognition, and
Computational Linguistics", 2nd edition. Prentice-Hall, Upper Saddle

River, NJ, 2008.

Cambria, Erik and White, Bebo. “Jumping nlp curves: A review of
natural language processing research" . IREE Computational Intelligence
Magazine, pp. 51-55, 2014.

Alpaydin, Ethem., "Introduction to Machine Learning", 2nd edition, The
MIT Press, Massachusetts Institute of Technology, 2010.

Buche, Arti., Chandak, Dr. M. B., and Zadgaonkar, Akshay. “Opinion
mining and analysis: A survey" International Journal on Natural
Language Computing (IJNLC), Vol. 2, No.3,pp. 41, 2013.

Domingos, Pedro. "A few useful things to know about machine

learning", communications of the ACM magazine vol.55,issue.10,pp 78-
79,2012.

[9] Pereira, Fernando. "Machine Learning in Natural Language

[5]

[6]

[7]

[8]

Processing",University of Pennsylvania, pp. 3, 2002.

[10] Indurkhya, Nitin and Damerau, Fred J. , "Handbook Of Natural Language
Processing", second edition, Chapman & Hall/CRC press, 2010.

Daumé I, Hal ,"A Course in Machine Learning", Published by
TODO,2014

Li, Qi." Literature survey:domain adaptation algorithms for natural
language processing", Department of Computer Science The Graduate
Center, The City University of New York, pp. 8-10, 2012.

Mihalcea, Rada, Liu, Hugo, and Lieberman, Henry. "Nlp (natural

language processing) for nlp (natural language programming)",pp. 323-
325, Springer-Verlag Berlin Heidelberg, 2006.

{11]

[12]

[13]

AUTHOR PROFILE

Fateme Behzadi is a MSC student in software engineering in bahmanyar
institute of higher education of kerman.she has two accepted papers in 2th
National Conference on New Approaches in Computer Engineering, which
will be held in Islamic Azad University of Roudsar.

https://sites.google.com/site/ijcsis/
ISSN 1947-5500
