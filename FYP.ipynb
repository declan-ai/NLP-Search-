{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\\n  Mounting trade friction between the\\n  U.S. And Japan has raised fears among many of Asia's exporting\\n  nations that the row could inflict far-reaching\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view text from one document \n",
    "reuters.raw(fileids=['test/14826'])[0:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir,path\n",
    "from os.path import join,isfile\n",
    "# remove punctuation from all DOCs \n",
    "#exclude = set(string.punctuation)\n",
    "#mypath='C:\\Users\\USER\\Desktop'\n",
    "#alldocslist = []\n",
    "#file_names = [f for f in listdir(mypath)if isfile(join(mypath, f))]\n",
    "\n",
    "#for index, i in  enumerate(file_names):\n",
    "#    text = open(os.path.join(mypath, i),'r')\n",
    "#    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "#    alldocslist.append(text)\n",
    "    \n",
    "#print(alldocslist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25EASMarch-3369.txt', 'bitc.txt', 'bitcoin.txt', 'bitc_founder.txt', 'blockchain.txt', 'blockchain1 - Copy.txt', 'blockchain1.txt', 'blockchain2.txt', 'blockchain3.txt', 'cnn.txt', 'cnn1.txt', 'Comparison Between an Artificial Neural Network and Logistic Regression in Predicting Long Term Kidney Transplantation Outcome.txt', 'crypto-wiki.txt', 'cryptocurrency.txt', 'Elsevier Enhanced Reader.txt', 'internet2009.txt', 'internetmemes.txt', 'iot2009.txt', 'kunihiko.txt', 'Natural Language Processing with Python.txt', 'Natural_Language_Processing_and_Machine.txt', 'necognitrion1.txt', 'necognitron.txt', 'nlp.txt', 'peer2peerECS.txt', 'pooling (2).txt', 'pooling.txt', 'pwc.txt', 'satoshi_nakamoto_investopedia.txt', 'self_organising_nn.txt', 'stoshi_nakamoto.txt']\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation from all DOCs \n",
    "\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "mypath='./text'\n",
    "alldocslist = list()\n",
    "file_names = [f for f in listdir(mypath)if isfile(join(mypath, f))]\n",
    "cntr=0\n",
    "temp=list()\n",
    "for i in range(len(file_names)):\n",
    "    temp=[file_names[i]]\n",
    "    alldocslist.append(temp)\n",
    "cntr=0\n",
    "for index, i in  enumerate(file_names):\n",
    "    text = open(os.path.join(mypath, i),'r',encoding=\"Latin-1\")\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    alldocslist[cntr].append(text)\n",
    "    cntr=cntr+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'Bitcoin', '?', 'Bitcoin', 'is', 'a', 'digital', 'currency', 'created', 'in', 'January', '2009', 'following', 'the', 'housing', 'market', 'crash', '.', 'It', 'follows', 'the', 'ideas', 'set', 'out', 'in', 'a', 'whitepaper', 'by', 'the', 'mysterious', 'and', 'pseudonymous', 'Satoshi', 'Nakamoto', '.', 'The', 'identity', 'of', 'the', 'person', 'or', 'persons', 'who', 'created', 'the', 'technology', 'is', 'still', 'a', 'mystery', '.', 'Bitcoin', 'offers', 'the', 'promise', 'of', 'lower', 'transaction', 'fees', 'than', 'traditional', 'online', 'payment', 'mechanisms', 'and', 'is', 'operated', 'by', 'a', 'decentralized', 'authority', ',', 'unlike', 'government-issued', 'currencies', '.', 'There', 'are', 'no', 'physical', 'bitcoins', ',', 'only', 'balances', 'kept', 'on', 'a', 'public', 'ledger', 'that', 'everyone', 'has', 'transparent', 'access', 'to', ',', 'that', '\\x96', 'along', 'with', 'all', 'Bitcoin', 'transactions', '\\x96', 'is', 'verified', 'by', 'a', 'massive', 'amount', 'of', 'computing', 'power', '.', 'Bitcoins', 'are', 'not', 'issued', 'or', 'backed', 'by', 'any', 'banks', 'or', 'governments', ',', 'nor', 'are', 'individual', 'bitcoins', 'valuable', 'as', 'a', 'commodity', '.', 'Despite', 'it', 'not', 'being', 'legal', 'tender', ',', 'Bitcoin', 'charts', 'high', 'on', 'popularity', ',', 'and', 'has', 'triggered', 'the', 'launch', 'of', 'hundreds', 'of', 'other', 'virtual', 'currencies', 'collectively', 'referred', 'to', 'as', 'Altcoins', '.', '1:57', 'What', 'Is', 'Bitcoin', 'KEY', 'TAKEAWAYS', 'Launched', 'in', '2009', ',', 'Bitcoin', 'is', 'the', 'world', \"'s\", 'largest', 'cryptocurrency', 'by', 'market', 'cap', '.', 'Unlike', 'fiat', 'currency', ',', 'Bitcoin', 'is', 'created', ',', 'distributed', ',', 'traded', ',', 'and', 'stored', 'with', 'the', 'use', 'of', 'a', 'decentralized', 'ledger', 'system', 'known', 'as', 'a', 'blockchain', '.', 'Bitcoin', \"'s\", 'history', 'as', 'a', 'store', 'of', 'value', 'has', 'been', 'turbulent', ';', 'the', 'cryptocurrency', 'skyrocketed', 'up', 'to', 'roughly', '$', '20,000', 'per', 'coin', 'in', '2017', ',', 'but', 'as', 'of', 'two', 'years', 'later', ',', 'is', 'currency', 'trading', 'for', 'less', 'than', 'half', 'of', 'that', '.', 'As', 'the', 'earliest', 'cryptocurrency', 'to', 'meet', 'widespread', 'popularity', 'and', 'success', ',', 'Bitcoin', 'has', 'inspired', 'a', 'host', 'of', 'other', 'projects', 'in', 'the', 'blockchain', 'space', '.', 'Understanding', 'Bitcoin', 'Bitcoin', 'is', 'a', 'collection', 'of', 'computers', ',', 'or', 'nodes', ',', 'that', 'all', 'run', 'Bitcoin', \"'s\", 'code', 'and', 'store', 'its', 'blockchain', '.', 'A', 'blockchain', 'can', 'be', 'thought', 'of', 'as', 'a', 'collection', 'of', 'blocks', '.', 'In', 'each', 'block', 'is', 'a', 'collection', 'of', 'transactions', '.', 'Because', 'all', 'these', 'computers', 'running', 'the', 'blockchain', 'have', 'the', 'same', 'list', 'of', 'blocks', 'and', 'transactions', 'and', 'can', 'transparently', 'see', 'these', 'new', 'blocks', 'being', 'filled', 'with', 'new', 'Bitcoin', 'transactions', ',', 'no', 'one', 'can', 'cheat', 'the', 'system', '.', 'Anyone', ',', 'whether', 'they', 'run', 'a', 'Bitcoin', '``', 'node', \"''\", 'or', 'not', ',', 'can', 'see', 'these', 'transactions', 'occurring', 'live', '.', 'In', 'order', 'to', 'achieve', 'a', 'nefarious', 'act', ',', 'a', 'bad', 'actor', 'would', 'need', 'to', 'operate', '51', '%', 'of', 'the', 'computing', 'power', 'that', 'makes', 'up', 'Bitcoin', '.', 'Bitcoin', 'currently', 'has', 'over', '10,000', 'nodes', 'and', 'this', 'number', 'is', 'growing', ',', 'making', 'such', 'an', 'attack', 'quite', 'unlikely', '.', 'In', 'the', 'event', 'that', 'an', 'attack', 'was', 'to', 'happen', ',', 'the', 'Bitcoin', 'nodes', ',', 'or', 'the', 'people', 'who', 'take', 'part', 'in', 'the', 'Bitcoin', 'network', 'with', 'their', 'computer', ',', 'would', 'likely', 'fork', 'to', 'a', 'new', 'blockchain', 'making', 'the', 'effort', 'the', 'bad', 'actor', 'put', 'forth', 'to', 'achieve', 'the', 'attack', 'a', 'waste', '.', 'Bitcoin', 'is', 'a', 'type', 'of', 'cryptocurrency', '.', 'Balances', 'of', 'Bitcoin', 'tokens', 'are', 'kept', 'using', 'public', 'and', 'private', '``', 'keys', ',', \"''\", 'which', 'are', 'long', 'strings', 'of', 'numbers', 'and', 'letters', 'linked', 'through', 'the', 'mathematical', 'encryption', 'algorithm', 'that', 'was', 'used', 'to', 'create', 'them', '.', 'The', 'public', 'key', '(', 'comparable', 'to', 'a', 'bank', 'account', 'number', ')', 'serves', 'as', 'the', 'address', 'which', 'is', 'published', 'to', 'the', 'world', 'and', 'to', 'which', 'others', 'may', 'send', 'bitcoins', '.', 'The', 'private', 'key', '(', 'comparable', 'to', 'an', 'ATM', 'PIN', ')', 'is', 'meant', 'to', 'be', 'a', 'guarded', 'secret', 'and', 'only', 'used', 'to', 'authorize', 'Bitcoin', 'transmissions', '.', 'Bitcoin', 'keys', 'should', 'not', 'be', 'confused', 'with', 'a', 'Bitcoin', 'wallet', ',', 'which', 'is', 'a', 'physical', 'or', 'digital', 'device', 'which', 'facilitates', 'the', 'trading', 'of', 'Bitcoin', 'and', 'allows', 'users', 'to', 'track', 'ownership', 'of', 'coins', '.', 'The', 'term', '``', 'wallet', \"''\", 'is', 'a', 'bit', 'misleading', ',', 'as', 'Bitcoin', \"'s\", 'decentralized', 'nature', 'means', 'that', 'it', 'is', 'never', 'stored', '``', 'in', \"''\", 'a', 'wallet', ',', 'but', 'rather', 'decentrally', 'on', 'a', 'blockchain', '.', 'Style', 'notes', ':', 'according', 'to', 'the', 'official', 'Bitcoin', 'Foundation', ',', 'the', 'word', '``', 'Bitcoin', \"''\", 'is', 'capitalized', 'in', 'the', 'context', 'of', 'referring', 'to', 'the', 'entity', 'or', 'concept', ',', 'whereas', '``', 'bitcoin', \"''\", 'is', 'written', 'in', 'the', 'lower', 'case', 'when', 'referring', 'to', 'a', 'quantity', 'of', 'the', 'currency', '(', 'e.g', '.', '``', 'I', 'traded', '20', 'bitcoin', \"''\", ')', 'or', 'the', 'units', 'themselves', '.', 'The', 'plural', 'form', 'can', 'be', 'either', '``', 'bitcoin', \"''\", 'or', '``', 'bitcoins', '.', \"''\", 'Bitcoin', 'is', 'also', 'commonly', 'abbreviated', 'as', '``', 'BTC', '.', \"''\", 'How', 'Bitcoin', 'Works', 'Bitcoin', 'is', 'one', 'of', 'the', 'first', 'digital', 'currencies', 'to', 'use', 'peer-to-peer', 'technology', 'to', 'facilitate', 'instant', 'payments', '.', 'The', 'independent', 'individuals', 'and', 'companies', 'who', 'own', 'the', 'governing', 'computing', 'power', 'and', 'participate', 'in', 'the', 'Bitcoin', 'network', ',', 'are', 'comprised', 'of', 'nodes', 'or', 'miners', '.', '``', 'Miners', ',', \"''\", 'or', 'the', 'people', 'who', 'process', 'the', 'transactions', 'on', 'the', 'blockchain', ',', 'are', 'motivated', 'by', 'rewards', '(', 'the', 'release', 'of', 'new', 'bitcoin', ')', 'and', 'transaction', 'fees', 'paid', 'in', 'bitcoin', '.', 'These', 'miners', 'can', 'be', 'thought', 'of', 'as', 'the', 'decentralized', 'authority', 'enforcing', 'the', 'credibility', 'of', 'the', 'Bitcoin', 'network', '.', 'New', 'bitcoin', 'is', 'being', 'released', 'to', 'the', 'miners', 'at', 'a', 'fixed', ',', 'but', 'periodically', 'declining', 'rate', ',', 'such', 'that', 'the', 'total', 'supply', 'of', 'bitcoins', 'approaches', '21', 'million', '.', 'Currently', ',', 'there', 'are', 'roughly', '3', 'million', 'bitcoins', 'which', 'have', 'yet', 'to', 'be', 'mined', '.', 'In', 'this', 'way', ',', 'Bitcoin', '(', 'and', 'any', 'cryptocurrency', 'generated', 'through', 'a', 'similar', 'process', ')', 'operates', 'differently', 'from', 'fiat', 'currency', ';', 'in', 'centralized', 'banking', 'systems', ',', 'currency', 'is', 'released', 'at', 'a', 'rate', 'matching', 'the', 'growth', 'in', 'goods', 'in', 'an', 'attempt', 'to', 'maintain', 'price', 'stability', ',', 'while', 'a', 'decentralized', 'system', 'like', 'Bitcoin', 'sets', 'the', 'release', 'rate', 'ahead', 'of', 'time', 'and', 'according', 'to', 'an', 'algorithm', '.', 'Bitcoin', 'mining', 'is', 'the', 'process', 'by', 'which', 'bitcoins', 'are', 'released', 'into', 'circulation', '.', 'Generally', ',', 'mining', 'requires', 'the', 'solving', 'of', 'computationally', 'difficult', 'puzzles', 'in', 'order', 'to', 'discover', 'a', 'new', 'block', ',', 'which', 'is', 'added', 'to', 'the', 'blockchain', '.', 'In', 'contributing', 'to', 'the', 'blockchain', ',', 'mining', 'adds', 'and', 'verifies', 'transaction', 'records', 'across', 'the', 'network', '.', 'For', 'adding', 'blocks', 'to', 'the', 'blockchain', ',', 'miners', 'receive', 'a', 'reward', 'in', 'the', 'form', 'of', 'a', 'few', 'bitcoins', ';', 'the', 'reward', 'is', 'halved', 'every', '210,000', 'blocks', '.', 'The', 'block', 'reward', 'was', '50', 'new', 'bitcoins', 'in', '2009', 'and', 'is', 'currently', '12.5', '.', 'By', 'around', 'May', '11th', ',', '2020', 'the', 'next', 'halving', 'will', 'occur', ',', 'bringing', 'the', 'reward', 'for', 'each', 'block', 'discovery', 'down', 'to', '6.25', 'bitcoins', '.', 'A', 'variety', 'of', 'hardware', 'can', 'be', 'used', 'to', 'mine', 'bitcoin', 'but', 'some', 'yield', 'higher', 'rewards', 'than', 'others', '.', 'Certain', 'computer', 'chips', 'called', 'Application-Specific', 'Integrated', 'Circuits', '(', 'ASIC', ')', 'and', 'more', 'advanced', 'processing', 'units', 'like', 'Graphic', 'Processing', 'Units', '(', 'GPUs', ')', 'can', 'achieve', 'more', 'rewards', '.', 'These', 'elaborate', 'mining', 'processors', 'are', 'known', 'as', '``', 'mining', 'rigs', '.', \"''\", 'One', 'bitcoin', 'is', 'divisible', 'to', 'eight', 'decimal', 'places', '(', '100', 'millionths', 'of', 'one', 'bitcoin', ')', ',', 'and', 'this', 'smallest', 'unit', 'is', 'referred', 'to', 'as', 'a', 'Satoshi', '.', 'If', 'necessary', ',', 'and', 'if', 'the', 'participating', 'miners', 'accept', 'the', 'change', ',', 'Bitcoin', 'could', 'eventually', 'be', 'made', 'divisible', 'to', 'even', 'more', 'decimal', 'places', '.', 'How', 'Bitcoin', 'Began', 'Aug.', '18', ',', '2008', ':', 'The', 'domain', 'name', 'bitcoin.org', 'is', 'registered', '.', 'Today', ',', 'at', 'least', ',', 'this', 'domain', 'is', '``', 'WhoisGuard', 'Protected', ',', \"''\", 'meaning', 'the', 'identity', 'of', 'the', 'person', 'who', 'registered', 'it', 'is', 'not', 'public', 'information', '.', 'Oct.', '31', ',', '2008', ':', 'A', 'person', 'or', 'group', 'using', 'the', 'name', 'Satoshi', 'Nakamoto', 'makes', 'an', 'announcement', 'on', 'The', 'Cryptography', 'Mailing', 'list', 'at', 'metzdowd.com', ':', '``', 'I', \"'ve\", 'been', 'working', 'on', 'a', 'new', 'electronic', 'cash', 'system', 'that', \"'s\", 'fully', 'peer-to-peer', ',', 'with', 'no', 'trusted', 'third', 'party', '.', 'The', 'paper', 'is', 'available', 'at', 'http', ':', '//www.bitcoin.org/bitcoin.pdf', '.', \"''\", 'This', 'link', 'leads', 'to', 'the', 'now-famous', 'whitepaper', 'published', 'on', 'bitcoin.org', 'entitled', '``', 'Bitcoin', ':', 'A', 'Peer-to-Peer', 'Electronic', 'Cash', 'System', '.', \"''\", 'This', 'paper', 'would', 'become', 'the', 'Magna', 'Carta', 'for', 'how', 'Bitcoin', 'operates', 'today', '.', 'Jan.', '3', ',', '2009', ':', 'The', 'first', 'Bitcoin', 'block', 'is', 'mined', ',', 'Block', '0', '.', 'This', 'is', 'also', 'known', 'as', 'the', '``', 'genesis', 'block', \"''\", 'and', 'contains', 'the', 'text', ':', '``', 'The', 'Times', '03/Jan/2009', 'Chancellor', 'on', 'brink', 'of', 'second', 'bailout', 'for', 'banks', ',', \"''\", 'perhaps', 'as', 'proof', 'that', 'the', 'block', 'was', 'mined', 'on', 'or', 'after', 'that', 'date', ',', 'and', 'perhaps', 'also', 'as', 'relevant', 'political', 'commentary', '.', 'Jan.', '8', ',', '2009', ':', 'The', 'first', 'version', 'of', 'the', 'Bitcoin', 'software', 'is', 'announced', 'on', 'The', 'Cryptography', 'Mailing', 'list', '.', 'Jan.', '9', ',', '2009', ':', 'Block', '1', 'is', 'mined', ',', 'and', 'Bitcoin', 'mining', 'commences', 'in', 'earnest', '.', 'Who', 'Invented', 'Bitcoin', '?', 'No', 'one', 'knows', 'who', 'invented', 'Bitcoin', ',', 'or', 'at', 'least', 'not', 'conclusively', '.', 'Satoshi', 'Nakamoto', 'is', 'the', 'name', 'associated', 'with', 'the', 'person', 'or', 'group', 'of', 'people', 'who', 'released', 'the', 'original', 'Bitcoin', 'white', 'paper', 'in', '2008', 'and', 'worked', 'on', 'the', 'original', 'Bitcoin', 'software', 'that', 'was', 'released', 'in', '2009', '.', 'In', 'the', 'years', 'since', 'that', 'time', ',', 'many', 'individuals', 'have', 'either', 'claimed', 'to', 'be', 'or', 'have', 'been', 'suggested', 'as', 'the', 'real-life', 'people', 'behind', 'the', 'pseudonym', ',', 'but', 'as', 'of', 'May', '2020', ',', 'the', 'true', 'identity', '(', 'or', 'identities', ')', 'behind', 'Satoshi', 'remains', 'obscured', '.', 'Before', 'Satoshi', 'Though', 'it', 'is', 'tempting', 'to', 'believe', 'the', 'media', \"'s\", 'spin', 'that', 'Satoshi', 'Nakamoto', 'is', 'a', 'solitary', ',', 'quixotic', 'genius', 'who', 'created', 'Bitcoin', 'out', 'of', 'thin', 'air', ',', 'such', 'innovations', 'do', 'not', 'typically', 'happen', 'in', 'a', 'vacuum', '.', 'All', 'major', 'scientific', 'discoveries', ',', 'no', 'matter', 'how', 'original-seeming', ',', 'were', 'built', 'on', 'previously', 'existing', 'research', '.', 'There', 'are', 'precursors', 'to', 'Bitcoin', ':', 'Adam', 'Back\\x92s', 'Hashcash', ',', 'invented', 'in', '1997', ',', 'and', 'subsequently', 'Wei', 'Dai\\x92s', 'b-money', ',', 'Nick', 'Szabo\\x92s', 'bit', 'gold', 'and', 'Hal', 'Finney\\x92s', 'Reusable', 'Proof', 'of', 'Work', '.', 'The', 'Bitcoin', 'whitepaper', 'itself', 'cites', 'Hashcash', 'and', 'b-money', ',', 'as', 'well', 'as', 'various', 'other', 'works', 'spanning', 'several', 'research', 'fields', '.', 'Perhaps', 'unsurprisingly', ',', 'many', 'of', 'the', 'individuals', 'behind', 'the', 'other', 'projects', 'named', 'above', 'have', 'been', 'speculated', 'to', 'have', 'also', 'had', 'a', 'part', 'in', 'creating', 'Bitcoin', '.', 'Why', 'Is', 'Satoshi', 'Anonymous', '?', 'There', 'are', 'a', 'few', 'motivations', 'for', 'Bitcoin', \"'s\", 'inventor', 'keeping', 'his', 'or', 'her', 'or', 'their', 'identity', 'secret', '.', 'One', 'is', 'privacy', '.', 'As', 'Bitcoin', 'has', 'gained', 'in', 'popularity', '\\x96', 'becoming', 'something', 'of', 'a', 'worldwide', 'phenomenon', '\\x96', 'Satoshi', 'Nakamoto', 'would', 'likely', 'garner', 'a', 'lot', 'of', 'attention', 'from', 'the', 'media', 'and', 'from', 'governments', '.', 'Another', 'reason', 'could', 'be', 'the', 'potential', 'for', 'Bitcoin', 'to', 'cause', 'major', 'disruption', 'of', 'the', 'current', 'banking', 'and', 'monetary', 'systems', '.', 'If', 'Bitcoin', 'were', 'to', 'gain', 'mass', 'adoption', ',', 'the', 'system', 'could', 'surpass', 'nations', \"'\", 'sovereign', 'fiat', 'currencies', '.', 'This', 'threat', 'to', 'existing', 'currency', 'could', 'motivate', 'governments', 'to', 'want', 'to', 'take', 'legal', 'action', 'against', 'Bitcoin', \"'s\", 'creator', '.', 'The', 'other', 'reason', 'is', 'safety', '.', 'Looking', 'at', '2009', 'alone', ',', '32,489', 'blocks', 'were', 'mined', ';', 'at', 'the', 'then-reward', 'rate', 'of', '50', 'BTC', 'per', 'block', ',', 'the', 'total', 'payout', 'in', '2009', 'was', '1,624,500', 'BTC', ',', 'which', 'is', 'worth', '$', '13.9', 'billion', 'as', 'of', 'October', '25', ',', '2019', '.', 'One', 'may', 'conclude', 'that', 'only', 'Satoshi', 'and', 'perhaps', 'a', 'few', 'other', 'people', 'were', 'mining', 'through', '2009', 'and', 'that', 'they', 'possess', 'a', 'majority', 'of', 'that', 'stash', 'of', 'BTC', '.', 'Someone', 'in', 'possession', 'of', 'that', 'much', 'Bitcoin', 'could', 'become', 'a', 'target', 'of', 'criminals', ',', 'especially', 'since', 'bitcoins', 'are', 'less', 'like', 'stocks', 'and', 'more', 'like', 'cash', ',', 'where', 'the', 'private', 'keys', 'needed', 'to', 'authorize', 'spending', 'could', 'be', 'printed', 'out', 'and', 'literally', 'kept', 'under', 'a', 'mattress', '.', 'While', 'it', \"'s\", 'likely', 'the', 'inventor', 'of', 'Bitcoin', 'would', 'take', 'precautions', 'to', 'make', 'any', 'extortion-induced', 'transfers', 'traceable', ',', 'remaining', 'anonymous', 'is', 'a', 'good', 'way', 'for', 'Satoshi', 'to', 'limit', 'exposure', '.', 'Receiving', 'Bitcoins', 'As', 'Payment', 'Bitcoins', 'can', 'be', 'accepted', 'as', 'a', 'means', 'of', 'payment', 'for', 'products', 'sold', 'or', 'services', 'provided', '.', 'If', 'you', 'have', 'a', 'brick', 'and', 'mortar', 'store', ',', 'just', 'display', 'a', 'sign', 'saying', '\\x93Bitcoin', 'Accepted', 'Here\\x94', 'and', 'many', 'of', 'your', 'customers', 'may', 'well', 'take', 'you', 'up', 'on', 'it', ';', 'the', 'transactions', 'can', 'be', 'handled', 'with', 'the', 'requisite', 'hardware', 'terminal', 'or', 'wallet', 'address', 'through', 'QR', 'codes', 'and', 'touch', 'screen', 'apps', '.', 'An', 'online', 'business', 'can', 'easily', 'accept', 'bitcoins', 'by', 'just', 'adding', 'this', 'payment', 'option', 'to', 'the', 'others', 'it', 'offers', 'credit', 'cards', ',', 'PayPal', ',', 'etc', '.', 'Working', 'For', 'Bitcoins', 'Those', 'who', 'are', 'self-employed', 'can', 'get', 'paid', 'for', 'a', 'job', 'in', 'bitcoins', '.', 'There', 'are', 'a', 'number', 'of', 'ways', 'to', 'achieve', 'this', 'such', 'as', 'creating', 'any', 'internet', 'service', 'and', 'adding', 'your', 'bitcoin', 'wallet', 'address', 'to', 'the', 'site', 'as', 'a', 'form', 'of', 'payment', '.', 'There', 'are', 'several', 'websites/job', 'boards', 'which', 'are', 'dedicated', 'to', 'the', 'digital', 'currency', ':', 'Cryptogrind', 'brings', 'together', 'work', 'seekers', 'and', 'prospective', 'employers', 'through', 'its', 'website', 'Coinality', 'features', 'jobs', '\\x96', 'freelance', ',', 'part-time', 'and', 'full-time', '\\x96', 'that', 'offer', 'payment', 'in', 'bitcoins', ',', 'as', 'well', 'as', 'other', 'cryptocurrencies', 'like', 'Dogecoin', 'and', 'Litecoin', 'Jobs4Bitcoins', ',', 'part', 'of', 'reddit.com', 'BitGigs', 'Bitwage', 'offers', 'a', 'way', 'to', 'choose', 'a', 'percentage', 'of', 'your', 'work', 'paycheck', 'to', 'be', 'converted', 'into', 'bitcoin', 'and', 'sent', 'to', 'your', 'bitcoin', 'address', '4:24', 'How', 'to', 'Buy', 'Bitcoin', 'Investing', 'in', 'Bitcoins', 'There', 'are', 'many', 'Bitcoin', 'supporters', 'who', 'believe', 'that', 'digital', 'currency', 'is', 'the', 'future', '.', 'Many', 'of', 'those', 'who', 'endorse', 'Bitcoin', 'believe', 'that', 'it', 'facilitates', 'a', 'much', 'faster', ',', 'low-fee', 'payment', 'system', 'for', 'transactions', 'across', 'the', 'globe', '.', 'Although', 'it', 'is', 'not', 'backed', 'by', 'any', 'government', 'or', 'central', 'bank', ',', 'bitcoin', 'can', 'be', 'exchanged', 'for', 'traditional', 'currencies', ';', 'in', 'fact', ',', 'its', 'exchange', 'rate', 'against', 'the', 'dollar', 'attracts', 'potential', 'investors', 'and', 'traders', 'interested', 'in', 'currency', 'plays', '.', 'Indeed', ',', 'one', 'of', 'the', 'primary', 'reasons', 'for', 'the', 'growth', 'of', 'digital', 'currencies', 'like', 'Bitcoin', 'is', 'that', 'they', 'can', 'act', 'as', 'an', 'alternative', 'to', 'national', 'fiat', 'money', 'and', 'traditional', 'commodities', 'like', 'gold', '.', 'In', 'March', '2014', ',', 'the', 'IRS', 'stated', 'that', 'all', 'virtual', 'currencies', ',', 'including', 'bitcoins', ',', 'would', 'be', 'taxed', 'as', 'property', 'rather', 'than', 'currency', '.', 'Gains', 'or', 'losses', 'from', 'bitcoins', 'held', 'as', 'capital', 'will', 'be', 'realized', 'as', 'capital', 'gains', 'or', 'losses', ',', 'while', 'bitcoins', 'held', 'as', 'inventory', 'will', 'incur', 'ordinary', 'gains', 'or', 'losses', '.', 'The', 'sale', 'of', 'bitcoins', 'that', 'you', 'mined', 'or', 'purchased', 'from', 'another', 'party', ',', 'or', 'the', 'use', 'of', 'bitcoins', 'to', 'pay', 'for', 'goods', 'or', 'services', 'are', 'examples', 'of', 'transactions', 'which', 'can', 'be', 'taxed', '.', 'Like', 'any', 'other', 'asset', ',', 'the', 'principle', 'of', 'buying', 'low', 'and', 'selling', 'high', 'applies', 'to', 'bitcoins', '.', 'The', 'most', 'popular', 'way', 'of', 'amassing', 'the', 'currency', 'is', 'through', 'buying', 'on', 'a', 'Bitcoin', 'exchange', ',', 'but', 'there', 'are', 'many', 'other', 'ways', 'to', 'earn', 'and', 'own', 'bitcoins', '.', 'Risks', 'of', 'Bitcoin', 'Investing', 'Though', 'Bitcoin', 'was', 'not', 'designed', 'as', 'a', 'normal', 'equity', 'investment', '(', 'no', 'shares', 'have', 'been', 'issued', ')', ',', 'some', 'speculative', 'investors', 'were', 'drawn', 'to', 'the', 'digital', 'money', 'after', 'it', 'appreciated', 'rapidly', 'in', 'May', '2011', 'and', 'again', 'in', 'November', '2013', '.', 'Thus', ',', 'many', 'people', 'purchase', 'bitcoin', 'for', 'its', 'investment', 'value', 'rather', 'than', 'as', 'a', 'medium', 'of', 'exchange', '.', 'However', ',', 'their', 'lack', 'of', 'guaranteed', 'value', 'and', 'digital', 'nature', 'means', 'the', 'purchase', 'and', 'use', 'of', 'bitcoins', 'carries', 'several', 'inherent', 'risks', '.', 'Many', 'investor', 'alerts', 'have', 'been', 'issued', 'by', 'the', 'Securities', 'and', 'Exchange', 'Commission', '(', 'SEC', ')', ',', 'the', 'Financial', 'Industry', 'Regulatory', 'Authority', '(', 'FINRA', ')', ',', 'the', 'Consumer', 'Financial', 'Protection', 'Bureau', '(', 'CFPB', ')', ',', 'and', 'other', 'agencies', '.', 'The', 'concept', 'of', 'a', 'virtual', 'currency', 'is', 'still', 'novel', 'and', ',', 'compared', 'to', 'traditional', 'investments', ',', 'Bitcoin', 'does', \"n't\", 'have', 'much', 'of', 'a', 'long-term', 'track', 'record', 'or', 'history', 'of', 'credibility', 'to', 'back', 'it', '.', 'With', 'their', 'increasing', 'popularity', ',', 'bitcoins', 'are', 'becoming', 'less', 'experimental', 'every', 'day', ';', 'still', ',', 'after', '10', 'years', ',', 'they', '(', 'like', 'all', 'digital', 'currencies', ')', 'remain', 'in', 'a', 'development', 'phase', 'and', 'are', 'consistently', 'evolving', '.', '``', 'It', 'is', 'pretty', 'much', 'the', 'highest-risk', ',', 'highest-return', 'investment', 'that', 'you', 'can', 'possibly', 'make', ',', '\\x94', 'says', 'Barry', 'Silbert', ',', 'CEO', 'of', 'Digital', 'Currency', 'Group', ',', 'which', 'builds', 'and', 'invests', 'in', 'Bitcoin', 'and', 'blockchain', 'companies', '.', 'Bitcoin', 'Regulatory', 'Risk', 'Investing', 'money', 'into', 'Bitcoin', 'in', 'any', 'of', 'its', 'many', 'guises', 'is', 'not', 'for', 'the', 'risk-averse', '.', 'Bitcoins', 'are', 'a', 'rival', 'to', 'government', 'currency', 'and', 'may', 'be', 'used', 'for', 'black', 'market', 'transactions', ',', 'money', 'laundering', ',', 'illegal', 'activities', 'or', 'tax', 'evasion', '.', 'As', 'a', 'result', ',', 'governments', 'may', 'seek', 'to', 'regulate', ',', 'restrict', 'or', 'ban', 'the', 'use', 'and', 'sale', 'of', 'bitcoins', ',', 'and', 'some', 'already', 'have', '.', 'Others', 'are', 'coming', 'up', 'with', 'various', 'rules', '.', 'For', 'example', ',', 'in', '2015', ',', 'the', 'New', 'York', 'State', 'Department', 'of', 'Financial', 'Services', 'finalized', 'regulations', 'that', 'would', 'require', 'companies', 'dealing', 'with', 'the', 'buy', ',', 'sell', ',', 'transfer', 'or', 'storage', 'of', 'bitcoins', 'to', 'record', 'the', 'identity', 'of', 'customers', ',', 'have', 'a', 'compliance', 'officer', 'and', 'maintain', 'capital', 'reserves', '.', 'The', 'transactions', 'worth', '$', '10,000', 'or', 'more', 'will', 'have', 'to', 'be', 'recorded', 'and', 'reported', '.', 'The', 'lack', 'of', 'uniform', 'regulations', 'about', 'bitcoins', '(', 'and', 'other', 'virtual', 'currency', ')', 'raises', 'questions', 'over', 'their', 'longevity', ',', 'liquidity', ',', 'and', 'universality', '.', 'Security', 'Risk', 'of', 'Bitcoins', 'Most', 'individuals', 'who', 'own', 'and', 'use', 'Bitcoin', 'have', 'not', 'acquired', 'their', 'tokens', 'through', 'mining', 'operations', '.', 'Rather', ',', 'they', 'buy', 'and', 'sell', 'Bitcoin', 'and', 'other', 'digital', 'currencies', 'on', 'any', 'of', 'a', 'number', 'of', 'popular', 'online', 'markets', 'known', 'as', 'Bitcoin', 'exchanges', '.', 'Bitcoin', 'exchanges', 'are', 'entirely', 'digital', 'and', ',', 'as', 'with', 'any', 'virtual', 'system', ',', 'are', 'at', 'risk', 'from', 'hackers', ',', 'malware', ',', 'and', 'operational', 'glitches', '.', 'If', 'a', 'thief', 'gains', 'access', 'to', 'a', 'Bitcoin', 'owner', \"'s\", 'computer', 'hard', 'drive', 'and', 'steals', 'his', 'private', 'encryption', 'key', ',', 'he', 'could', 'transfer', 'the', 'stolen', 'Bitcoins', 'to', 'another', 'account', '.', '(', 'Users', 'can', 'prevent', 'this', 'only', 'if', 'bitcoins', 'are', 'stored', 'on', 'a', 'computer', 'which', 'is', 'not', 'connected', 'to', 'the', 'internet', ',', 'or', 'else', 'by', 'choosing', 'to', 'use', 'a', 'paper', 'wallet', '\\x96', 'printing', 'out', 'the', 'Bitcoin', 'private', 'keys', 'and', 'addresses', ',', 'and', 'not', 'keeping', 'them', 'on', 'a', 'computer', 'at', 'all', '.', ')', 'Hackers', 'can', 'also', 'target', 'Bitcoin', 'exchanges', ',', 'gaining', 'access', 'to', 'thousands', 'of', 'accounts', 'and', 'digital', 'wallets', 'where', 'bitcoins', 'are', 'stored', '.', 'One', 'especially', 'notorious', 'hacking', 'incident', 'took', 'place', 'in', '2014', ',', 'when', 'Mt', '.', 'Gox', ',', 'a', 'Bitcoin', 'exchange', 'in', 'Japan', ',', 'was', 'forced', 'to', 'close', 'down', 'after', 'millions', 'of', 'dollars', 'worth', 'of', 'bitcoins', 'were', 'stolen', '.', 'This', 'is', 'particularly', 'problematic', 'once', 'you', 'remember', 'that', 'all', 'Bitcoin', 'transactions', 'are', 'permanent', 'and', 'irreversible', '.', 'It', \"'s\", 'like', 'dealing', 'with', 'cash', ':', 'Any', 'transaction', 'carried', 'out', 'with', 'bitcoins', 'can', 'only', 'be', 'reversed', 'if', 'the', 'person', 'who', 'has', 'received', 'them', 'refunds', 'them', '.', 'There', 'is', 'no', 'third', 'party', 'or', 'a', 'payment', 'processor', ',', 'as', 'in', 'the', 'case', 'of', 'a', 'debit', 'or', 'credit', 'card', '\\x96', 'hence', ',', 'no', 'source', 'of', 'protection', 'or', 'appeal', 'if', 'there', 'is', 'a', 'problem', '.', 'Insurance', 'Risk', 'Some', 'investments', 'are', 'insured', 'through', 'the', 'Securities', 'Investor', 'Protection', 'Corporation', '.', 'Normal', 'bank', 'accounts', 'are', 'insured', 'through', 'the', 'Federal', 'Deposit', 'Insurance', 'Corporation', '(', 'FDIC', ')', 'up', 'to', 'a', 'certain', 'amount', 'depending', 'on', 'the', 'jurisdiction', '.', 'Generally', 'speaking', ',', 'Bitcoin', 'exchanges', 'and', 'Bitcoin', 'accounts', 'are', 'not', 'insured', 'by', 'any', 'type', 'of', 'federal', 'or', 'government', 'program', '.', 'In', '2019', ',', 'prime', 'dealer', 'and', 'trading', 'platform', 'SFOX', 'announced', 'it', 'would', 'be', 'able', 'to', 'provide', 'Bitcoin', 'investors', 'with', 'FDIC', 'insurance', ',', 'but', 'only', 'for', 'the', 'portion', 'of', 'transactions', 'involving', 'cash', '.', 'Risk', 'of', 'Bitcoin', 'Fraud', 'While', 'Bitcoin', 'uses', 'private', 'key', 'encryption', 'to', 'verify', 'owners', 'and', 'register', 'transactions', ',', 'fraudsters', 'and', 'scammers', 'may', 'attempt', 'to', 'sell', 'false', 'bitcoins', '.', 'For', 'instance', ',', 'in', 'July', '2013', ',', 'the', 'SEC', 'brought', 'legal', 'action', 'against', 'an', 'operator', 'of', 'a', 'Bitcoin-related', 'Ponzi', 'scheme', '.', 'There', 'have', 'also', 'been', 'documented', 'cases', 'of', 'Bitcoin', 'price', 'manipulation', ',', 'another', 'common', 'form', 'of', 'fraud', '.', 'Market', 'Risk', 'Like', 'with', 'any', 'investment', ',', 'Bitcoin', 'values', 'can', 'fluctuate', '.', 'Indeed', ',', 'the', 'value', 'of', 'the', 'currency', 'has', 'seen', 'wild', 'swings', 'in', 'price', 'over', 'its', 'short', 'existence', '.', 'Subject', 'to', 'high', 'volume', 'buying', 'and', 'selling', 'on', 'exchanges', ',', 'it', 'has', 'a', 'high', 'sensitivity', 'to', '\\x93news', '.', \"''\", 'According', 'to', 'the', 'CFPB', ',', 'the', 'price', 'of', 'bitcoins', 'fell', 'by', '61', '%', 'in', 'a', 'single', 'day', 'in', '2013', ',', 'while', 'the', 'one-day', 'price', 'drop', 'record', 'in', '2014', 'was', 'as', 'big', 'as', '80', '%', '.', 'If', 'fewer', 'people', 'begin', 'to', 'accept', 'Bitcoin', 'as', 'a', 'currency', ',', 'these', 'digital', 'units', 'may', 'lose', 'value', 'and', 'could', 'become', 'worthless', '.', 'Indeed', ',', 'there', 'was', 'speculation', 'that', 'the', '``', 'Bitcoin', 'bubble', \"''\", 'had', 'burst', 'when', 'the', 'price', 'declined', 'from', 'its', 'all-time', 'high', 'during', 'the', 'cryptocurrency', 'rush', 'in', 'late', '2017', 'and', 'early', '2018', '.', 'There', 'is', 'already', 'plenty', 'of', 'competition', ',', 'and', 'though', 'Bitcoin', 'has', 'a', 'huge', 'lead', 'over', 'the', 'hundreds', 'of', 'other', 'digital', 'currencies', 'that', 'have', 'sprung', 'up', ',', 'thanks', 'to', 'its', 'brand', 'recognition', 'and', 'venture', 'capital', 'money', ',', 'a', 'technological', 'break-through', 'in', 'the', 'form', 'of', 'a', 'better', 'virtual', 'coin', 'is', 'always', 'a', 'threat', '.', 'Bitcoin', \"'s\", 'Tax', 'Risk', 'As', 'bitcoin', 'is', 'ineligible', 'to', 'be', 'included', 'in', 'any', 'tax-advantaged', 'retirement', 'accounts', ',', 'there', 'are', 'no', 'good', ',', 'legal', 'options', 'to', 'shield', 'investments', 'from', 'taxation', '.', 'Bitcoin', 'Forks', 'In', 'the', 'years', 'since', 'Bitcoin', 'launched', ',', 'there', 'have', 'been', 'numerous', 'instances', 'in', 'which', 'disagreements', 'between', 'factions', 'of', 'miners', 'and', 'developers', 'prompted', 'large-scale', 'splits', 'of', 'the', 'cryptocurrency', 'community', '.', 'In', 'some', 'of', 'these', 'cases', ',', 'groups', 'of', 'Bitcoin', 'users', 'and', 'miners', 'have', 'changed', 'the', 'protocol', 'of', 'the', 'Bitcoin', 'network', 'itself', '.', 'This', 'process', 'is', 'known', '``', 'forking', \"''\", 'and', 'usually', 'results', 'in', 'the', 'creation', 'of', 'a', 'new', 'type', 'of', 'Bitcoin', 'with', 'a', 'new', 'name', '.', 'This', 'split', 'can', 'be', 'a', '``', 'hard', 'fork', ',', \"''\", 'in', 'which', 'a', 'new', 'coin', 'shares', 'transaction', 'history', 'with', 'Bitcoin', 'up', 'until', 'a', 'decisive', 'split', 'point', ',', 'at', 'which', 'point', 'a', 'new', 'token', 'is', 'created', '.', 'Examples', 'of', 'cryptocurrencies', 'that', 'have', 'been', 'created', 'as', 'a', 'result', 'of', 'hard', 'forks', 'include', 'Bitcoin', 'Cash', '(', 'created', 'in', 'August', '2017', ')', ',', 'Bitcoin', 'Gold', '(', 'created', 'in', 'October', '2017', ')', 'and', 'Bitcoin', 'SV', '(', 'created', 'in', 'November', '2017', ')', '.', 'A', '``', 'soft', 'fork', \"''\", 'is', 'a', 'change', 'to', 'protocol', 'which', 'is', 'still', 'compatible', 'with', 'the', 'previous', 'system', 'rules', '.', 'Bitcoin', 'soft', 'forks', 'have', 'increased', 'the', 'total', 'size', 'of', 'blocks', ',', 'as', 'an', 'example', '.', 'Compete', 'Risk', 'Free', 'with', '$', '100,000', 'in', 'Virtual', 'Cash', 'Put', 'your', 'trading', 'skills', 'to', 'the', 'test', 'with', 'our', 'FREE', 'Stock', 'Simulator', '.', 'Compete', 'with', 'thousands', 'of', 'Investopedia', 'traders', 'and', 'trade', 'your', 'way', 'to', 'the', 'top', '!', 'Submit', 'trades', 'in', 'a', 'virtual', 'environment', 'before', 'you', 'start', 'risking', 'your', 'own', 'money', '.', 'Practice', 'trading', 'strategies', 'so', 'that', 'when', 'you', \"'re\", 'ready', 'to', 'enter', 'the', 'real', 'market', ',', 'you', \"'ve\", 'had', 'the', 'practice', 'you', 'need', '.', 'Try', 'our', 'Stock', 'Simulator', 'today', '>', '>']\n"
     ]
    }
   ],
   "source": [
    "#tokenize words in all DOCS \n",
    "plot_data = [[]] * len(alldocslist)\n",
    "\n",
    "for doc in alldocslist:\n",
    "    text = doc\n",
    "    tokentext = word_tokenize(text)\n",
    "    plot_data[index].append(tokentext)\n",
    "    \n",
    "print(plot_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'is',\n",
       " 'Bitcoin',\n",
       " '?',\n",
       " 'Bitcoin',\n",
       " 'is',\n",
       " 'a',\n",
       " 'digital',\n",
       " 'currency',\n",
       " 'created']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigation: first index gives all documents, second index gives specific document, third index gives words of that doc\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'is',\n",
       " 'bitcoin',\n",
       " '?',\n",
       " 'bitcoin',\n",
       " 'is',\n",
       " 'a',\n",
       " 'digital',\n",
       " 'currency',\n",
       " 'created']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make all words lower case for all docs \n",
    "for x in range(len(file_names)):\n",
    "    lowers = [word.lower() for word in plot_data[0][x]]\n",
    "    plot_data[0][x] = lowers\n",
    "\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bitcoin',\n",
       " '?',\n",
       " 'bitcoin',\n",
       " 'digital',\n",
       " 'currency',\n",
       " 'created',\n",
       " 'january',\n",
       " '2009',\n",
       " 'following',\n",
       " 'housing']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words from all docs \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for x in range(len(file_names)):\n",
    "    filtered_sentence = [w for w in plot_data[0][x] if not w in stop_words]\n",
    "    plot_data[0][x] = filtered_sentence\n",
    "\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['satoshi',\n",
       " 'nakamoto',\n",
       " 'wikipedia',\n",
       " ',',\n",
       " 'free',\n",
       " 'encyclopedia',\n",
       " 'jump',\n",
       " 'navigationjump',\n",
       " 'search',\n",
       " 'satoshi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stem words EXAMPLE (could try others/lemmers )\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_sentence = [snowball_stemmer.stem(w) for w in filtered_sentence]\n",
    "stemmed_sentence[0:10]\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_sentence = [ porter_stemmer.stem(w) for w in filtered_sentence]\n",
    "stemmed_sentence[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inverse index which gives document number for each document and where word appears\n",
    "\n",
    "#first we need to create a list of all words \n",
    "l = plot_data[0]\n",
    "flatten = [item for sublist in l for item in sublist]\n",
    "words = flatten\n",
    "wordsunique = set(words)\n",
    "wordsunique = list(wordsunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions for TD-IDF / BM25\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc)\n",
    "\n",
    "def idf(word, doclist):\n",
    "    return math.log(len(doclist) / (0.01 + n_containing(word, doclist)))\n",
    "\n",
    "def tfidf(word, doc, doclist):\n",
    "    return (tf(word, doc) * idf(word, doclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictonary of words\n",
    "# THIS ONE-TIME INDEXING IS THE MOST PROCESSOR-INTENSIVE STEP AND WILL TAKE TIME TO RUN (BUT ONLY NEEDS TO BE RUN ONCE)\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "plottest = plot_data[0][0:1000]\n",
    "\n",
    "worddic = {}\n",
    "\n",
    "for doc in plottest:\n",
    "    for word in wordsunique:\n",
    "        if word in doc:\n",
    "            word = str(word)\n",
    "            index = plottest.index(doc)\n",
    "            positions = list(np.where(np.array(plottest[index]) == word)[0])\n",
    "            idfs = tfidf(word,doc,plottest)\n",
    "            try:\n",
    "                worddic[word].append([index,positions,idfs])\n",
    "            except:\n",
    "                worddic[word] = []\n",
    "                worddic[word].append([index,positions,idfs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [890, 924, 3358], 0.0004611121266409789],\n",
       " [5, [881, 2885, 2916, 3133, 3486], 0.0009084048356839742],\n",
       " [7, [994], 0.00036246499038756054],\n",
       " [9,\n",
       "  [14,\n",
       "   33,\n",
       "   95,\n",
       "   109,\n",
       "   158,\n",
       "   255,\n",
       "   258,\n",
       "   493,\n",
       "   605,\n",
       "   616,\n",
       "   741,\n",
       "   1287,\n",
       "   1344,\n",
       "   1469,\n",
       "   1601,\n",
       "   1701,\n",
       "   1778,\n",
       "   1841,\n",
       "   1850,\n",
       "   1877,\n",
       "   2061],\n",
       "  0.006318873964939426],\n",
       " [10,\n",
       "  [2,\n",
       "   10,\n",
       "   14,\n",
       "   70,\n",
       "   115,\n",
       "   274,\n",
       "   523,\n",
       "   696,\n",
       "   2770,\n",
       "   4180,\n",
       "   4252,\n",
       "   4825,\n",
       "   5102,\n",
       "   5336,\n",
       "   5883,\n",
       "   5894,\n",
       "   5920,\n",
       "   6220,\n",
       "   6261,\n",
       "   6806],\n",
       "  0.001873472292249852],\n",
       " [11,\n",
       "  [92, 195, 274, 831, 1683, 2042, 2291, 2367, 2413, 2798],\n",
       "  0.0021743128577707232],\n",
       " [12, [1163, 2809], 0.00032972738397032074],\n",
       " [13, [29], 0.000812759750893632],\n",
       " [14,\n",
       "  [1,\n",
       "   12,\n",
       "   22,\n",
       "   270,\n",
       "   374,\n",
       "   516,\n",
       "   600,\n",
       "   1503,\n",
       "   1525,\n",
       "   1989,\n",
       "   2506,\n",
       "   2817,\n",
       "   3592,\n",
       "   4420,\n",
       "   4594,\n",
       "   4610,\n",
       "   5289,\n",
       "   5455,\n",
       "   6304,\n",
       "   6364,\n",
       "   6535,\n",
       "   7104,\n",
       "   7108,\n",
       "   7369,\n",
       "   7398,\n",
       "   8360,\n",
       "   8763,\n",
       "   9362,\n",
       "   10062,\n",
       "   10078,\n",
       "   10496,\n",
       "   10689,\n",
       "   10701,\n",
       "   11111,\n",
       "   11576,\n",
       "   11653,\n",
       "   11825,\n",
       "   12601,\n",
       "   12781,\n",
       "   12936,\n",
       "   13576,\n",
       "   13753,\n",
       "   13761,\n",
       "   13804,\n",
       "   14176,\n",
       "   14340,\n",
       "   14415,\n",
       "   14442,\n",
       "   14777,\n",
       "   14827,\n",
       "   14938,\n",
       "   14943,\n",
       "   14977,\n",
       "   15069,\n",
       "   15606,\n",
       "   15698,\n",
       "   15740,\n",
       "   16259,\n",
       "   16344,\n",
       "   16460,\n",
       "   16579,\n",
       "   16615,\n",
       "   16682,\n",
       "   16988,\n",
       "   17016,\n",
       "   17596,\n",
       "   17657,\n",
       "   17662,\n",
       "   17768,\n",
       "   18126,\n",
       "   18143,\n",
       "   18211,\n",
       "   18560,\n",
       "   18777,\n",
       "   18835,\n",
       "   18916,\n",
       "   19104,\n",
       "   19154,\n",
       "   19379],\n",
       "  0.0026797289794992457],\n",
       " [17, [769], 0.0007551699171160261],\n",
       " [18, [22, 46, 97, 311], 0.00808285844007979],\n",
       " [19,\n",
       "  [2,\n",
       "   44,\n",
       "   172,\n",
       "   178,\n",
       "   254,\n",
       "   317,\n",
       "   700,\n",
       "   1659,\n",
       "   1822,\n",
       "   2194,\n",
       "   2244,\n",
       "   2377,\n",
       "   2499,\n",
       "   2519,\n",
       "   2573,\n",
       "   2616,\n",
       "   3191,\n",
       "   3659,\n",
       "   3892,\n",
       "   4007,\n",
       "   4018,\n",
       "   4031,\n",
       "   4118,\n",
       "   4154,\n",
       "   4277,\n",
       "   4526,\n",
       "   4534,\n",
       "   4778,\n",
       "   5289,\n",
       "   5404,\n",
       "   5441,\n",
       "   5521,\n",
       "   5565,\n",
       "   5599,\n",
       "   5609,\n",
       "   5748,\n",
       "   5840,\n",
       "   5844,\n",
       "   6025,\n",
       "   6152,\n",
       "   6180,\n",
       "   6539,\n",
       "   6940,\n",
       "   6947,\n",
       "   7116,\n",
       "   7617,\n",
       "   8522,\n",
       "   8595,\n",
       "   8791,\n",
       "   8883,\n",
       "   8923,\n",
       "   8951,\n",
       "   9154,\n",
       "   9204,\n",
       "   9364,\n",
       "   9488,\n",
       "   9497,\n",
       "   9608,\n",
       "   9610],\n",
       "  0.004022041367080867],\n",
       " [20, [1224, 1254, 1257], 0.00055171751528794],\n",
       " [22, [35], 0.00167709055197087],\n",
       " [23, [230, 239], 0.0009731571096856007],\n",
       " [26, [6, 111, 176, 183], 0.00040334117349398614]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the index creates a dic with each word as a KEY and a list of doc indexs, word positions, and td-idf score as VALUES\n",
    "worddic['networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickel (save) the dictonary to avoid re-calculating\n",
    "np.save('worddic_1000.npy', worddic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['internet', '2009']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create word search which takes multiple words and finds documents that contain both along with metrics for ranking:\n",
    "\n",
    "    ## (1) Number of occruances of search words \n",
    "    ## (2) TD-IDF score for search words \n",
    "    ## (3) Percentage of search terms\n",
    "    ## (4) Word ordering score \n",
    "    ## (5) Exact match bonus \n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def search(searchsentence):\n",
    "    try:\n",
    "        # split sentence into individual words \n",
    "        searchsentence = searchsentence.lower()\n",
    "        try:\n",
    "            words = searchsentence.split(' ')\n",
    "        except:\n",
    "            words = list(words)\n",
    "        enddic = {}\n",
    "        idfdic = {}\n",
    "        closedic = {}\n",
    "        \n",
    "        # remove words if not in worddic \n",
    "        realwords = []\n",
    "        for word in words:\n",
    "            if word in list(worddic.keys()):\n",
    "                realwords.append(word)  \n",
    "        words = realwords\n",
    "        numwords = len(words)\n",
    "        \n",
    "        # make metric of number of occurances of all words in each doc & largest total IDF \n",
    "        for word in words:\n",
    "            for indpos in worddic[word]:\n",
    "                index = indpos[0]\n",
    "                amount = len(indpos[1])\n",
    "                idfscore = indpos[2]\n",
    "                enddic[index] = amount\n",
    "                idfdic[index] = idfscore\n",
    "                fullcount_order = sorted(enddic.items(), key=lambda x:x[1], reverse=True)\n",
    "                fullidf_order = sorted(idfdic.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "                \n",
    "        # make metric of what percentage of words appear in each doc\n",
    "        combo = []\n",
    "        alloptions = {k: worddic.get(k, None) for k in (words)}\n",
    "        for worddex in list(alloptions.values()):\n",
    "            for indexpos in worddex:\n",
    "                for indexz in indexpos:\n",
    "                    combo.append(indexz)\n",
    "        comboindex = combo[::3]\n",
    "        combocount = Counter(comboindex)\n",
    "        for key in combocount:\n",
    "            combocount[key] = combocount[key] / numwords\n",
    "        combocount_order = sorted(combocount.items(), key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "        # make metric for if words appear in same order as in search\n",
    "        if len(words) > 1:\n",
    "            x = []\n",
    "            y = []\n",
    "            for record in [worddic[z] for z in words]:\n",
    "                for index in record:\n",
    "                     x.append(index[0])\n",
    "            for i in x:\n",
    "                if x.count(i) > 1:\n",
    "                    y.append(i)\n",
    "            y = list(set(y))\n",
    "\n",
    "            closedic = {}\n",
    "            for wordbig in [worddic[x] for x in words]:\n",
    "                for record in wordbig:\n",
    "                    if record[0] in y:\n",
    "                        index = record[0]\n",
    "                        positions = record[1]\n",
    "                        try:\n",
    "                            closedic[index].append(positions)\n",
    "                        except:\n",
    "                            closedic[index] = []\n",
    "                            closedic[index].append(positions)\n",
    "\n",
    "            x = 0\n",
    "            fdic = {}\n",
    "            for index in y:\n",
    "                csum = []\n",
    "                for seqlist in closedic[index]:\n",
    "                    while x > 0:\n",
    "                        secondlist = seqlist\n",
    "                        x = 0\n",
    "                        sol = [1 for i in firstlist if i + 1 in secondlist]\n",
    "                        csum.append(sol)\n",
    "                        fsum = [item for sublist in csum for item in sublist]\n",
    "                        fsum = sum(fsum)\n",
    "                        fdic[index] = fsum\n",
    "                        fdic_order = sorted(fdic.items(), key=lambda x:x[1], reverse=True)\n",
    "                    while x == 0:\n",
    "                        firstlist = seqlist\n",
    "                        x = x + 1\n",
    "        else:\n",
    "            fdic_order = 0\n",
    "                    \n",
    "        # also the one above should be given a big boost if ALL found together \n",
    "           \n",
    "        \n",
    "        #could make another metric for if they are not next to each other but still close \n",
    "        \n",
    "        \n",
    "        return(searchsentence,words,fullcount_order,combocount_order,fullidf_order,fdic_order)\n",
    "    \n",
    "    except:\n",
    "        return(\"\")\n",
    "\n",
    "\n",
    "search('the internet in 2009')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 return will give back the search term, the rest will give back metrics (see above)\n",
    "\n",
    "search('the internet in 2009')[1][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the internet in 2009</td>\n",
       "      <td>[internet, 2009]</td>\n",
       "      <td>[(15, 20), (14, 15), (1, 10), (2, 9), (16, 8),...</td>\n",
       "      <td>[(1, 1.0), (2, 1.0), (4, 1.0), (5, 1.0), (7, 1...</td>\n",
       "      <td>[(15, 0.02120674148654315), (16, 0.00775690437...</td>\n",
       "      <td>[(4, 2), (15, 2), (16, 1), (1, 0), (2, 0), (5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bitcoin is a digital currency technology</td>\n",
       "      <td>[bitcoin, digital, currency, technology]</td>\n",
       "      <td>[(7, 21), (5, 18), (27, 13), (0, 13), (6, 10),...</td>\n",
       "      <td>[(1, 1.0), (2, 1.0), (4, 1.0), (5, 1.0), (7, 1...</td>\n",
       "      <td>[(6, 0.02270699922599735), (27, 0.021054063252...</td>\n",
       "      <td>[(1, 6), (2, 6), (28, 5), (4, 3), (12, 3), (30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anonymous person or group known as satoshi nak...</td>\n",
       "      <td>[anonymous, person, group, known, satoshi, nak...</td>\n",
       "      <td>[(30, 62), (28, 28), (3, 19), (2, 17), (1, 5),...</td>\n",
       "      <td>[(1, 1.0), (2, 1.0), (4, 1.0), (5, 1.0), (12, ...</td>\n",
       "      <td>[(30, 0.036163551027759054), (28, 0.0334226748...</td>\n",
       "      <td>[(28, 19), (2, 12), (30, 12), (3, 8), (1, 7), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the \"neocognitron\"[7] was introduced by kunihi...</td>\n",
       "      <td>[introduced, kunihiko, fukushima, 1980]</td>\n",
       "      <td>[(22, 6), (2, 3), (7, 2), (14, 2), (21, 2), (2...</td>\n",
       "      <td>[(9, 1.0), (21, 1.0), (18, 0.75), (29, 0.75), ...</td>\n",
       "      <td>[(22, 0.024983184608193352), (18, 0.0050170105...</td>\n",
       "      <td>[(9, 3), (18, 3), (21, 2), (29, 2), (22, 1), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neocognitron, origin of the cnn architecture</td>\n",
       "      <td>[origin, cnn, architecture]</td>\n",
       "      <td>[(10, 28), (19, 11), (9, 9), (14, 9), (18, 3),...</td>\n",
       "      <td>[(9, 1.0), (12, 0.6666666666666666), (10, 0.66...</td>\n",
       "      <td>[(18, 0.0086995189760849), (29, 0.004087274001...</td>\n",
       "      <td>[(9, 3), (10, 1), (18, 1), (12, 0), (14, 0), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[pooling]</td>\n",
       "      <td>[(26, 92), (10, 35), (25, 26), (9, 14)]</td>\n",
       "      <td>[(9, 1.0), (10, 1.0), (25, 1.0), (26, 1.0)]</td>\n",
       "      <td>[(25, 0.07080571909764763), (26, 0.02871326546...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blockchain</td>\n",
       "      <td>[blockchain]</td>\n",
       "      <td>[(5, 154), (7, 78), (2, 38), (27, 22), (12, 17...</td>\n",
       "      <td>[(1, 1.0), (2, 1.0), (3, 1.0), (4, 1.0), (5, 1...</td>\n",
       "      <td>[(27, 0.046818421723372826), (6, 0.04177238751...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>convolutional layer</td>\n",
       "      <td>[convolutional, layer]</td>\n",
       "      <td>[(10, 124), (21, 50), (26, 36), (9, 33), (25, ...</td>\n",
       "      <td>[(9, 1.0), (10, 1.0), (14, 1.0), (19, 1.0), (2...</td>\n",
       "      <td>[(10, 0.019870984375332308), (9, 0.01698692448...</td>\n",
       "      <td>[(26, 10), (9, 8), (10, 8), (14, 0), (19, 0)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         search term  \\\n",
       "0                               the internet in 2009   \n",
       "1           bitcoin is a digital currency technology   \n",
       "2  anonymous person or group known as satoshi nak...   \n",
       "3  the \"neocognitron\"[7] was introduced by kunihi...   \n",
       "4       neocognitron, origin of the cnn architecture   \n",
       "5                                            pooling   \n",
       "6                                         blockchain   \n",
       "7                                convolutional layer   \n",
       "\n",
       "                               actual_words_searched  \\\n",
       "0                                   [internet, 2009]   \n",
       "1           [bitcoin, digital, currency, technology]   \n",
       "2  [anonymous, person, group, known, satoshi, nak...   \n",
       "3            [introduced, kunihiko, fukushima, 1980]   \n",
       "4                        [origin, cnn, architecture]   \n",
       "5                                          [pooling]   \n",
       "6                                       [blockchain]   \n",
       "7                             [convolutional, layer]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(15, 20), (14, 15), (1, 10), (2, 9), (16, 8),...   \n",
       "1  [(7, 21), (5, 18), (27, 13), (0, 13), (6, 10),...   \n",
       "2  [(30, 62), (28, 28), (3, 19), (2, 17), (1, 5),...   \n",
       "3  [(22, 6), (2, 3), (7, 2), (14, 2), (21, 2), (2...   \n",
       "4  [(10, 28), (19, 11), (9, 9), (14, 9), (18, 3),...   \n",
       "5            [(26, 92), (10, 35), (25, 26), (9, 14)]   \n",
       "6  [(5, 154), (7, 78), (2, 38), (27, 22), (12, 17...   \n",
       "7  [(10, 124), (21, 50), (26, 36), (9, 33), (25, ...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(1, 1.0), (2, 1.0), (4, 1.0), (5, 1.0), (7, 1...   \n",
       "1  [(1, 1.0), (2, 1.0), (4, 1.0), (5, 1.0), (7, 1...   \n",
       "2  [(1, 1.0), (2, 1.0), (4, 1.0), (5, 1.0), (12, ...   \n",
       "3  [(9, 1.0), (21, 1.0), (18, 0.75), (29, 0.75), ...   \n",
       "4  [(9, 1.0), (12, 0.6666666666666666), (10, 0.66...   \n",
       "5        [(9, 1.0), (10, 1.0), (25, 1.0), (26, 1.0)]   \n",
       "6  [(1, 1.0), (2, 1.0), (3, 1.0), (4, 1.0), (5, 1...   \n",
       "7  [(9, 1.0), (10, 1.0), (14, 1.0), (19, 1.0), (2...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(15, 0.02120674148654315), (16, 0.00775690437...   \n",
       "1  [(6, 0.02270699922599735), (27, 0.021054063252...   \n",
       "2  [(30, 0.036163551027759054), (28, 0.0334226748...   \n",
       "3  [(22, 0.024983184608193352), (18, 0.0050170105...   \n",
       "4  [(18, 0.0086995189760849), (29, 0.004087274001...   \n",
       "5  [(25, 0.07080571909764763), (26, 0.02871326546...   \n",
       "6  [(27, 0.046818421723372826), (6, 0.04177238751...   \n",
       "7  [(10, 0.019870984375332308), (9, 0.01698692448...   \n",
       "\n",
       "                                          word_order  \n",
       "0  [(4, 2), (15, 2), (16, 1), (1, 0), (2, 0), (5,...  \n",
       "1  [(1, 6), (2, 6), (28, 5), (4, 3), (12, 3), (30...  \n",
       "2  [(28, 19), (2, 12), (30, 12), (3, 8), (1, 7), ...  \n",
       "3  [(9, 3), (18, 3), (21, 2), (29, 2), (22, 1), (...  \n",
       "4  [(9, 3), (10, 1), (18, 1), (12, 0), (14, 0), (...  \n",
       "5                                                  0  \n",
       "6                                                  0  \n",
       "7      [(26, 10), (9, 8), (10, 8), (14, 0), (19, 0)]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save metrics to dataframe for use in ranking and machine learning \n",
    "result1 = search('the internet in 2009')\n",
    "result2 = search('Bitcoin is a digital currency technology')\n",
    "result3 = search('anonymous person or group known as Satoshi Nakamoto')\n",
    "result4 = search('The \"neocognitron\"[7] was introduced by Kunihiko Fukushima in 1980')\n",
    "result5 = search('Neocognitron, origin of the CNN architecture')\n",
    "result6 = search('pooling')\n",
    "result7 = search('blockchain')\n",
    "result8 = search('Convolutional Layer')\n",
    "df = pd.DataFrame([result1,result2,result3,result4,result5,result6,result7,result8])\n",
    "df.columns = ['search term', 'actual_words_searched','num_occur','percentage_of_terms','td-idf','word_order']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is Bitcoin?\\nBitcoin is a digital currency created in January 2009 following the housing market crash. It follows the ideas set out in a whitepaper by the mysterious and pseudonymous Satoshi Nakamoto. The identity of the person or persons who created the technology is still a mystery. Bitcoin offers the promise of lower transaction fees than traditional online payment mechanisms and is operated by a decentralized authority, unlike government-issued currencies.\\n\\n\\nThere are no physical bitcoins, only balances kept on a public ledger that everyone has transparent access to, that \\x96 along with all Bitcoin transactions \\x96 is verified by a massive amount of computing power. Bitcoins are not issued or backed by any banks or governments, nor are individual bitcoins valuable as a commodity. Despite it not being legal tender, Bitcoin charts high on popularity, and has triggered the launch of hundreds of other virtual currencies collectively referred to as Altcoins.\\n\\n\\n1:57\\nWhat Is Bitcoin\\n\\nKEY TAKEAWAYS\\nLaunched in 2009, Bitcoin is the world\\'s largest cryptocurrency by market cap.\\nUnlike fiat currency, Bitcoin is created, distributed, traded, and stored with the use of a decentralized ledger system known as a blockchain.\\nBitcoin\\'s history as a store of value has been turbulent; the cryptocurrency skyrocketed up to roughly $20,000 per coin in 2017, but as of two years later, is currency trading for less than half of that.\\nAs the earliest cryptocurrency to meet widespread popularity and success, Bitcoin has inspired a host of other projects in the blockchain space.\\nUnderstanding Bitcoin\\nBitcoin is a collection of computers, or nodes, that all run Bitcoin\\'s code and store its blockchain. A blockchain can be thought of as a collection of blocks. In each block is a collection of transactions. Because all these computers running the blockchain have the same list of blocks and transactions and can transparently see these new blocks being filled with new Bitcoin transactions, no one can cheat the system. Anyone, whether they run a Bitcoin \"node\" or not, can see these transactions occurring live. In order to achieve a nefarious act, a bad actor would need to operate 51% of the computing power that makes up Bitcoin. Bitcoin currently has over 10,000 nodes and this number is growing, making such an attack quite unlikely.\\n\\nIn the event that an attack was to happen, the Bitcoin nodes, or the people who take part in the Bitcoin network with their computer, would likely fork to a new blockchain making the effort the bad actor put forth to achieve the attack a waste.\\n\\n\\nBitcoin is a type of cryptocurrency. Balances of Bitcoin tokens are kept using public and private \"keys,\" which are long strings of numbers and letters linked through the mathematical encryption algorithm that was used to create them. The public key (comparable to a bank account number) serves as the address which is published to the world and to which others may send bitcoins. The private key (comparable to an ATM PIN) is meant to be a guarded secret and only used to authorize Bitcoin transmissions. Bitcoin keys should not be confused with a Bitcoin wallet, which is a physical or digital device which facilitates the trading of Bitcoin and allows users to track ownership of coins. The term \"wallet\" is a bit misleading, as Bitcoin\\'s decentralized nature means that it is never stored \"in\" a wallet, but rather decentrally on a blockchain.\\n\\n\\nStyle notes: according to the official Bitcoin Foundation, the word \"Bitcoin\" is capitalized in the context of referring to the entity or concept, whereas \"bitcoin\" is written in the lower case when referring to a quantity of the currency (e.g. \"I traded 20 bitcoin\") or the units themselves. The plural form can be either \"bitcoin\" or \"bitcoins.\" Bitcoin is also commonly abbreviated as \"BTC.\"\\n\\nHow Bitcoin Works\\nBitcoin is one of the first digital currencies to use peer-to-peer technology to facilitate instant payments. The independent individuals and companies who own the governing computing power and participate in the Bitcoin network, are comprised of nodes or miners. \"Miners,\" or the people who process the transactions on the blockchain, are motivated by rewards (the release of new bitcoin) and transaction fees paid in bitcoin. These miners can be thought of as the decentralized authority enforcing the credibility of the Bitcoin network. New bitcoin is being released to the miners at a fixed, but periodically declining rate, such that the total supply of bitcoins approaches 21 million. Currently, there are roughly 3 million bitcoins which have yet to be mined. In this way, Bitcoin (and any cryptocurrency generated through a similar process) operates differently from fiat currency; in centralized banking systems, currency is released at a rate matching the growth in goods in an attempt to maintain price stability, while a decentralized system like Bitcoin sets the release rate ahead of time and according to an algorithm.\\n\\nBitcoin mining is the process by which bitcoins are released into circulation. Generally, mining requires the solving of computationally difficult puzzles in order to discover a new block, which is added to the blockchain. In contributing to the blockchain, mining adds and verifies transaction records across the network. For adding blocks to the blockchain, miners receive a reward in the form of a few bitcoins; the reward is halved every 210,000 blocks. The block reward was 50 new bitcoins in 2009 and is currently 12.5. By around May 11th, 2020 the next halving will occur, bringing the reward for each block discovery down to 6.25 bitcoins. A variety of hardware can be used to mine bitcoin but some yield higher rewards than others. Certain computer chips called Application-Specific Integrated Circuits (ASIC) and more advanced processing units like Graphic Processing Units (GPUs) can achieve more rewards. These elaborate mining processors are known as \"mining rigs.\"\\n\\nOne bitcoin is divisible to eight decimal places (100 millionths of one bitcoin), and this smallest unit is referred to as a Satoshi. If necessary, and if the participating miners accept the change, Bitcoin could eventually be made divisible to even more decimal places.\\n\\nHow Bitcoin Began\\nAug. 18, 2008: The domain name bitcoin.org is registered. Today, at least, this domain is \"WhoisGuard Protected,\" meaning the identity of the person who registered it is not public information.\\n\\nOct. 31, 2008: A person or group using the name Satoshi Nakamoto makes an announcement on The Cryptography Mailing list at metzdowd.com: \"I\\'ve been working on a new electronic cash system that\\'s fully peer-to-peer, with no trusted third party. The paper is available at http://www.bitcoin.org/bitcoin.pdf.\" This link leads to the now-famous whitepaper published on bitcoin.org entitled \"Bitcoin: A Peer-to-Peer Electronic Cash System.\" This paper would become the Magna Carta for how Bitcoin operates today.\\n\\nJan. 3, 2009: The first Bitcoin block is mined, Block 0. This is also known as the \"genesis block\" and contains the text: \"The Times 03/Jan/2009 Chancellor on brink of second bailout for banks,\" perhaps as proof that the block was mined on or after that date, and perhaps also as relevant political commentary.\\n\\nJan. 8, 2009: The first version of the Bitcoin software is announced on The Cryptography Mailing list.\\n\\nJan. 9, 2009: Block 1 is mined, and Bitcoin mining commences in earnest.\\n\\nWho Invented Bitcoin?\\nNo one knows who invented Bitcoin, or at least not conclusively. Satoshi Nakamoto is the name associated with the person or group of people who released the original Bitcoin white paper in 2008 and worked on the original Bitcoin software that was released in 2009. In the years since that time, many individuals have either claimed to be or have been suggested as the real-life people behind the pseudonym, but as of May 2020, the true identity (or identities) behind Satoshi remains obscured.\\n\\nBefore Satoshi\\nThough it is tempting to believe the media\\'s spin that Satoshi Nakamoto is a solitary, quixotic genius who created Bitcoin out of thin air, such innovations do not typically happen in a vacuum. All major scientific discoveries, no matter how original-seeming, were built on previously existing research. There are precursors to Bitcoin: Adam Back\\x92s Hashcash, invented in 1997, and subsequently Wei Dai\\x92s b-money, Nick Szabo\\x92s bit gold and Hal Finney\\x92s Reusable Proof of Work. The Bitcoin whitepaper itself cites Hashcash and b-money, as well as various other works spanning several research fields. Perhaps unsurprisingly, many of the individuals behind the other projects named above have been speculated to have also had a part in creating Bitcoin.\\n\\nWhy Is Satoshi Anonymous?\\nThere are a few motivations for Bitcoin\\'s inventor keeping his or her or their identity secret. One is privacy. As Bitcoin has gained in popularity \\x96 becoming something of a worldwide phenomenon \\x96 Satoshi Nakamoto would likely garner a lot of attention from the media and from governments.\\n\\nAnother reason could be the potential for Bitcoin to cause major disruption of the current banking and monetary systems. If Bitcoin were to gain mass adoption, the system could surpass nations\\' sovereign fiat currencies. This threat to existing currency could motivate governments to want to take legal action against Bitcoin\\'s creator.\\n\\nThe other reason is safety. Looking at 2009 alone, 32,489 blocks were mined; at the then-reward rate of 50 BTC per block, the total payout in 2009 was 1,624,500 BTC, which is worth $13.9 billion as of October 25, 2019. One may conclude that only Satoshi and perhaps a few other people were mining through 2009 and that they possess a majority of that stash of BTC. Someone in possession of that much Bitcoin could become a target of criminals, especially since bitcoins are less like stocks and more like cash, where the private keys needed to authorize spending could be printed out and literally kept under a mattress. While it\\'s likely the inventor of Bitcoin would take precautions to make any extortion-induced transfers traceable, remaining anonymous is a good way for Satoshi to limit exposure.\\n\\nReceiving Bitcoins As Payment\\nBitcoins can be accepted as a means of payment for products sold or services provided. If you have a brick and mortar store, just display a sign saying \\x93Bitcoin Accepted Here\\x94 and many of your customers may well take you up on it; the transactions can be handled with the requisite hardware terminal or wallet address through QR codes and touch screen apps. An online business can easily accept bitcoins by just adding this payment option to the others it offers credit cards, PayPal, etc.\\n\\nWorking For Bitcoins\\nThose who are self-employed can get paid for a job in bitcoins. There are a number of ways to achieve this such as creating any internet service and adding your bitcoin wallet address to the site as a form of payment. There are several websites/job boards which are dedicated to the digital currency:\\n\\nCryptogrind brings together work seekers and prospective employers through its website\\nCoinality features jobs \\x96 freelance, part-time and full-time \\x96 that offer payment in bitcoins, as well as other cryptocurrencies like Dogecoin and Litecoin\\nJobs4Bitcoins, part of reddit.com\\nBitGigs\\nBitwage offers a way to choose a percentage of your work paycheck to be converted into bitcoin and sent to your bitcoin address\\n4:24\\nHow to Buy Bitcoin\\nInvesting in Bitcoins\\nThere are many Bitcoin supporters who believe that digital currency is the future. Many of those who endorse Bitcoin believe that it facilitates a much faster, low-fee payment system for transactions across the globe. Although it is not backed by any government or central bank, bitcoin can be exchanged for traditional currencies; in fact, its exchange rate against the dollar attracts potential investors and traders interested in currency plays. Indeed, one of the primary reasons for the growth of digital currencies like Bitcoin is that they can act as an alternative to national fiat money and traditional commodities like gold.\\n\\nIn March 2014, the IRS stated that all virtual currencies, including bitcoins, would be taxed as property rather than currency. Gains or losses from bitcoins held as capital will be realized as capital gains or losses, while bitcoins held as inventory will incur ordinary gains or losses. The sale of bitcoins that you mined or purchased from another party, or the use of bitcoins to pay for goods or services are examples of transactions which can be taxed.\\n\\nLike any other asset, the principle of buying low and selling high applies to bitcoins. The most popular way of amassing the currency is through buying on a Bitcoin exchange, but there are many other ways to earn and own bitcoins.\\n\\nRisks of Bitcoin Investing\\nThough Bitcoin was not designed as a normal equity investment (no shares have been issued), some speculative investors were drawn to the digital money after it appreciated rapidly in May 2011 and again in November 2013. Thus, many people purchase bitcoin for its investment value rather than as a medium of exchange.\\n\\nHowever, their lack of guaranteed value and digital nature means the purchase and use of bitcoins carries several inherent risks. Many investor alerts have been issued by the Securities and Exchange Commission (SEC), the Financial Industry Regulatory Authority (FINRA), the Consumer Financial Protection Bureau (CFPB), and other agencies.\\n\\nThe concept of a virtual currency is still novel and, compared to traditional investments, Bitcoin doesn\\'t have much of a long-term track record or history of credibility to back it. With their increasing popularity, bitcoins are becoming less experimental every day; still, after 10 years, they (like all digital currencies) remain in a development phase and are consistently evolving. \"It is pretty much the highest-risk, highest-return investment that you can possibly make,\\x94 says Barry Silbert, CEO of Digital Currency Group, which builds and invests in Bitcoin and blockchain companies.\\n\\nBitcoin Regulatory Risk\\nInvesting money into Bitcoin in any of its many guises is not for the risk-averse. Bitcoins are a rival to government currency and may be used for black market transactions, money laundering, illegal activities or tax evasion. As a result, governments may seek to regulate, restrict or ban the use and sale of bitcoins, and some already have. Others are coming up with various rules. For example, in 2015, the New York State Department of Financial Services finalized regulations that would require companies dealing with the buy, sell, transfer or storage of bitcoins to record the identity of customers, have a compliance officer and maintain capital reserves. The transactions worth $10,000 or more will have to be recorded and reported.\\n\\nThe lack of uniform regulations about bitcoins (and other virtual currency) raises questions over their longevity, liquidity, and universality.\\n\\nSecurity Risk of Bitcoins\\nMost individuals who own and use Bitcoin have not acquired their tokens through mining operations. Rather, they buy and sell Bitcoin and other digital currencies on any of a number of popular online markets known as Bitcoin exchanges. Bitcoin exchanges are entirely digital and, as with any virtual system, are at risk from hackers, malware, and operational glitches. If a thief gains access to a Bitcoin owner\\'s computer hard drive and steals his private encryption key, he could transfer the stolen Bitcoins to another account. (Users can prevent this only if bitcoins are stored on a computer which is not connected to the internet, or else by choosing to use a paper wallet \\x96 printing out the Bitcoin private keys and addresses, and not keeping them on a computer at all.) Hackers can also target Bitcoin exchanges, gaining access to thousands of accounts and digital wallets where bitcoins are stored. One especially notorious hacking incident took place in 2014, when Mt. Gox, a Bitcoin exchange in Japan, was forced to close down after millions of dollars worth of bitcoins were stolen.\\n\\nThis is particularly problematic once you remember that all Bitcoin transactions are permanent and irreversible. It\\'s like dealing with cash: Any transaction carried out with bitcoins can only be reversed if the person who has received them refunds them. There is no third party or a payment processor, as in the case of a debit or credit card \\x96 hence, no source of protection or appeal if there is a problem.\\n\\nInsurance Risk\\nSome investments are insured through the Securities Investor Protection Corporation. Normal bank accounts are insured through the Federal Deposit Insurance Corporation (FDIC) up to a certain amount depending on the jurisdiction. Generally speaking, Bitcoin exchanges and Bitcoin accounts are not insured by any type of federal or government program. In 2019, prime dealer and trading platform SFOX announced it would be able to provide Bitcoin investors with FDIC insurance, but only for the portion of transactions involving cash.\\n\\nRisk of Bitcoin Fraud\\nWhile Bitcoin uses private key encryption to verify owners and register transactions, fraudsters and scammers may attempt to sell false bitcoins. For instance, in July 2013, the SEC brought legal action against an operator of a Bitcoin-related Ponzi scheme. There have also been documented cases of Bitcoin price manipulation, another common form of fraud.\\n\\nMarket Risk\\nLike with any investment, Bitcoin values can fluctuate. Indeed, the value of the currency has seen wild swings in price over its short existence. Subject to high volume buying and selling on exchanges, it has a high sensitivity to \\x93news.\" According to the CFPB, the price of bitcoins fell by 61% in a single day in 2013, while the one-day price drop record in 2014 was as big as 80%.\\n\\nIf fewer people begin to accept Bitcoin as a currency, these digital units may lose value and could become worthless. Indeed, there was speculation that the \"Bitcoin bubble\" had burst when the price declined from its all-time high during the cryptocurrency rush in late 2017 and early 2018. There is already plenty of competition, and though Bitcoin has a huge lead over the hundreds of other digital currencies that have sprung up, thanks to its brand recognition and venture capital money, a technological break-through in the form of a better virtual coin is always a threat.\\n\\nBitcoin\\'s Tax Risk\\nAs bitcoin is ineligible to be included in any tax-advantaged retirement accounts, there are no good, legal options to shield investments from taxation.\\n\\nBitcoin Forks\\nIn the years since Bitcoin launched, there have been numerous instances in which disagreements between factions of miners and developers prompted large-scale splits of the cryptocurrency community. In some of these cases, groups of Bitcoin users and miners have changed the protocol of the Bitcoin network itself. This process is known \"forking\" and usually results in the creation of a new type of Bitcoin with a new name. This split can be a \"hard fork,\" in which a new coin shares transaction history with Bitcoin up until a decisive split point, at which point a new token is created. Examples of cryptocurrencies that have been created as a result of hard forks include Bitcoin Cash (created in August 2017), Bitcoin Gold (created in October 2017) and Bitcoin SV (created in November 2017). A \"soft fork\" is a change to protocol which is still compatible with the previous system rules. Bitcoin soft forks have increased the total size of blocks, as an example.\\n\\nCompete Risk Free with $100,000 in Virtual Cash\\nPut your trading skills to the test with our FREE Stock Simulator. Compete with thousands of Investopedia traders and trade your way to the top! Submit trades in a virtual environment before you start risking your own money. Practice trading strategies so that when you\\'re ready to enter the real market, you\\'ve had the practice you need. Try our Stock Simulator today >>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look to see if the top documents seem to make sense\n",
    "\n",
    "alldocslist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple (non-machine learning) rank and return function\n",
    "\n",
    "def rank(term):\n",
    "    results = search(term)\n",
    "\n",
    "    # get metrics \n",
    "    num_score = results[2]\n",
    "    per_score = results[3]\n",
    "    tfscore = results[4]\n",
    "    order_score = results[5]\n",
    "    final_candidates = []\n",
    "\n",
    "    # rule1: if high word order score & 100% percentage terms then put at top position\n",
    "    try:\n",
    "        first_candidates = []\n",
    "\n",
    "        for candidates in order_score:\n",
    "            if candidates[1] > 1:\n",
    "                first_candidates.append(candidates[0])\n",
    "\n",
    "        second_candidates = []\n",
    "\n",
    "        for match_candidates in per_score:\n",
    "            if match_candidates[1] == 1:\n",
    "                second_candidates.append(match_candidates[0])\n",
    "            if match_candidates[1] == 1 and match_candidates[0] in first_candidates:\n",
    "                final_candidates.append(match_candidates[0])\n",
    "\n",
    "    # rule2: next add other word order score which are greater than 1 \n",
    "\n",
    "        t3_order = first_candidates[0:3]\n",
    "        for each in t3_order:\n",
    "            if each not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),each)\n",
    "\n",
    "    # rule3: next add top td-idf results\n",
    "        final_candidates.insert(len(final_candidates),tfscore[0][0])\n",
    "        final_candidates.insert(len(final_candidates),tfscore[1][0])\n",
    "\n",
    "    # rule4: next add other high percentage score \n",
    "        t3_per = second_candidates[0:3]\n",
    "        for each in t3_per:\n",
    "            if each not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),each)\n",
    "\n",
    "    #rule5: next add any other top results for metrics\n",
    "        othertops = [num_score[0][0],per_score[0][0],tfscore[0][0],order_score[0][0]]\n",
    "        for top in othertops:\n",
    "            if top not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),top)\n",
    "                \n",
    "    # unless single term searched, in which case just return \n",
    "    except:\n",
    "        othertops = [num_score[0][0],num_score[1][0],num_score[2][0],per_score[0][0],tfscore[0][0]]\n",
    "        for top in othertops:\n",
    "            if top not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),top)\n",
    "\n",
    "    for index, results in enumerate(final_candidates):\n",
    "        if index < 5:\n",
    "            print(\"RESULT\", index + 1, \": File Name : \",alldocslist[results][0].upper(),'\\n\\n',alldocslist[results][1:100],\"...\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(21, 26), (29, 8), (14, 5), (22, 2), (11, 2), (0, 1), (9, 1), (10, 1), (19, 1)]\n",
      "[(0, 1.0), (9, 1.0), (10, 1.0), (14, 1.0), (21, 1.0), (22, 1.0), (19, 0.5), (29, 0.5), (11, 0.5)]\n",
      "[(29, 0.015555131533389407), (21, 0.0075700914785360035), (22, 0.007546444179891611), (11, 0.0009783807196042432), (9, 0.0006769806481961054), (14, 0.0003815835481105358), (0, 0.0003458128642564893), (10, 0.00021075269399470478), (19, 0.00013961585096511695)]\n",
      "[(9, 1), (0, 0), (10, 0), (14, 0), (21, 0), (22, 0)]\n",
      "RESULT 1 : Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffect ...\n",
      "RESULT 2 : Biol. Cybernetics 36, 193 202 (1980) Biological\n",
      "Cybernetics\n",
      "\u000e9 by Springer-Verlag 1980\n",
      "Neocognitron: ...\n",
      "RESULT 3 : UREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\n",
      "International Journal of Research in Engineer ...\n",
      "RESULT 4 : In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural network ...\n",
      "RESULT 5 : Convolutional Neural Networks (CNNs / ConvNets)\n",
      "Convolutional Neural Networks are very similar to or ...\n"
     ]
    }
   ],
   "source": [
    "# example of output \n",
    "rank('visual cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(18, 3), (21, 2), (22, 2), (29, 2), (9, 1)]\n",
      "[(9, 1.0), (18, 1.0), (21, 1.0), (22, 1.0), (29, 1.0)]\n",
      "[(18, 0.01672065403108599), (22, 0.009251529387758237), (29, 0.005237216348817163), (9, 0.0008299413886103702), (21, 0.0007138861298035146)]\n",
      "0\n",
      "RESULT 1 : Kunihiko Fukushima\n",
      "From Wikipedia, the free encyclopedia\n",
      "Jump to navigationJump to search\n",
      "Kunihiko F ...\n",
      "RESULT 2 : Biol. Cybernetics 36, 193 202 (1980) Biological\n",
      "Cybernetics\n",
      "\u000e9 by Springer-Verlag 1980\n",
      "Neocognitron: ...\n",
      "RESULT 3 : Neocognitron\n",
      "From Wikipedia, the free encyclopedia\n",
      "Jump to navigationJump to search\n",
      "The neocognitron ...\n",
      "RESULT 4 : In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural network ...\n"
     ]
    }
   ],
   "source": [
    "# example of output \n",
    "rank('Kunihiko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pseudo-truth set using first 5 words \n",
    "# Because I don't have a turth set I will generate a pseudo one by pulling terms from the documents - this is far from perfect\n",
    "     # as it may not approximate well peoples actual queries but it will serve well to build the ML architecture \n",
    "\n",
    "df_truth = pd.DataFrame()\n",
    "\n",
    "for doc in plottest:\n",
    "    first_five = doc[0:5]\n",
    "    test_sentence = ' '.join(first_five)\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth= pd.concat([df_truth, df_temp])\n",
    "\n",
    "df_truth['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using random 3 word sequence from docs\n",
    "\n",
    "df_truth1 = pd.DataFrame()\n",
    "seqlen = 3\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth1= pd.concat([df_truth1, df_temp])\n",
    "\n",
    "df_truth1['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using different random 4 word sequence from docs\n",
    "\n",
    "df_truth2 = pd.DataFrame()\n",
    "seqlen = 4\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth2= pd.concat([df_truth2, df_temp])\n",
    "\n",
    "df_truth2['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using different random 2 word sequence from docs\n",
    "\n",
    "df_truth3 = pd.DataFrame()\n",
    "seqlen = 2\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth3= pd.concat([df_truth3, df_temp])\n",
    "\n",
    "df_truth3['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the truth sets and save to disk \n",
    "truth_set = pd.concat([df_truth,df_truth1,df_truth2,df_truth3])\n",
    "truth_set.columns = ['search term', 'actual_words_searched','num_occur','percentage_of_terms','td-idf','word_order','truth']\n",
    "truth_set.to_csv(\"truth_set_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ureas volume 6 , issue</td>\n",
       "      <td>[ureas, volume, 6, ,, issue]</td>\n",
       "      <td>[(26, 1142), (21, 458), (10, 436), (20, 284), ...</td>\n",
       "      <td>[(0, 1.0), (5, 0.8), (9, 0.6), (10, 0.6), (20,...</td>\n",
       "      <td>[(0, 0.003803941506821382), (24, 0.00115154880...</td>\n",
       "      <td>[(0, 41), (26, 12), (14, 6), (19, 4), (10, 3),...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin ? bitcoin digital currency</td>\n",
       "      <td>[bitcoin, ?, bitcoin, digital, currency]</td>\n",
       "      <td>[(22, 36), (12, 20), (1, 18), (2, 14), (14, 10...</td>\n",
       "      <td>[(1, 0.8), (2, 0.8), (3, 0.8), (5, 0.8), (7, 0...</td>\n",
       "      <td>[(22, 0.03129353076671049), (1, 0.008066363016...</td>\n",
       "      <td>[(1, 9), (2, 9), (28, 4), (12, 3), (4, 2), (30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin wikipedia , free encyclopedia</td>\n",
       "      <td>[bitcoin, wikipedia, ,, free, encyclopedia]</td>\n",
       "      <td>[(19, 1029), (21, 458), (10, 436), (11, 204), ...</td>\n",
       "      <td>[(2, 1.0), (12, 1.0), (30, 1.0), (5, 0.8), (18...</td>\n",
       "      <td>[(18, 0.005017010568617829), (22, 0.0041638641...</td>\n",
       "      <td>[(2, 4), (13, 4), (12, 3), (18, 3), (22, 3), (...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three people supposedly bitcoin founder</td>\n",
       "      <td>[three, people, supposedly, bitcoin, founder]</td>\n",
       "      <td>[(2, 287), (1, 114), (5, 42), (28, 29), (13, 1...</td>\n",
       "      <td>[(3, 1.0), (30, 1.0), (2, 0.6), (5, 0.6), (16,...</td>\n",
       "      <td>[(1, 0.039195067632697096), (2, 0.026616061100...</td>\n",
       "      <td>[(3, 4), (7, 1), (30, 1), (1, 0), (2, 0), (5, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first sight its pretty clear</td>\n",
       "      <td>[first, sight, its, pretty, clear]</td>\n",
       "      <td>[(2, 14), (12, 11), (21, 7), (17, 5), (24, 5),...</td>\n",
       "      <td>[(4, 1.0), (5, 0.6), (0, 0.4), (1, 0.4), (7, 0...</td>\n",
       "      <td>[(17, 0.009374642605360172), (4, 0.00528275736...</td>\n",
       "      <td>[(4, 4), (0, 0), (1, 0), (5, 0), (7, 0), (10, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>following banking , investing ,</td>\n",
       "      <td>[following, banking, ,, investing, ,]</td>\n",
       "      <td>[(14, 2418), (26, 1142), (19, 1029), (21, 458)...</td>\n",
       "      <td>[(1, 0.8), (5, 0.8), (2, 0.6), (12, 0.6), (0, ...</td>\n",
       "      <td>[(15, -6.601463130056997e-06), (6, -1.21918037...</td>\n",
       "      <td>[(14, 10), (29, 6), (5, 4), (21, 4), (25, 4), ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blockchain technology ? blockchain technology</td>\n",
       "      <td>[blockchain, technology, ?, blockchain, techno...</td>\n",
       "      <td>[(22, 36), (7, 21), (24, 21), (5, 18), (27, 13...</td>\n",
       "      <td>[(1, 0.6), (2, 0.6), (5, 0.6), (6, 0.6), (7, 0...</td>\n",
       "      <td>[(22, 0.03129353076671049), (6, 0.022706999225...</td>\n",
       "      <td>[(7, 25), (5, 19), (6, 19), (27, 18), (13, 4),...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21st century technology . increasing</td>\n",
       "      <td>[21st, century, technology, ., increasing]</td>\n",
       "      <td>[(19, 814), (21, 351), (12, 214), (11, 165), (...</td>\n",
       "      <td>[(7, 1.0), (0, 0.6), (1, 0.6), (2, 0.6), (4, 0...</td>\n",
       "      <td>[(4, 0.003276529307704397), (24, 0.00087560233...</td>\n",
       "      <td>[(7, 7), (24, 3), (6, 2), (1, 1), (2, 1), (18,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surely 's complicated ? yes</td>\n",
       "      <td>[surely, 's, complicated, ?, yes]</td>\n",
       "      <td>[(22, 36), (30, 31), (3, 23), (24, 21), (2, 20...</td>\n",
       "      <td>[(8, 1.0), (10, 0.6), (5, 0.6), (1, 0.4), (2, ...</td>\n",
       "      <td>[(22, 0.03129353076671049), (3, 0.010630603381...</td>\n",
       "      <td>[(8, 4), (3, 1), (1, 0), (2, 0), (5, 0), (6, 0...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep learning , convolutional neural</td>\n",
       "      <td>[deep, learning, ,, convolutional, neural]</td>\n",
       "      <td>[(2, 446), (0, 385), (5, 304), (12, 270), (1, ...</td>\n",
       "      <td>[(9, 1.0), (10, 1.0), (14, 1.0), (18, 1.0), (2...</td>\n",
       "      <td>[(18, 0.028491282213318102), (9, 0.01319905788...</td>\n",
       "      <td>[(14, 28), (26, 14), (9, 9), (18, 6), (22, 6),...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     search term  \\\n",
       "0                         ureas volume 6 , issue   \n",
       "0             bitcoin ? bitcoin digital currency   \n",
       "0          bitcoin wikipedia , free encyclopedia   \n",
       "0        three people supposedly bitcoin founder   \n",
       "0                  first sight its pretty clear   \n",
       "0                following banking , investing ,   \n",
       "0  blockchain technology ? blockchain technology   \n",
       "0           21st century technology . increasing   \n",
       "0                    surely 's complicated ? yes   \n",
       "0           deep learning , convolutional neural   \n",
       "\n",
       "                               actual_words_searched  \\\n",
       "0                       [ureas, volume, 6, ,, issue]   \n",
       "0           [bitcoin, ?, bitcoin, digital, currency]   \n",
       "0        [bitcoin, wikipedia, ,, free, encyclopedia]   \n",
       "0      [three, people, supposedly, bitcoin, founder]   \n",
       "0                [first, sight, its, pretty, clear]   \n",
       "0              [following, banking, ,, investing, ,]   \n",
       "0  [blockchain, technology, ?, blockchain, techno...   \n",
       "0         [21st, century, technology, ., increasing]   \n",
       "0                  [surely, 's, complicated, ?, yes]   \n",
       "0         [deep, learning, ,, convolutional, neural]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(26, 1142), (21, 458), (10, 436), (20, 284), ...   \n",
       "0  [(22, 36), (12, 20), (1, 18), (2, 14), (14, 10...   \n",
       "0  [(19, 1029), (21, 458), (10, 436), (11, 204), ...   \n",
       "0  [(2, 287), (1, 114), (5, 42), (28, 29), (13, 1...   \n",
       "0  [(2, 14), (12, 11), (21, 7), (17, 5), (24, 5),...   \n",
       "0  [(14, 2418), (26, 1142), (19, 1029), (21, 458)...   \n",
       "0  [(22, 36), (7, 21), (24, 21), (5, 18), (27, 13...   \n",
       "0  [(19, 814), (21, 351), (12, 214), (11, 165), (...   \n",
       "0  [(22, 36), (30, 31), (3, 23), (24, 21), (2, 20...   \n",
       "0  [(2, 446), (0, 385), (5, 304), (12, 270), (1, ...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(0, 1.0), (5, 0.8), (9, 0.6), (10, 0.6), (20,...   \n",
       "0  [(1, 0.8), (2, 0.8), (3, 0.8), (5, 0.8), (7, 0...   \n",
       "0  [(2, 1.0), (12, 1.0), (30, 1.0), (5, 0.8), (18...   \n",
       "0  [(3, 1.0), (30, 1.0), (2, 0.6), (5, 0.6), (16,...   \n",
       "0  [(4, 1.0), (5, 0.6), (0, 0.4), (1, 0.4), (7, 0...   \n",
       "0  [(1, 0.8), (5, 0.8), (2, 0.6), (12, 0.6), (0, ...   \n",
       "0  [(1, 0.6), (2, 0.6), (5, 0.6), (6, 0.6), (7, 0...   \n",
       "0  [(7, 1.0), (0, 0.6), (1, 0.6), (2, 0.6), (4, 0...   \n",
       "0  [(8, 1.0), (10, 0.6), (5, 0.6), (1, 0.4), (2, ...   \n",
       "0  [(9, 1.0), (10, 1.0), (14, 1.0), (18, 1.0), (2...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(0, 0.003803941506821382), (24, 0.00115154880...   \n",
       "0  [(22, 0.03129353076671049), (1, 0.008066363016...   \n",
       "0  [(18, 0.005017010568617829), (22, 0.0041638641...   \n",
       "0  [(1, 0.039195067632697096), (2, 0.026616061100...   \n",
       "0  [(17, 0.009374642605360172), (4, 0.00528275736...   \n",
       "0  [(15, -6.601463130056997e-06), (6, -1.21918037...   \n",
       "0  [(22, 0.03129353076671049), (6, 0.022706999225...   \n",
       "0  [(4, 0.003276529307704397), (24, 0.00087560233...   \n",
       "0  [(22, 0.03129353076671049), (3, 0.010630603381...   \n",
       "0  [(18, 0.028491282213318102), (9, 0.01319905788...   \n",
       "\n",
       "                                          word_order  truth  \n",
       "0  [(0, 41), (26, 12), (14, 6), (19, 4), (10, 3),...      0  \n",
       "0  [(1, 9), (2, 9), (28, 4), (12, 3), (4, 2), (30...      1  \n",
       "0  [(2, 4), (13, 4), (12, 3), (18, 3), (22, 3), (...      2  \n",
       "0  [(3, 4), (7, 1), (30, 1), (1, 0), (2, 0), (5, ...      3  \n",
       "0  [(4, 4), (0, 0), (1, 0), (5, 0), (7, 0), (10, ...      4  \n",
       "0  [(14, 10), (29, 6), (5, 4), (21, 4), (25, 4), ...      5  \n",
       "0  [(7, 25), (5, 19), (6, 19), (27, 18), (13, 4),...      6  \n",
       "0  [(7, 7), (24, 3), (6, 2), (1, 1), (2, 1), (18,...      7  \n",
       "0  [(8, 4), (3, 1), (1, 0), (2, 0), (5, 0), (6, 0...      8  \n",
       "0  [(14, 28), (26, 14), (9, 9), (18, 6), (22, 6),...      9  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_set[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ureas volume 6 , issue</td>\n",
       "      <td>[ureas, volume, 6, ,, issue]</td>\n",
       "      <td>[(26, 1142), (21, 458), (10, 436), (20, 284), ...</td>\n",
       "      <td>[(0, 1.0), (5, 0.8), (9, 0.6), (10, 0.6), (20,...</td>\n",
       "      <td>[(0, 0.003803941506821382), (24, 0.00115154880...</td>\n",
       "      <td>[(0, 41), (26, 12), (14, 6), (19, 4), (10, 3),...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin ? bitcoin digital currency</td>\n",
       "      <td>[bitcoin, ?, bitcoin, digital, currency]</td>\n",
       "      <td>[(22, 36), (12, 20), (1, 18), (2, 14), (14, 10...</td>\n",
       "      <td>[(1, 0.8), (2, 0.8), (3, 0.8), (5, 0.8), (7, 0...</td>\n",
       "      <td>[(22, 0.03129353076671049), (1, 0.008066363016...</td>\n",
       "      <td>[(1, 9), (2, 9), (28, 4), (12, 3), (4, 2), (30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin wikipedia , free encyclopedia</td>\n",
       "      <td>[bitcoin, wikipedia, ,, free, encyclopedia]</td>\n",
       "      <td>[(19, 1029), (21, 458), (10, 436), (11, 204), ...</td>\n",
       "      <td>[(2, 1.0), (12, 1.0), (30, 1.0), (5, 0.8), (18...</td>\n",
       "      <td>[(18, 0.005017010568617829), (22, 0.0041638641...</td>\n",
       "      <td>[(2, 4), (13, 4), (12, 3), (18, 3), (22, 3), (...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             search term  \\\n",
       "0                 ureas volume 6 , issue   \n",
       "0     bitcoin ? bitcoin digital currency   \n",
       "0  bitcoin wikipedia , free encyclopedia   \n",
       "\n",
       "                         actual_words_searched  \\\n",
       "0                 [ureas, volume, 6, ,, issue]   \n",
       "0     [bitcoin, ?, bitcoin, digital, currency]   \n",
       "0  [bitcoin, wikipedia, ,, free, encyclopedia]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(26, 1142), (21, 458), (10, 436), (20, 284), ...   \n",
       "0  [(22, 36), (12, 20), (1, 18), (2, 14), (14, 10...   \n",
       "0  [(19, 1029), (21, 458), (10, 436), (11, 204), ...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(0, 1.0), (5, 0.8), (9, 0.6), (10, 0.6), (20,...   \n",
       "0  [(1, 0.8), (2, 0.8), (3, 0.8), (5, 0.8), (7, 0...   \n",
       "0  [(2, 1.0), (12, 1.0), (30, 1.0), (5, 0.8), (18...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(0, 0.003803941506821382), (24, 0.00115154880...   \n",
       "0  [(22, 0.03129353076671049), (1, 0.008066363016...   \n",
       "0  [(18, 0.005017010568617829), (22, 0.0041638641...   \n",
       "\n",
       "                                          word_order  truth  \n",
       "0  [(0, 41), (26, 12), (14, 6), (19, 4), (10, 3),...      0  \n",
       "0  [(1, 9), (2, 9), (28, 4), (12, 3), (4, 2), (30...      1  \n",
       "0  [(2, 4), (13, 4), (12, 3), (18, 3), (22, 3), (...      2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_set\n",
    "test_set = truth_set[0:3]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>truth</th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, index, 0)</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ureas volume 6</td>\n",
       "      <td>[ureas, volume, 6]</td>\n",
       "      <td>[(26, 21), (0, 15), (14, 12), (19, 8), (21, 8)...</td>\n",
       "      <td>[(0, 1.0), (5, 0.6666666666666666), (9, 0.6666...</td>\n",
       "      <td>[(25, 0.0045581282768224485), (29, 0.002135990...</td>\n",
       "      <td>[(0, 20), (5, 0), (9, 0), (10, 0), (20, 0)]</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>axiomatizations critical facts must</td>\n",
       "      <td>[axiomatizations, critical, facts, must]</td>\n",
       "      <td>[(5, 15), (14, 13), (2, 11), (10, 6), (24, 5),...</td>\n",
       "      <td>[(0, 1.0), (2, 0.5), (10, 0.5), (14, 0.5), (19...</td>\n",
       "      <td>[(5, 0.0035809825898847915), (23, 0.0019181198...</td>\n",
       "      <td>[(0, 3), (2, 0), (10, 0), (14, 0), (19, 0)]</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wiebe et</td>\n",
       "      <td>[wiebe, et]</td>\n",
       "      <td>[(14, 129), (19, 12), (9, 9), (0, 8), (10, 5),...</td>\n",
       "      <td>[(0, 1.0), (9, 0.5), (10, 0.5), (11, 0.5), (14...</td>\n",
       "      <td>[(14, 0.009844855541251824), (9, 0.00609282583...</td>\n",
       "      <td>[(0, 1)]</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin ? bitcoin digital currency</td>\n",
       "      <td>[bitcoin, ?, bitcoin, digital, currency]</td>\n",
       "      <td>[(22, 36), (12, 20), (1, 18), (2, 14), (14, 10...</td>\n",
       "      <td>[(1, 0.8), (2, 0.8), (3, 0.8), (5, 0.8), (7, 0...</td>\n",
       "      <td>[(22, 0.03129353076671049), (1, 0.008066363016...</td>\n",
       "      <td>[(1, 9), (2, 9), (28, 4), (12, 3), (4, 2), (30...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. also known</td>\n",
       "      <td>[., also, known]</td>\n",
       "      <td>[(29, 61), (16, 46), (25, 20), (2, 10), (1, 5)...</td>\n",
       "      <td>[(0, 1.0), (1, 1.0), (2, 1.0), (3, 1.0), (4, 1...</td>\n",
       "      <td>[(6, 0.004010192676579764), (13, 0.00143538261...</td>\n",
       "      <td>[(20, 5), (21, 5), (1, 4), (10, 4), (2, 2), (5...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           search term  \\\n",
       "0                       ureas volume 6   \n",
       "1  axiomatizations critical facts must   \n",
       "2                             wiebe et   \n",
       "0   bitcoin ? bitcoin digital currency   \n",
       "1                         . also known   \n",
       "\n",
       "                      actual_words_searched  \\\n",
       "0                        [ureas, volume, 6]   \n",
       "1  [axiomatizations, critical, facts, must]   \n",
       "2                               [wiebe, et]   \n",
       "0  [bitcoin, ?, bitcoin, digital, currency]   \n",
       "1                          [., also, known]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(26, 21), (0, 15), (14, 12), (19, 8), (21, 8)...   \n",
       "1  [(5, 15), (14, 13), (2, 11), (10, 6), (24, 5),...   \n",
       "2  [(14, 129), (19, 12), (9, 9), (0, 8), (10, 5),...   \n",
       "0  [(22, 36), (12, 20), (1, 18), (2, 14), (14, 10...   \n",
       "1  [(29, 61), (16, 46), (25, 20), (2, 10), (1, 5)...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(0, 1.0), (5, 0.6666666666666666), (9, 0.6666...   \n",
       "1  [(0, 1.0), (2, 0.5), (10, 0.5), (14, 0.5), (19...   \n",
       "2  [(0, 1.0), (9, 0.5), (10, 0.5), (11, 0.5), (14...   \n",
       "0  [(1, 0.8), (2, 0.8), (3, 0.8), (5, 0.8), (7, 0...   \n",
       "1  [(0, 1.0), (1, 1.0), (2, 1.0), (3, 1.0), (4, 1...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(25, 0.0045581282768224485), (29, 0.002135990...   \n",
       "1  [(5, 0.0035809825898847915), (23, 0.0019181198...   \n",
       "2  [(14, 0.009844855541251824), (9, 0.00609282583...   \n",
       "0  [(22, 0.03129353076671049), (1, 0.008066363016...   \n",
       "1  [(6, 0.004010192676579764), (13, 0.00143538261...   \n",
       "\n",
       "                                          word_order  truth  \\\n",
       "0        [(0, 20), (5, 0), (9, 0), (10, 0), (20, 0)]      0   \n",
       "1        [(0, 3), (2, 0), (10, 0), (14, 0), (19, 0)]      0   \n",
       "2                                           [(0, 1)]      0   \n",
       "0  [(1, 9), (2, 9), (28, 4), (12, 3), (4, 2), (30...      1   \n",
       "1  [(20, 5), (21, 5), (1, 4), (10, 4), (2, 2), (5...      1   \n",
       "\n",
       "   (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  ...  \\\n",
       "0                     26                   1142                     21  ...   \n",
       "1                     26                   1142                     21  ...   \n",
       "2                     26                   1142                     21  ...   \n",
       "0                     22                     36                     12  ...   \n",
       "1                     22                     36                     12  ...   \n",
       "\n",
       "   (word_order, index, 0)  (word_order, score, 0)  (word_order, index, 1)  \\\n",
       "0                       0                      41                    26.0   \n",
       "1                       0                      41                    26.0   \n",
       "2                       0                      41                    26.0   \n",
       "0                       1                       9                     2.0   \n",
       "1                       1                       9                     2.0   \n",
       "\n",
       "   (word_order, score, 1)  (word_order, index, 2)  (word_order, score, 2)  \\\n",
       "0                    12.0                    14.0                     6.0   \n",
       "1                    12.0                    14.0                     6.0   \n",
       "2                    12.0                    14.0                     6.0   \n",
       "0                     9.0                    28.0                     4.0   \n",
       "1                     9.0                    28.0                     4.0   \n",
       "\n",
       "   (word_order, index, 3)  (word_order, score, 3)  (word_order, index, 4)  \\\n",
       "0                    19.0                     4.0                    10.0   \n",
       "1                    19.0                     4.0                    10.0   \n",
       "2                    19.0                     4.0                    10.0   \n",
       "0                    12.0                     3.0                     4.0   \n",
       "1                    12.0                     3.0                     4.0   \n",
       "\n",
       "   (word_order, score, 4)  \n",
       "0                     3.0  \n",
       "1                     3.0  \n",
       "2                     3.0  \n",
       "0                     2.0  \n",
       "1                     2.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to long format for ML \n",
    "# WARNING AGAIN THIS IS A SLOW PROCESS DUE TO RAM ILOC - COULD BE OPTIMISED FOR FASTER PERFORMANCE \n",
    "# BUG When min(maxnum, len(truth_set) <- is a int not a list because of very short variable length)\n",
    "\n",
    "# row is row\n",
    "# column is variable\n",
    "# i is the result \n",
    "\n",
    "final_set =  pd.DataFrame()\n",
    "test_set = truth_set[1:100]\n",
    "maxnum = 5\n",
    "\n",
    "for row in range(0,len(test_set.index)):\n",
    "    test_set = truth_set[1:100]\n",
    "    for col in range(2,6):\n",
    "        for i in range(0,min(maxnum,len(truth_set.iloc[row][col]))):\n",
    "            x = pd.DataFrame([truth_set.iloc[row][col][i]])\n",
    "            x['truth'] = truth_set.iloc[row]['truth']\n",
    "            x.columns = [(str(truth_set.columns[col]),\"index\",i),(str(truth_set.columns[col]),\"score\",i),'truth']\n",
    "            test_set = test_set.merge(x,on='truth')\n",
    "    final_set = pd.concat([final_set,test_set])\n",
    "        \n",
    "final_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_set.to_csv(\"ML_set_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, index, 0)</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   truth  (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0      0                     26                   1142                     21   \n",
       "1      0                     26                   1142                     21   \n",
       "2      0                     26                   1142                     21   \n",
       "0      1                     22                     36                     12   \n",
       "1      1                     22                     36                     12   \n",
       "\n",
       "   (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                    458                     10                    436   \n",
       "1                    458                     10                    436   \n",
       "2                    458                     10                    436   \n",
       "0                     20                      1                     18   \n",
       "1                     20                      1                     18   \n",
       "\n",
       "   (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  ...  \\\n",
       "0                   20.0                  284.0                   11.0  ...   \n",
       "1                   20.0                  284.0                   11.0  ...   \n",
       "2                   20.0                  284.0                   11.0  ...   \n",
       "0                    2.0                   14.0                   14.0  ...   \n",
       "1                    2.0                   14.0                   14.0  ...   \n",
       "\n",
       "   (word_order, index, 0)  (word_order, score, 0)  (word_order, index, 1)  \\\n",
       "0                       0                      41                    26.0   \n",
       "1                       0                      41                    26.0   \n",
       "2                       0                      41                    26.0   \n",
       "0                       1                       9                     2.0   \n",
       "1                       1                       9                     2.0   \n",
       "\n",
       "   (word_order, score, 1)  (word_order, index, 2)  (word_order, score, 2)  \\\n",
       "0                    12.0                    14.0                     6.0   \n",
       "1                    12.0                    14.0                     6.0   \n",
       "2                    12.0                    14.0                     6.0   \n",
       "0                     9.0                    28.0                     4.0   \n",
       "1                     9.0                    28.0                     4.0   \n",
       "\n",
       "   (word_order, index, 3)  (word_order, score, 3)  (word_order, index, 4)  \\\n",
       "0                    19.0                     4.0                    10.0   \n",
       "1                    19.0                     4.0                    10.0   \n",
       "2                    19.0                     4.0                    10.0   \n",
       "0                    12.0                     3.0                     4.0   \n",
       "1                    12.0                     3.0                     4.0   \n",
       "\n",
       "   (word_order, score, 4)  \n",
       "0                     3.0  \n",
       "1                     3.0  \n",
       "2                     3.0  \n",
       "0                     2.0  \n",
       "1                     2.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set2 = final_set.drop(['actual_words_searched','num_occur','percentage_of_terms','search term','td-idf','word_order'], 1)\n",
    "final_set2.to_csv(\"ML_set_100_3.csv\")\n",
    "final_set2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, index, 0)</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1029</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1029</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1029</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   truth  (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0      0                     26                   1142                     21   \n",
       "1      0                     26                   1142                     21   \n",
       "2      0                     26                   1142                     21   \n",
       "0      1                     22                     36                     12   \n",
       "1      1                     22                     36                     12   \n",
       "2      1                     22                     36                     12   \n",
       "3      1                     22                     36                     12   \n",
       "0      2                     19                   1029                     21   \n",
       "1      2                     19                   1029                     21   \n",
       "2      2                     19                   1029                     21   \n",
       "\n",
       "   (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                    458                     10                    436   \n",
       "1                    458                     10                    436   \n",
       "2                    458                     10                    436   \n",
       "0                     20                      1                     18   \n",
       "1                     20                      1                     18   \n",
       "2                     20                      1                     18   \n",
       "3                     20                      1                     18   \n",
       "0                    458                     10                    436   \n",
       "1                    458                     10                    436   \n",
       "2                    458                     10                    436   \n",
       "\n",
       "   (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  ...  \\\n",
       "0                   20.0                  284.0                   11.0  ...   \n",
       "1                   20.0                  284.0                   11.0  ...   \n",
       "2                   20.0                  284.0                   11.0  ...   \n",
       "0                    2.0                   14.0                   14.0  ...   \n",
       "1                    2.0                   14.0                   14.0  ...   \n",
       "2                    2.0                   14.0                   14.0  ...   \n",
       "3                    2.0                   14.0                   14.0  ...   \n",
       "0                   11.0                  204.0                    7.0  ...   \n",
       "1                   11.0                  204.0                    7.0  ...   \n",
       "2                   11.0                  204.0                    7.0  ...   \n",
       "\n",
       "   (word_order, index, 0)  (word_order, score, 0)  (word_order, index, 1)  \\\n",
       "0                       0                      41                    26.0   \n",
       "1                       0                      41                    26.0   \n",
       "2                       0                      41                    26.0   \n",
       "0                       1                       9                     2.0   \n",
       "1                       1                       9                     2.0   \n",
       "2                       1                       9                     2.0   \n",
       "3                       1                       9                     2.0   \n",
       "0                       2                       4                    13.0   \n",
       "1                       2                       4                    13.0   \n",
       "2                       2                       4                    13.0   \n",
       "\n",
       "   (word_order, score, 1)  (word_order, index, 2)  (word_order, score, 2)  \\\n",
       "0                    12.0                    14.0                     6.0   \n",
       "1                    12.0                    14.0                     6.0   \n",
       "2                    12.0                    14.0                     6.0   \n",
       "0                     9.0                    28.0                     4.0   \n",
       "1                     9.0                    28.0                     4.0   \n",
       "2                     9.0                    28.0                     4.0   \n",
       "3                     9.0                    28.0                     4.0   \n",
       "0                     4.0                    12.0                     3.0   \n",
       "1                     4.0                    12.0                     3.0   \n",
       "2                     4.0                    12.0                     3.0   \n",
       "\n",
       "   (word_order, index, 3)  (word_order, score, 3)  (word_order, index, 4)  \\\n",
       "0                    19.0                     4.0                    10.0   \n",
       "1                    19.0                     4.0                    10.0   \n",
       "2                    19.0                     4.0                    10.0   \n",
       "0                    12.0                     3.0                     4.0   \n",
       "1                    12.0                     3.0                     4.0   \n",
       "2                    12.0                     3.0                     4.0   \n",
       "3                    12.0                     3.0                     4.0   \n",
       "0                    18.0                     3.0                    22.0   \n",
       "1                    18.0                     3.0                    22.0   \n",
       "2                    18.0                     3.0                    22.0   \n",
       "\n",
       "   (word_order, score, 4)  \n",
       "0                     3.0  \n",
       "1                     3.0  \n",
       "2                     3.0  \n",
       "0                     2.0  \n",
       "1                     2.0  \n",
       "2                     2.0  \n",
       "3                     2.0  \n",
       "0                     3.0  \n",
       "1                     3.0  \n",
       "2                     3.0  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set3 = final_set2\n",
    "final_set3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from sklearn.model_selection import cross_validate,KFold,train_test_split\n",
    "from sklearn import linear_model, feature_selection,preprocessing\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>(num_occur, score, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>21</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>2418</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>19</td>\n",
       "      <td>1029</td>\n",
       "      <td>21.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>2418</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>19</td>\n",
       "      <td>1029</td>\n",
       "      <td>21.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2418</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>19</td>\n",
       "      <td>1029</td>\n",
       "      <td>21.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2418</td>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>19</td>\n",
       "      <td>1029</td>\n",
       "      <td>21.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0                      26                   1142                     21   \n",
       "1                      26                   1142                     21   \n",
       "2                      26                   1142                     21   \n",
       "0                      22                     36                     12   \n",
       "1                      22                     36                     12   \n",
       "..                    ...                    ...                    ...   \n",
       "3                       7                     14                      5   \n",
       "0                      14                   2418                     26   \n",
       "1                      14                   2418                     26   \n",
       "2                      14                   2418                     26   \n",
       "3                      14                   2418                     26   \n",
       "\n",
       "    (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                     458                     10                    436   \n",
       "1                     458                     10                    436   \n",
       "2                     458                     10                    436   \n",
       "0                      20                      1                     18   \n",
       "1                      20                      1                     18   \n",
       "..                    ...                    ...                    ...   \n",
       "3                       3                      4                      2   \n",
       "0                    1142                     19                   1029   \n",
       "1                    1142                     19                   1029   \n",
       "2                    1142                     19                   1029   \n",
       "3                    1142                     19                   1029   \n",
       "\n",
       "    (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  \\\n",
       "0                    20.0                  284.0                   11.0   \n",
       "1                    20.0                  284.0                   11.0   \n",
       "2                    20.0                  284.0                   11.0   \n",
       "0                     2.0                   14.0                   14.0   \n",
       "1                     2.0                   14.0                   14.0   \n",
       "..                    ...                    ...                    ...   \n",
       "3                    12.0                    2.0                   13.0   \n",
       "0                    21.0                  458.0                   20.0   \n",
       "1                    21.0                  458.0                   20.0   \n",
       "2                    21.0                  458.0                   20.0   \n",
       "3                    21.0                  458.0                   20.0   \n",
       "\n",
       "    (num_occur, score, 4)  ...  (word_order, score, 0)  \\\n",
       "0                   204.0  ...                      41   \n",
       "1                   204.0  ...                      41   \n",
       "2                   204.0  ...                      41   \n",
       "0                    10.0  ...                       9   \n",
       "1                    10.0  ...                       9   \n",
       "..                    ...  ...                     ...   \n",
       "3                     2.0  ...                       1   \n",
       "0                   284.0  ...                       2   \n",
       "1                   284.0  ...                       2   \n",
       "2                   284.0  ...                       2   \n",
       "3                   284.0  ...                       2   \n",
       "\n",
       "    (word_order, index, 1)  (word_order, score, 1)  (word_order, index, 2)  \\\n",
       "0                     26.0                    12.0                    14.0   \n",
       "1                     26.0                    12.0                    14.0   \n",
       "2                     26.0                    12.0                    14.0   \n",
       "0                      2.0                     9.0                    28.0   \n",
       "1                      2.0                     9.0                    28.0   \n",
       "..                     ...                     ...                     ...   \n",
       "3                      7.0                     0.0                     NaN   \n",
       "0                      5.0                     1.0                     0.0   \n",
       "1                      5.0                     1.0                     0.0   \n",
       "2                      5.0                     1.0                     0.0   \n",
       "3                      5.0                     1.0                     0.0   \n",
       "\n",
       "    (word_order, score, 2)  (word_order, index, 3)  (word_order, score, 3)  \\\n",
       "0                      6.0                    19.0                     4.0   \n",
       "1                      6.0                    19.0                     4.0   \n",
       "2                      6.0                    19.0                     4.0   \n",
       "0                      4.0                    12.0                     3.0   \n",
       "1                      4.0                    12.0                     3.0   \n",
       "..                     ...                     ...                     ...   \n",
       "3                      NaN                     NaN                     NaN   \n",
       "0                      0.0                     2.0                     0.0   \n",
       "1                      0.0                     2.0                     0.0   \n",
       "2                      0.0                     2.0                     0.0   \n",
       "3                      0.0                     2.0                     0.0   \n",
       "\n",
       "    (word_order, index, 4)  (word_order, score, 4)  y  \n",
       "0                     10.0                     3.0  0  \n",
       "1                     10.0                     3.0  0  \n",
       "2                     10.0                     3.0  0  \n",
       "0                      4.0                     2.0  1  \n",
       "1                      4.0                     2.0  1  \n",
       "..                     ...                     ... ..  \n",
       "3                      NaN                     NaN  4  \n",
       "0                     16.0                     0.0  5  \n",
       "1                     16.0                     0.0  5  \n",
       "2                     16.0                     0.0  5  \n",
       "3                     16.0                     0.0  5  \n",
       "\n",
       "[320 rows x 41 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set3['y'] = final_set3['truth']\n",
    "final_set3 = final_set3.drop(['truth'], 1)\n",
    "final_set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(num_occur, index, 0)             -0.029505\n",
       "(num_occur, score, 0)              0.043943\n",
       "(num_occur, index, 1)              0.041411\n",
       "(num_occur, score, 1)              0.039071\n",
       "(num_occur, index, 2)              0.251069\n",
       "(num_occur, score, 2)              0.038315\n",
       "(num_occur, index, 3)              0.028205\n",
       "(num_occur, score, 3)              0.032323\n",
       "(num_occur, index, 4)              0.037847\n",
       "(num_occur, score, 4)              0.041958\n",
       "(percentage_of_terms, index, 0)    0.523454\n",
       "(percentage_of_terms, score, 0)    0.029703\n",
       "(percentage_of_terms, index, 1)    0.298882\n",
       "(percentage_of_terms, score, 1)    0.220459\n",
       "(percentage_of_terms, index, 2)   -0.023530\n",
       "(percentage_of_terms, score, 2)    0.123263\n",
       "(percentage_of_terms, index, 3)    0.172155\n",
       "(percentage_of_terms, score, 3)    0.180705\n",
       "(percentage_of_terms, index, 4)    0.023379\n",
       "(percentage_of_terms, score, 4)    0.097777\n",
       "(td-idf, index, 0)                 0.254292\n",
       "(td-idf, score, 0)                 0.047955\n",
       "(td-idf, index, 1)                 0.029017\n",
       "(td-idf, score, 1)                 0.033670\n",
       "(td-idf, index, 2)                -0.050736\n",
       "(td-idf, score, 2)                 0.020522\n",
       "(td-idf, index, 3)                 0.100632\n",
       "(td-idf, score, 3)                 0.056013\n",
       "(td-idf, index, 4)                 0.099630\n",
       "(td-idf, score, 4)                 0.083510\n",
       "(word_order, index, 0)             0.735968\n",
       "(word_order, score, 0)             0.156622\n",
       "(word_order, index, 1)             0.222151\n",
       "(word_order, score, 1)             0.136968\n",
       "(word_order, index, 2)             0.004995\n",
       "(word_order, score, 2)             0.169839\n",
       "(word_order, index, 3)            -0.052026\n",
       "(word_order, score, 3)             0.135644\n",
       "(word_order, index, 4)            -0.200595\n",
       "(word_order, score, 4)             0.135692\n",
       "y                                  1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = final_set3\n",
    "data.corr()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['a'] = data[data.columns[0]]\n",
    "data['b'] = data[data.columns[10]]\n",
    "data['c'] = data[data.columns[20]]\n",
    "data['d'] = data[data.columns[30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   123.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Jul 2020</td> <th>  Prob (F-statistic):</th> <td>3.95e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:51:10</td>     <th>  Log-Likelihood:    </th> <td> -791.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   256</td>      <th>  AIC:               </th> <td>   1594.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   251</td>      <th>  BIC:               </th> <td>   1612.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.8248</td> <td>    1.003</td> <td>    1.819</td> <td> 0.070</td> <td>   -0.151</td> <td>    3.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>a</th>         <td>   -0.1055</td> <td>    0.047</td> <td>   -2.230</td> <td> 0.027</td> <td>   -0.199</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b</th>         <td>    0.1936</td> <td>    0.053</td> <td>    3.664</td> <td> 0.000</td> <td>    0.090</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th>         <td>    0.1570</td> <td>    0.042</td> <td>    3.741</td> <td> 0.000</td> <td>    0.074</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d</th>         <td>    0.7032</td> <td>    0.049</td> <td>   14.480</td> <td> 0.000</td> <td>    0.608</td> <td>    0.799</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>117.348</td> <th>  Durbin-Watson:     </th> <td>   1.887</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 725.593</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.730</td>  <th>  Prob(JB):          </th> <td>2.75e-158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.487</td>  <th>  Cond. No.          </th> <td>    85.3</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.663\n",
       "Model:                            OLS   Adj. R-squared:                  0.658\n",
       "Method:                 Least Squares   F-statistic:                     123.6\n",
       "Date:                Tue, 21 Jul 2020   Prob (F-statistic):           3.95e-58\n",
       "Time:                        18:51:10   Log-Likelihood:                -791.99\n",
       "No. Observations:                 256   AIC:                             1594.\n",
       "Df Residuals:                     251   BIC:                             1612.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.8248      1.003      1.819      0.070      -0.151       3.800\n",
       "a             -0.1055      0.047     -2.230      0.027      -0.199      -0.012\n",
       "b              0.1936      0.053      3.664      0.000       0.090       0.298\n",
       "c              0.1570      0.042      3.741      0.000       0.074       0.240\n",
       "d              0.7032      0.049     14.480      0.000       0.608       0.799\n",
       "==============================================================================\n",
       "Omnibus:                      117.348   Durbin-Watson:                   1.887\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              725.593\n",
       "Skew:                           1.730   Prob(JB):                    2.75e-158\n",
       "Kurtosis:                      10.487   Cond. No.                         85.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "\n",
    "train,test = train_test_split(X,train_size=0.80)\n",
    "\n",
    "model = sm.ols(formula='y ~ 1 + a + b + c + d', \n",
    "               data=train).fit()\n",
    "\n",
    "modelforout = model \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "fig = sma.graphics.influence_plot(modelforout, ax=ax, criterion=\"cooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = model.resid # residuals\n",
    "fig = sma.qqplot(res)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: automatic\n",
      "RESULT 1 : File Name :  CNN.TXT \n",
      " ['In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery.[1] They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.[2][3] They have applications in image and video recognition, recommender systems,[4] image classification, medical image analysis, natural language processing,[5] and financial time series.[6]\\n\\nCNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"fully-connectedness\" of these networks makes them prone to overfitting data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.\\n\\nConvolutional networks were inspired by biological processes[7][8][9][10] in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\\n\\nCNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage.\\nDefinition\\nThe name \\x93convolutional neural network\\x94 indicates that the network employs a mathematical operation called convolution. Convolution is a specialized kind of linear operation. Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers.[11]\\n\\nArchitecture\\nA convolutional neural network consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of a series of convolutional layers that convolve with a multiplication or other dot product. The activation function is commonly a RELU layer, and is subsequently followed by additional convolutions such as pooling layers, fully connected layers and normalization layers, referred to as hidden layers because their inputs and outputs are masked by the activation function and final convolution.\\n\\nThough the layers are colloquially referred to as convolutions, this is only by convention. Mathematically, it is technically a sliding dot product or cross-correlation. This has significance for the indices in the matrix, in that it affects how weight is determined at a specific index point.\\n\\nConvolutional\\nWhen programming a CNN, the input is a tensor with shape (number of images) x (image height) x (image width) x (image depth). Then after passing through a convolutional layer, the image becomes abstracted to a feature map, with shape (number of images) x (feature map height) x (feature map width) x (feature map channels). A convolutional layer within a neural network should have the following attributes:\\n\\nConvolutional kernels defined by a width and height (hyper-parameters).\\nThe number of input channels and output channels (hyper-parameter).\\nThe depth of the Convolution filter (the input channels) must be equal to the number channels (depth) of the input feature map.\\nConvolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus.[12] Each convolutional neuron processes data only for its receptive field. Although fully connected feedforward neural networks can be used to learn features as well as classify data, it is not practical to apply this architecture to images. A very high number of neurons would be necessary, even in a shallow (opposite of deep) architecture, due to the very large input sizes associated with images, where each pixel is a relevant variable. For instance, a fully connected layer for a (small) image of size 100 x 100 has 10,000 weights for each neuron in the second layer. The convolution operation brings a solution to this problem as it reduces the number of free parameters, allowing the network to be deeper with fewer parameters.[13] For instance, regardless of image size, tiling regions of size 5 x 5, each with the same shared weights, requires only 25 learnable parameters. By using regularized weights over fewer parameters, the vanishing gradient and exploding gradient problems seen during backpropagation in traditional neural networks are avoided.[14][15]\\n\\nPooling\\nConvolutional networks may include local or global pooling layers to streamline the underlying computation. Pooling layers reduce the dimensions of the data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, typically 2 x 2. Global pooling acts on all the neurons of the convolutional layer.[16][17] In addition, pooling may compute a max or an average. Max pooling uses the maximum value from each of a cluster of neurons at the prior layer.[18][19] Average pooling uses the average value from each of a cluster of neurons at the prior layer.[20]\\n\\nFully connected\\nFully connected layers connect every neuron in one layer to every neuron in another layer. It is in principle the same as the traditional multi-layer perceptron neural network (MLP). The flattened matrix goes through a fully connected layer to classify the images.\\n\\nReceptive field\\nIn neural networks, each neuron receives input from some number of locations in the previous layer. In a fully connected layer, each neuron receives input from every element of the previous layer. In a convolutional layer, neurons receive input from only a restricted subarea of the previous layer. Typically the subarea is of a square shape (e.g., size 5 by 5). The input area of a neuron is called its receptive field. So, in a fully connected layer, the receptive field is the entire previous layer. In a convolutional layer, the receptive area is smaller than the entire previous layer. The subarea of the original input image in the receptive field is increasingly growing as getting deeper in the network architecture. This is due to applying over and over again a convolution which takes into account the value of a specific pixel, but also some surrounding pixels.\\n\\nWeights\\nEach neuron in a neural network computes an output value by applying a specific function to the input values coming from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias (typically real numbers). Learning, in a neural network, progresses by making iterative adjustments to these biases and weights.\\n\\nThe vector of weights and the bias are called filters and represent particular features of the input (e.g., a particular shape). A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces memory footprint because a single bias and a single vector of weights are used across all receptive fields sharing that filter, as opposed to each receptive field having its own bias and vector weighting.[21]\\n\\nHistory\\nCNN design follows vision processing in living organisms.[citation needed]\\n\\nReceptive fields in the visual cortex\\nWork by Hubel and Wiesel in the 1950s and 1960s showed that cat and monkey visual cortexes contain neurons that individually respond to small regions of the visual field. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field.[citation needed] Neighboring cells have similar and overlapping receptive fields.[citation needed] Receptive field size and location varies systematically across the cortex to form a complete map of visual space.[citation needed] The cortex in each hemisphere represents the contralateral visual field.[citation needed]\\n\\nTheir 1968 paper identified two basic visual cell types in the brain:[8]\\n\\nsimple cells, whose output is maximized by straight edges having particular orientations within their receptive field\\ncomplex cells, which have larger receptive fields, whose output is insensitive to the exact position of the edges in the field.\\nHubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks.[22][23]\\n\\nNeocognitron, origin of the CNN architecture\\nThe \"neocognitron\"[7] was introduced by Kunihiko Fukushima in 1980.[9][19][24] It was inspired by the above-mentioned work of Hubel and Wiesel. The neocognitron introduced the two basic types of layers in CNNs: convolutional layers, and downsampling layers. A convolutional layer contains units whose receptive fields cover a patch of the previous layer. The weight vector (the set of adaptive parameters) of such a unit is often called a filter. Units can share filters. Downsampling layers contain units whose receptive fields cover patches of previous convolutional layers. Such a unit typically computes the average of the activations of the units in its patch. This downsampling helps to correctly classify objects in visual scenes even when the objects are shifted.\\n\\nIn a variant of the neocognitron called the cresceptron, instead of using Fukushima\\'s spatial averaging, J. Weng et al. introduced a method called max-pooling where a downsampling unit computes the maximum of the activations of the units in its patch.[25] Max-pooling is often used in modern CNNs.[26]\\n\\nSeveral supervised and unsupervised learning algorithms have been proposed over the decades to train the weights of a neocognitron.[7] Today, however, the CNN architecture is usually trained through backpropagation.\\n\\nThe neocognitron is the first CNN which requires units located at multiple network positions to have shared weights. Neocognitrons were adapted in 1988 to analyze time-varying signals.[27]\\n\\nTime delay neural networks\\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel et al. and was the first convolutional network, as it achieved shift invariance.[28] It did so by utilizing weight sharing in combination with Backpropagation training.[29] Thus, while also using a pyramidal structure as in the neocognitron, it performed a global optimization of the weights instead of a local one.[28]\\n\\nTDNNs are convolutional networks that share weights along the temporal dimension.[30] They allow speech signals to be processed time-invariantly. In 1990 Hampshire and Waibel introduced a variant which performs a two dimensional convolution.[31] Since these TDNNs operated on spectrograms, the resulting phoneme recognition system was invariant to both shifts in time and in frequency. This inspired translation invariance in image processing with CNNs.[29] The tiling of neuron outputs can cover timed stages.[32]\\n\\nTDNNs now achieve the best performance in far distance speech recognition.[33]\\n\\nMax pooling\\nIn 1990 Yamaguchi et al. introduced the concept of max pooling. They did so by combining TDNNs with max pooling in order to realize a speaker independent isolated word recognition system.[18] In their system they used several TDNNs per word, one for each syllable. The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.\\n\\nImage recognition with CNNs trained by gradient descent\\nA system to recognize hand-written ZIP Code numbers[34] involved convolutions in which the kernel coefficients had been laboriously hand designed.[35]\\n\\nYann LeCun et al. (1989)[35] used back-propagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning was thus fully automatic, performed better than manual coefficient design, and was suited to a broader range of image recognition problems and image types.\\n\\nThis approach became a foundation of modern computer vision.\\n\\nLeNet-5\\nMain article: LeNet\\nLeNet-5, a pioneering 7-level convolutional network by LeCun et al. in 1998,[36] that classifies digits, was applied by several banks to recognize hand-written numbers on checks (British English: cheques) digitized in 32x32 pixel images. The ability to process higher resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources.\\n\\nShift-invariant neural network\\nSimilarly, a shift invariant neural network was proposed by W. Zhang et al. for image character recognition in 1988.[2][3] The architecture and training algorithm were modified in 1991[37] and applied for medical image processing[38] and automatic detection of breast cancer in mammograms.[39]\\n\\nA different convolution-based design was proposed in 1988[40] for application to decomposition of one-dimensional electromyography convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.[41][42]\\n\\nNeural abstraction pyramid\\nNeural Abstraction Pyramid\\nNeural Abstraction Pyramid\\nThe feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid[43] by lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models, image-like outputs at the highest resolution were generated, e.g., for semantic segmentation, image reconstruction, and object localization tasks.\\n\\nGPU implementations\\nAlthough CNNs were invented in the 1980s, their breakthrough in the 2000s required fast implementations on graphics processing units (GPUs).\\n\\nIn 2004, it was shown by K. S. Oh and K. Jung that standard neural networks can be greatly accelerated on GPUs. Their implementation was 20 times faster than an equivalent implementation on CPU.[44][26] In 2005, another paper also emphasised the value of GPGPU for machine learning.[45]\\n\\nThe first GPU-implementation of a CNN was described in 2006 by K. Chellapilla et al. Their implementation was 4 times faster than an equivalent implementation on CPU.[46] Subsequent work also used GPUs, initially for other types of neural networks (different from CNNs), especially unsupervised neural networks.[47][48][49][50]\\n\\nIn 2010, Dan Ciresan et al. at IDSIA showed that even deep standard neural networks with many layers can be quickly trained on GPU by supervised learning through the old method known as backpropagation. Their network outperformed previous machine learning methods on the MNIST handwritten digits benchmark.[51] In 2011, they extended this GPU approach to CNNs, achieving an acceleration factor of 60, with impressive results.[16] In 2011, they used such CNNs on GPU to win an image recognition contest where they achieved superhuman performance for the first time.[52] Between May 15, 2011 and September 30, 2012, their CNNs won no less than four image competitions.[53][26] In 2012, they also significantly improved on the best performance in the literature for multiple image databases, including the MNIST database, the NORB database, the HWDB1.0 dataset (Chinese characters) and the CIFAR10 dataset (dataset of 60000 32x32 labeled RGB images).[19]\\n\\nSubsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.[54] A very deep CNN with over 100 layers by Microsoft won the ImageNet 2015 contest.[55]\\n\\nIntel Xeon Phi implementations\\nCompared to the training of CNNs using GPUs, not much attention was given to the Intel Xeon Phi coprocessor.[56] A notable development is a parallelization method for training convolutional neural networks on the Intel Xeon Phi, named Controlled Hogwild with Arbitrary Order of Synchronization (CHAOS).[57] CHAOS exploits both the thread- and SIMD-level parallelism that is available on the Intel Xeon Phi.\\nConvolutional layer\\nThe convolutional layer is the core building block of a CNN. The layer\\'s parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.[58] [nb 1]\\n\\nStacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input and shares parameters with neurons in the same activation map.'] ...\n",
      "\n",
      "\n",
      "RESULT 2 : File Name :  25EASMARCH-3369.TXT \n",
      " ['UREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR - 6.573)\\n\\n \\n\\nNatural Language Processing: A Review\\n\\nSethunya R Joseph\\x80\\x99,\\nComputer Science Department,\\nBotswana International University of Science and Technology,\\nPalapye, Botswana\\n\\nHlomani Hlomani\\x80\\x9d\\nComputer Science Department,\\nBotswana International University of Science and Technology,\\n\\nKeletso Letsholo\\x80\\x99,\\nComputer Science Department,\\nBotswana International University of Science and Technology,\\nPalapye, Botswana\\n\\nFreeson Kaniwa\\x80\\x99,\\nComputer Science Department,\\nBotswana International University of Science and Technology,\\nPalapye, Botswana\\n\\nKutlwano Sedimo*\\nComputer Science Department,\\nBotswana International University of Science and Technology,\\nPalapye, Botswana\\n\\nABSTRACT\\n\\nNatural Language Processing (NLP) is a way of analyzing texts by computerized means. NLP involves\\ngathering of knowledge on how human beings understand and use language. This is done in order to\\ndevelop appropriate tools and techniques which could make computer systems understand and\\nmanipulate natural languages to perform various desired tasks. This paper reviews the literature on NLP.\\nIt also covers or gives a hint about the history of NLP. It is based on document analysis. This research\\npaper could be beneficial to those who wish to study and learn about NLP.\\n\\nKeywords: NLP, machine translation, machine learning, computational techniques, linguists\\n\\n1. Introduction\\n\\nVarious researchers have explained Natural Language Processing (NLP) as an area of research and\\napplication that explores how computers can be used to understand and manipulate natural language text\\nor speech to do useful things ([2]; [3]; [6]; [7]).\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences\\nEmail:- editorijrim@gmail.com, http://www.euroasiapub.org\\n\\n207\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR - 6.573)\\n\\n \\n\\nLiddy [1] defines NLP as a theoretically motivated range of computational techniques for analyzing and\\nrepresenting naturally occurring texts, at one or more levels of linguistic analysis for the purpose of\\nachieving human-like language processing for a range of tasks or applications. The term NLP is normally\\nused to describe the function of software or hardware components in a computer system which analyze\\nor synthesize spoken or written language [14]. The \\x80\\x98natural\\x80\\x99 epithet is meant to distinguish human\\nspeech and writing from more formal languages, such as mathematical notations or programming\\nlanguages, where vocabulary and syntax are comparatively restricted [14].\\n\\nThe research and development in NLP over the last sixty years as stated by Church and Rau [16] can be\\ncategorized into the following five areas:\\n\\nNatural Language Understanding\\n\\nNatural Language Generation\\n\\nSpeech or Voice recognition\\n\\nMachine Translation\\n\\nSpelling Correction and Grammar Checking\\n\\nThe increase demands for softwares that process text of all kinds have tremendously been influenced by\\nthe advent of the Internet and World Wide Web. Over a decade, Internet publishing has become a\\ncommon place activity for private individuals, commercial enterprises, and government organizations, as\\nwell as traditional media companies, and the medium of most of these communications and transactions\\nis primarily natural language [14]. Various forms of keyword processing provide access to Web sites as\\nwell as organizational principles for retrieving, navigating and browsing web pages within those sites.\\nSearch engines and spam filters are now of everyday life and work well enough that their viability as\\nproducts is not in question [14].\\n\\nThe language is more than transfer of information. Language is a set of resources to enable us to share\\nmeanings, but is not best thought of as a means for \\x80\\x9cencoding\\x80\\x9d meanings [16]. The foundations of NLP fall\\nwithin a number of disciplines being: computer and information sciences, linguistics, mathematics,\\nelectrical and electronic engineering, psychology, artificial intelligence and robotics, etc. NLP applications\\ncomprise a number of fields of studies, such as natural language text processing and summarization,\\n\\nmachine translation, user interfaces, multilingual and cross language information retrieval, speech\\nrecognition, artificial intelligence and expert systems, and so on ( [6]; [7] ).\\n\\n2. Scope and objective\\n\\nBased on document analysis, this paper summarizes the information on NLP, the general overview,\\nhistory, and previous works on NLP. It then considers applications of NLP. The challenges and failures of\\nNLP together with current and future research of NLP are also discussed briefly in this paper. The\\nresearch paper is intended to give an understating to researchers, scholarly peers and companies who\\nwish to stay abreast with the NLP technologies and applications from the past, present and future.\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences 208\\nEmail:- editorijrim@gmail.com, http://www.euroasiapub.org\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR - 6.573)\\n\\n \\n\\n3. Previous Works On NLP (Brief History)\\n\\nNLP research dates back to the late 1940s with Machine translation (MT) being said to be the first\\ncomputer-based application related to natural language. It was Weaver and Booth who started one of the\\nearliest MT projects in 1946, on computer translation based on expertise in breaking enemy codes during\\nWorld War II. However, a general agreement was made that, Weaver\\x80\\x99s memorandum of 1949 has brought\\nthe idea of MT to general notice and had inspired many projects. Weaver suggested using ideas from\\ncryptography and information theory for language translation [1]; [29]. According to Liddy [1] earliest\\nworks in MT followed the basic view, that the only difference between languages was vested in their\\nvocabularies and the permitted word orders. Hence systems which were made from this perspective\\nbasically used dictionary-lookup (for appropriate words for translation and reordering of the words after\\ntranslation to fit the word-order rules of the target language). This was done without considering the\\nlexical ambiguity inherent in natural language. This generated poor results and called for researchers to\\ncome up with a more sufficient theory of language. It was the Chomsky\\x80\\x99s 1957 publication [25] of the\\nsyntactic structures which introduced the idea of generative grammar [25], which gave the linguistic a\\nbetter understanding of how they could help the machine translation. Subsequently, other NLP\\napplication areas began to emerge, such as speech recognition [1].\\n\\nSince 1960 there have been some significant developments, both in production of prototype systems and\\nin theoretical issues. This has mainly focused on the issue of how to represent meaning and developing\\ncomputationally tractable solutions that the then-existing theories of grammar were not able to produce\\nbefore 1960. Examples are: Chomsky\\x80\\x99s 1965 transformational model of linguistic [25]; case grammar of\\nFillmore [26], semantic networks of Quillian [27], and conceptual dependency theory of Schank, which\\nexplained syntactic anomalies, and provided semantic representations; Formalisms representation which\\nincluded Wilks\\x80\\x99 preference semantics[28] and Kay\\x80\\x99s functional grammar; Augmented transition networks\\nof Woods which extended the power of phrase-structure grammar by incorporating mechanisms from\\nprogramming languages [10].\\n\\nBesides theoretical development, many prototype systems have been developed. According to Liddy [1]\\nthese include: Weizenbaum\\x80\\x99s ELIZA [30] which was built to replicate the conversation between a\\npsychologist and a patient, simple by permuting or echoing the user input; Winograd\\x80\\x99s SHRDLU\\nsimulation [8] of a robot that manipulated blocks on a tabletop which showed that natural language\\nunderstanding was indeed possible for the computer [8], PARRY \\x80\\x98s a theory of paranoia [31] in a system\\nwhich used groups of keywords instead of single keywords and used synonyms if keywords were not\\nfound; LUNAR developed by Woods [9] as an interface system to a database that consisted of information\\nabout lunar rock samples using augmented transition network and procedural semantics ([1];[4]).\\n\\nBy the 1970\\x80\\x99s a substantial work was done on natural language generation, for example McKeown\\x80\\x99s\\ndiscourse planner TEXT [32] and McDonald\\x80\\x99s response generator MUMMBLE [34] used rhetorical\\npredicates to create declarative descriptions in short texts form (that is paragraphs) and TEXT\\x80\\x99s which\\ngenerated comprehensible responses online. However, by the early 1980s, there was an increasing\\nawareness of the limitations of isolated solutions to NLP problems and a general push towards\\napplications that worked with language in a broad, real-world context. Since then to the present times,\\nNLP has swiftly grown. This growth could be accredited to the advent of technologies such as: Internet;\\nfast computers with increased memory; increased availability of large amounts of electronic text [1].\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences\\nEmail:- editorijrim@gmail.com, http://www.euroasiapub.org\\n\\n209\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR - 6.573)\\n\\n \\n\\n4. Natural Language Processing Overview\\n\\nGiven NLP\\x80\\x99s lineage, it is clear that many of its early theories and methods are derived from the field of\\nlinguistics [4]. A major shift was noticed in the early 1990s with the move to a reliance on empirical\\nmethodologies vs. the introspective generalizations that characterized the Chomsky era which held sway\\nin theoretical linguistics. Liddy et al., [4] contends that, the focus in NLP shifted from what might be\\npossible to do in a language and still have it be grammatically acceptable to what is actually observed to\\noccur in naturally occurring text - that is, performance data. As more and larger corpora became available,\\nempirical methods and evaluation rather than introspection-based methods and evaluation became the\\nnorm [4].\\n\\nNLP researchers are now developing next generation NLP systems that deal reasonably well with general\\ntext and account for a good portion of the variability and ambiguity of a language. Statistical approaches\\nthrived in dealing with many generic problems in computational linguistics such as part-of-speech\\nidentification, word sense disambiguation, etc.,and have become standard throughout NLP [1].\\n\\nLiddy [1]\\x80\\x99s sentiments are also shared by Liddy et al., [4] that, the availability of larger, performance-\\noriented corpora supported the use of statistical (machine learning) methods, to learn the\\ntransformations that in previous approaches were performed by hand-built rules, eventually providing\\nthe empirical proof that statistical processing could accomplish some language analysis tasks at a level\\ncomparable to human performance. Liddy et al., [4] argue further that, at the center of this move lay the\\nunderstanding that most of the work to be effected by language processing algorithms is too complex to\\nbe captured by rules constructed by human generalization, but rather require machine learning methods.\\nAccording to Ringger et al., [8] the early statistical Part-Of-Speech tagging algorithms which were used in\\nthe early times, using Hidden Markov Models were said to achieve performance comparable to humans.\\nIn the course of the test sections of the Penn Treebank [35], and also on unobserved portions of the\\nBrown Corpus [31], an up-to-date statistical parser was made known to perform more accurately than a\\nbroad-coverage rule-based parser [8]. Framing questions in the noisy channel model / information\\ntheory, with use of Probability Theory, Maximum Entropy, and Mutual Information, produced tangible\\nadvances in automatic capabilities [8].\\n\\nThe aforesaid transformations came in about because of the newly existing extensive electronic resources\\n(e.g. the sizable corpora, such as the Brown corpus and other research programs) which were collected\\nand distributed by the Linguistic Data Consortium. These were then followed by the lexical resources\\nsuch as WordNet, which provided lexical-semantic knowledge bases (i.e. it enabled use of the semantic\\nlevel of processing) and the Penn TreeBank (which provided gold standard syntactic resources that\\nsteered the development and testing of progressively rich algorithmic analysis tools [4].\\n\\nA shift from a focus on closed domains of the earliest NLP research (from the 60s through the 80s) to\\nopen domains (e.g. newswire) has been made possible and supported by the increasing availability of\\nrealistically-sized resources coupled with machine learning methods. The flaring of the domains was\\nfurther enabled by the availability of the broad ranging-textual resources of the web [4].\\n\\nOn the other hand, parallel with these moves towards use of more real world data, a realization was made\\nthat NLP researchers should evaluate their work on a larger scale, hence the introduction of empirically-\\nbased, blind evaluations across systems. These efforts led to the development of metrics such as BLEU\\nand ROUGE that are integral to today\\x80\\x99s NLP research itself, of which they can be computed automatically\\nand results fed back into the research [4]. Concomitant with these advances in statistical capabilities, but\\nmoving at a slower pace, was the demonstration that higher levels of human language analysis are\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences\\nEmail:- editorijrim@gmail.com, http://www.euroasiapub.org\\n\\n210\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR - 6.573)\\n\\n \\n\\namenable to NLP. The lower levels (morphological, lexical, and syntactic) deal with smaller units of\\nanalysis and are considered to be more rule-oriented and therefore more amenable to statistical analysis,\\nwhile the higher levels (with semantics as a middle level, and discourse and pragmatics as the higher\\nlevels) admit of more free choice and variability in usage. This is to mean that, these levels allow more\\nvariation, with more exceptions, and perhaps less regularity (e.g. Rhetorical Structure Theory in NLP by\\nMann & Thompson [10], demonstrated that even much larger units of analysis (eg., treatises,\\ninstructional guides, etc.) are amenable to computational analysis [4].\\n\\nWiebe et al., [13] state that, in information extraction, increasingly complex phenomena such as\\nsubjectivity and opinion are identified automatically. Charniak et al., [11] and Quirk et al., [12] point out\\nthat with the most recent machine translation results, syntax based MT outperforms surface-level word\\nand phrase replacement systems. These developments have resulted in the realization that NLP, by the\\nblending of statistical and symbolic methods, together with lexical resources such as WordNet, and\\nsyntactic and semantic resources such as Prop Bank, plus the availability of large scale corpora on which\\nto test and evaluate approaches, is gaining ground on the goal of realistic comprehension and production\\nof human-like language understanding [4].\\n\\n5. Applications of NLP\\n\\nAccording to Church and Rau [16], in recent years, the natural language text interpretation and\\nprocessing technologies have also gained an increasing level of sophistication. For example, generic\\nengines are now available which can deliver semantic representations for sentences, or deliver sentences\\nfrom representations. It is now possible to build very-targeted systems for specific purposes, for example,\\nfinding index terms in open text, and also the ability to judge what level of syntax analysis is appropriate.\\nNLP technologies are becoming extremely important in the creation of user-friendly decision-support\\nsystems for everyday non-expert users, particularly in the areas of knowledge acquisition, information\\nretrieval and language translation [16].\\n\\nNLP technology has progressively increased. It can be noted that this has happened because of the\\nfollowing reasons: The web has provided researchers with readily accessible corpus of electronic\\ndocument on scale that is unprecedented ; Academia has replaced a new emphasis upon empirical\\napproaches to language processing that rely more heavily upon corpus statistics than linguist theory and\\nModern networked machines are capable of processing millions of documents and performing the billions\\nof calculations to build statical profiles of large corpora[14].\\n\\nMassive quantities of text are becoming available in electronic form, ranging from published documents\\nsuch as electronic dictionaries, encyclopedias, libraries and archives for information retrieval services,\\nprivate databases, personal email and faxes [15]. Online information services are reaching mainstream\\ncomputer users. With media attention reach time, hardly a day goes by without a new article on the\\nnational information infrastructure, digital libraries, networked services, digital convergence or\\nintelligent agents. This attention is moving NLP along the critical path for all kinds of novel applications\\n[15] see Figure 1.\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences\\nEmail:- editorijrim@gmail.com, http://www.euroasiapub.org\\n\\n211\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR - 6.573)\\n\\n \\n\\n   \\n\\nNLP CONTINUUM THE\\nTECHNOLOGY\\nNL: NL Interfaces Generation From DB ENVELOPE\\nEntity Extraction\\nWP: Simple String Match Spell Checkers\\nIR: Keyword Search NL Search\\nMT: Glossary Look-up Translation Memories\\nDirect Transfer\\nState-of-the-Art\\nWell-Understood Forward-Looking\\n\\nFigure 1: A diagram showing the NLP continuum (adopted from Church and Rau [16])\\n\\nFigure 1 shows a number of technologies ranging from well-understood technologies, such as string\\nmatching, to more forward looking technologies such as grammar checkers, conceptual search, event\\nextraction, interlingual and so on.\\n\\nThere are so many examples of the aforementioned technologies, However this paper does not provide an\\nexhaustive list (not all of them will be elaborated in this paper), examples of some applications products\\nof NLP as stated by Church and Rau [16] which are given in this paper includes: Word Processing and\\nDesktop Publishing, WordPerfect (Novell) which offers Grammatik 6, which checks for grammatical\\nerrors and attempts to fix them. Microsoft has demonstrated a considerable long-term commitment to\\nimproving the technology by hiring a research group, for significant contributions to grammar checking\\n[24]. Other examples of the application products include: finite-state automata (a practical set of\\nalgorithms that efficiently represent functions from strings to strings); Transducer techniques (facilitates\\nthe retrieval of answers to service repair questions from a text database of repair manual); information\\nretrieval products such as Xerox XSoft\\x80\\x99s Visual Recall, and OCR products such as Xerox Imaging Systems\\x80\\x99\\nTextbridge; lexical products through the Desktop Document Systems (DDS) division (which uses the\\ntechnology to create a range of multilingual components that can be embedded in information retrieval,\\ntranslation, and other document management applications);spelling checkers (e.g. The Xerox Memory-\\nWriter typewriter). Kaplan and Kay have been working on these issues for over a decade at Xerox PARC\\n[22].\\n\\nThe applications (such as the spell checker for the Xerox MemoryWriter typewriter) were the basis for a\\nstart-up company called Microlytics, formed in 1985 and later (1987) merged into the publically traded\\nSelectronics Corp [16]. Through Microlytics, the original Kaplan and Kay algorithms found their way into\\nspelling checkers and thesaurii, such as those included in popular systems such as Micropro, Claris,\\nMacWrite II, Microsoft Word 4 (the thesaurus), Symantec, and WordFinder software sold to the PC and\\nApple Macintosh user community.\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences\\nEmail:- editorijrim@gmail.com, http://www.euroasiapub.org\\n\\n212\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR \\x80\\x94 6.573)\\n\\n \\n\\nThe hand-held language-related device market is now dominated by such companies as Casio,\\nSeiko, Fuji, Xerox, Eurotronics, Franklin, Sharp and other primarily Asian manufacturers [16]. Word\\nprocessing and information management were previously cited as two of the better examples of\\ncommercial opportunities for natural language processing [16]. The importance of information\\nmanagement is beginning to be appreciated as vast quantities of text become available in electronic\\nform: digital libraries, it wasn\\x80\\x99t all that long ago that the researchers referred to the Brown Corpus\\nas a \\x80\\x9clarge\\x80\\x9d corpus [21]; [31]. However, Dialog, Westlaw, Lexis-Nexis and other major vendors of\\nonline information services are archiving hundreds of megabytes per night, the equivalent of one\\nBrown Corpus per hour [16]. Another significant recent development on NLP applications is the\\ndevelopment of a speller checker for the Tswana native language, which has been designed to\\nwork on the Mozilla Firefox software and Libre-Office application [19].\\n\\n6. Challenges and failures\\n\\nChurch and Rau [16] points out that even though we should know better, it is so appealing to\\nfantasize about intelligent computers that understand human communication, that hyperbole is\\npractically unavoidable. Sometimes these practices work out for the best. Symantec, for example, a\\nhighly successful vendor of software tools for the PC, started with a product called Q&A, an NLP\\nprogram for querying a database. The Q&A was successful because of its unique packaging of\\nAI/NLP with a good simple database facility. Neither would have been successful in isolation. The\\nAI/NLP generated initial sales, but the real value was in the database. People bought the product\\nbecause they were intrigued with the AIl/NLP technology, but most users ended up turning off the\\nAI/NLP features [20]. But all too often excessive optimism results in a manic-like cycle of euphoric\\nactivity followed by severe depression. In 1954, Georgetown University demonstrated what would\\nnow be called a \\x80\\x9ctoy\\x80\\x9d system. It was designed to translate a small corpus of approximately 50\\nRussian sentences into English. Little ifany attempt was made to generalize to sentences beyond\\nthe tiny test corpus [16]; [29].\\n\\nThe limitations of today\\x80\\x99s practical language processing technology have been summarized by\\nBobrow and Weischedel [18] as follows:\\n\\n1. Current systems have limited discourse capabilities that are almost ex-clusively\\nhandcrafted. Thus current systems are limited to viewing interaction, translation, and\\nwriting text as processing a sequence of either isolated sentences or loosely related\\nparagraphs. Consequently, the user must adapt to such limited discourse.\\n\\n2. Domains must be narrow enough so that the constraints on the relevant semantic concepts\\nand relations can be expressed using current knowledge presentation techniques, i.e.,\\nprimarily in terms of types and sorts. Processing may be viewed abstractly as the\\napplication of recursive tree re-writing rules, including filtering out trees not matching a\\ncertain pattern.\\n\\n3. Handcrafting is necessary, particularly in the grammatical components of systems (the\\ncomponent technology that exhibits least dependence on the application domain). Lexicons\\nand axiomatizations of critical facts must be developed for each domain, and these remain\\ntime-consuming tasks.\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences 207\\nEmail:- editorijrim@gmail.com, http://www-.euroasiapub.org\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR \\x80\\x94 6.573)\\n\\n \\n\\n4. The user must still adapt to the machine, but, as the products testify, the user can do so\\neffectively.\\n\\n7. Current and Future progress of NLP\\n\\nSome of the active researches on NLP phenomena include the Syntactic phenomena: those that\\npertain to the structure of a sentence and the order of words in the sentence, based on the\\ngrammatical classes of words rather than their meaning (e.g. discriminative models for scoring\\nparses, coarse to fine efficient approximate parsing, dependency grammar); Machine translation\\n(e.g. models and algorithms, low- resource and morphological complex language); Semantic\\nphenomena : those that pertain to the meeting of a sentence relatively independent of the context in\\nwhich the language occurs(e.g. sentiment analysis, summarization, information extraction ,slot-\\nfilling, discourse analysis, textual entailment);Pragmatic phenomena such as Speech: those that\\nrelate the meaning of a sentence to the context in which it occurs. This context can be linguistic\\n(such as the previous text or dialogue) or, non-linguistic (such as knowledge about person who\\nproduced the language, about goals of the communication, about the objects in the current visual\\nfield, etc. (e.g. language modelling-syntax and semantics, models of acoustics, pronunciation) [17];\\n[18]. Speech recognition and information retrieval have finally gone commercial and there is a ton\\nof text and speech on the Internet, cell phones, etc. It is now clear that studies regarding anything\\nabout a language are possible, e.g. formalizing some insights e.g. discrete knowledge (what is\\npossible) and continuous knowledge (what is likey); studying the formalism mathematically;\\ndeveloping and implementing algorithms and testing on real data. The current and on-going future\\nchanges or improvements which need to be done to NLP are: to add features to existing interfaces,\\nback end processing should be fully implemented (e.g. information extraction and normalization to\\nbuild databases. Another anticipated improvement is of having hand held devices with translators\\nand personal conversation recorder with topical searches [17].\\n\\n8. Conclusions\\n\\nAs a computerized approach of analyzing text, NLP is continually striving forward. Researchers are\\ncontinually trying to gather knowledge on how human beings understand and use various\\nlanguages. This aid in the development of appropriate tools and techniques which make computer\\nsystems understand and manipulate natural languages to perform the various tasks. Technologies,\\nsuch as string matching, keyword search, glossary lookup are now on the past as, to more forward\\nlooking technologies such as grammar checkers, conceptual search, event extraction, interlingual on\\ngoing and striving forward.\\n\\nReferences\\n\\n[1] E.D. Liddy, Natural Language Processing, 2001.\\n\\n[2] N. Kaur1, V. Pushe and R Kaur,\\x80\\x99Natural Language Processing Interface for Synonym\\x80\\x9d,\\nInternational Journal of Computer Science and Mobile Computing, Vol.3 Issue.7, July- 2014, pp.\\n638-642 ISSN 2320-088xX.\\n\\n[3] S. Vijayarani1, J. Ilamathi and Nithya, \\x80\\x9cPreprocessing Techniques for Text Mining - An\\nOverview\\x80\\x9d, International Journal of Computer Science & Communication Networks, Vol.5,\\nissue.1, pp. 7-16 7 ISSN: 2249-5789\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences 208\\nEmail:- editorijrim@gmail.com, http://www-.euroasiapub.org\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR \\x80\\x94 6.573)\\n\\n \\n\\n[4]L.Liddy, E. Hovy, J.Lin, J.Prager, D. Radev, L.Vanderwende, R.Weischedel, \\x80\\x9cNatural Language\\nProcessing\\x80\\x9d, This report is one of five reports that were based on the MINDS workshops.\\n\\n[5] G.Chowdhury, \\x80\\x9cNatural language processing\\x80\\x9d, Annual Review of Information Science and\\nTechnology, 2003, 37. pp. 51-89, ISSN 0066-4200.\\n\\n[6] S. Jusoh and H.M. Alfawareh, \\x80\\x9cNatural language interface for online sales\\x80\\x9d, in Proceedings of the\\nInternational Conference on Intelligent and Advanced System (ICIAS2007),Malaysia: IEEE,\\nNovember 2007, pp. 224-228\\n\\n[7] E.K. Ringger, R.C. Moore, E. Charniak, L. Vanderwende, and H Suzuki, \\x80\\x9cUsing the Penn Treebank\\nto Evaluate Non-Treebank Parsers\\x80\\x9d, In Proceedings of the 2004 Language Resources and\\nEvaluation Conference (LREC), 2004, Lisbon, Portugal.\\n\\n[8] T. Winograd, Procedures as a Representation for Data in a Computer Program for\\nUnderstanding Natural Language, 1971, MIT-AI-TR-235\\n\\n[9] W. A. Woods, \\x80\\x9cTransition Network Grammars for Natural Language Analysis\\x80\\x9d, Communications\\nof the ACM 13:10, 1970.\\n\\n[10] W.C. Mann & S. Thompson, \\x80\\x9cRhetorical Structure Theory: Toward a Functional Theory of Text\\nOrganization\\x80\\x9d, 1988. Text 8 (3). Pp. 243-281.\\n\\n[11] E. Charniak, K. Knight, and K.Yamada, \\x80\\x9cSyntax-based Language Models for Statistical Machine\\nTranslation\\x80\\x9d. In Proceedings of MT Summit IX, 2003.\\n\\n[12] C. Quirk, A. Menezes and C. Cherry, \\x80\\x9cDependency Treelet Translation: Syntactically Informed\\nPhrasal SMT\\x80\\x9d. In Proceedings of the 43rd Annual Meeting of the Association for Computational\\nLinguistics, Ann Arbor, Michigan, 2005.\\n\\n[13] J. Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis, B. Fraser, D. Litman, D. Pierce, E. Riloff, T.\\nWilson, D. Day, and M. Maybury, \\x80\\x9cRecognizing and Organizing Opinions Expressed in the World\\nPress\\x80\\x9d. In Proceedings of 2003 AAAI Spring Symposium on New Directions in Question Answering,\\n2003.\\n\\n[14] P. Jackson and I. Moulinier,\\x80\\x9dNatural Language Processing for Online Applications\\x80\\x9d: Cambridge\\nUniversity press, New York.2012, page 7-9.\\n\\n[15] R. Bose. \\x80\\x9cNatural language processing: Current state and future directions\\x80\\x9d. International\\nJournal of the Computer, the Internet and Management Vol. 12#1 (January - April, 2004) pp. 1 -\\n11.\\n\\n[16] K. W Church and L.F Rau,\\x80\\x9d Commercial applications of Natural Language Processing\\x80\\x9d.\\nCommunication of the ACM, vol 38, No. 11,November 1995\\n\\n[17] J. Eisner. Current and future NLP research.\\n\\n[18] R. J Bobrow and R.M. Weischedel, \\x80\\x9cChallenges in Natural Language Processing,\\x80\\x9d Cambridge\\nUniversity press, New York.1993\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences 209\\nEmail:- editorijrim@gmail.com, http://www-.euroasiapub.org\\n\\x0cUREAS VOLUME 6, ISSUE 3 (March, 2016) (ISSN 2249-3905)\\nInternational Journal of Research in Engineering and Applied Sciences (IMPACT FACTOR \\x80\\x94 6.573)\\n\\n \\n\\n[19] D. Bailey et al.,\\x80\\x99Tswana Spell Checker\\x80\\x9d, available online:\\nhttps://addspns.mozilla.org/.../fi.../addon/tswana-spell-checker.last accessed 11/14/2015.\\n\\n[20] W. Frakes and R., Baeza-Yates, Eds,\\x80\\x9d Information Retrieval: Data Structures & Algorithms\\x80\\x9d.\\nPrentice Hall, Englewood Cliffs, NJ, 1992.\\n\\n[22] W. Francis and H .K. Houghton Mifflin, Brown University, 1982.\\n\\n[23] R.M. Kaplan and M. Kay, \\x80\\x9cRegular models of phonological rule systems\\x80\\x9d, American J.\\nComputational Linguistics, 1994.\\n\\n[24] K., Jensen, G. Heidorn, and S. Richardson, \\x80\\x9cNatural Languag Processing: The PLNLP Approach,\\x80\\x9d\\nKluwer Academic Publisher, Boston, 1993\\n\\n[25] N. Chomsky.Syntatic structures.The Hague: Mouton & Co. Reprinetd 1978,Peter Lang\\nPublisjing\\n\\n[26] C.J. Fillmore,\" The Case for Case\". In Bach and Harms (Ed.)}: Universals in Linguistic Theory.\\nNew York: Holt, Rinehart, and Winston, 1-88, 1968.\\n\\n[27] R. Quillian, \\x80\\x9cA notation for representing conceptual information: An application to semantics\\nand mechanical English para- phrasing\\x80\\x9d, SP-1395, System Development Corporation, Santa Monica,\\n1963.\\n\\n[28] Y. Wilks, Preference Semantics\",1973.\\n\\n[29] J. Hutchins.,\\x80\\x9dThe history of Machine translation in a nutshell\\x80\\x9d Available[online] :\\nhttp://ourworld.compuserve.com/homepages/WJHutchins,Revised November 2005.Retrieved\\n11/13/2015.\\n\\n[30] J. Weizenbaum, \\x80\\x9cELIZA-A Computer Program For the Study of Natural Language\\nCommunication Between Man And Machine\", Communications of the ACM Vol.9., No.1pp:36-\\n45,January 1966), doi:10.1145/365153.365168\\n\\n[31] V. Cerf, \\x80\\x9cPARRY encounters the DOCTOR ,\"IETF. RFC 439,\\x80\\x9d21 January 1972.\\n\\n[32] K. R McKeown., \\x80\\x9cDiscourse Strategies for generating Natural Language Text\\x80\\x9d. Artificial\\nIntelligence.\\n\\n[33] W.N. Francis and H. Kucera,\\x80\\x9dThe Brown Corpus Manual\\x80\\x9d,1964,Available[online]:\\nhttp://clu.unino/icame/brown/bcm.html.Accessed: 13/11/2015\\n\\n[34] R. Rubinoff, \\x80\\x9cAdapting MUMBLE: experience with natural Language generation\\x80\\x9d, Published in\\nProceeding HLt\\x80\\x9986 Proceedings of the workshop on Strategic computing natural language pp. 200-\\n211.\\n\\n[35] A. Taylor, \\x80\\x9cThe Penn Tree bank: Overview,\\x80\\x9d Available at http://www.ldc.upenn.edu\\n\\n \\n\\nInternational Journal of Research in Engineering & Applied Sciences 210\\nEmail:- editorijrim@gmail.com, http://www-.euroasiapub.org\\n\\x0c'] ...\n",
      "\n",
      "\n",
      "RESULT 3 : File Name :  ELSEVIER ENHANCED READER.TXT \n",
      " ['Neural Networks 113 (2019} 54-71\\n\\n \\n\\nContents lists available at ScienceDirect\\n\\nNeural Networks\\n\\n \\n\\njournal homepage: www.elsevier.com/ocate/neunet\\n\\n \\n\\n \\n\\nReview\\n\\nContinual lifelong learning with neural networks: A review nA\\n\\nCheck for\\nupdates,\\n\\nGerman I. Parisi\\x80\\x9d, Ronald Kemker\\x80\\x9d, Jose L. Part\\x80\\x98, Christopher Kanan\\x80\\x9d, Stefan Wermter*\\n* Knowledge Technology, Department of Informatics, Universitt Hamburg, Germany\\n\\n Chester F. Cartson Center for Imaging Science, Rochester Institute of Technology, NY, USA\\n\\n Department of Computer Science, Heriot-Watt University, Edinburgh Centre for Robotics, Scotland, UK\\n\\n \\n\\nARTICLE [NFO ABSTRACT\\n\\n \\n\\nArticle history: Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and\\nReceived 6 July 2018 skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set\\nReceived in revised form 18 January 2019 of neurocognitive mechanisms that together contribute to the development and specialization of our\\nAccepted 22 January 2019 sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong\\nAvailable online 6 February 2019 learning capabilities are crucial for computational learning systems and autonomous agents interacting\\n\\nKeywords: in the real world and processing continuous streams of information. However, lifelong learning remains\\nContinual learning a long-standing challenge for machine learning and neural network models since the continual acqui-\\nLifelong learning sition of incrementally available information from non-stationary data distributions generally leads to\\nCatastrophic forgetting catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-\\nDevelopmental systems art deep neural network models that typically learn representations from stationary batches of training\\n\\nMemory consolidation data, thus without accounting for situations in which information becomes incrementally available over\\n\\ntime. In this review, we critically summarize the main challenges linked to lifelong learning for artificial\\nlearning systems and compare existing neural network approaches that alleviate, to different extents,\\ncatastrophic forgetting. Although significant advances have been made in domain-specific learning with\\nneural networks, extensive research efforts are required for the development of robust lifelong learning on\\nautonomous agents and robots. We discuss well-established and emerging research motivated by lifelong\\nlearning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer\\n\\nlearning, intrinsic motivation, and multisensory integration.\\n 2019 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND\\nlicense (http: //creativecommons.org/licenses/by-ne-nd/4.0/}.\\n\\n \\n\\nContents\\n\\n1. Introduction... \\x80\\x9c\\n2. Biological aspects of lifelong learning ...\\n2.1. The Stability\\x80\\x94Plasticity Dilemma..\\n2.2. Hebbian plasticity and stability...........\\n2.3. The complementary learning systems\\n24. Learning without forgetting ... .\\n3. Lifelong learning and catastrophic forgetting i in n neural networks.\\n3.1. Lifelong machine learning\\n3.2. Regularization approaches ..\\n3.3. Dynamic architectures ..\\n34. Complementary learning systems and memory Y replay\\n3.5. Benchmarks and evaluation metrics.. .\\n4. Developmental approaches and auitonomous agents ,\\n4.1. Towards autonomous agents... sean\\n42. Developmental and curriculum learning.\\n43. Transfer learning ... we\\n44. Curiosity and intrinsic \\x80\\x98motivation\\n4.5. Multisensory learning\\n5. Conclusion... eee eee\\n\\n \\n\\n \\n  \\n \\n \\n  \\n \\n \\n  \\n \\n \\n\\n* Correspondence to: Knowledge Technology, Department of Informatics, Universitat Hamburg, Vogt-Koelln-Strasse 30, Hamburg 22527, Germany.\\nE-mail address: parisi@informatik.uni-hamburg.de (G.I. Parisi}.\\n\\nhttps://doi.org/10.1016/j neunet.2019.01.012\\n\\n0893-6080/G 2019 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-ne-\\nnd/4.0/}.\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 55\\n\\nAcknowledgements ...\\nReferences ....... cee\\n\\n  \\n\\n \\n\\n1. Introduction\\n\\nComputational systems operating in the real world are exposed\\nto continuous streams ofinformation and thus are required to learn\\nand remember multiple tasks from dynamic data distributions.\\nFor instance, an autonomous agent interacting with the environ-\\nment is required to learn from its own experiences and must\\nbe capable of progressively acquiring, fine-tuning, and transfer-\\nring knowledge over long time spans. The ability to continually\\nlearn over time by accommodating new knowledge while retaining\\npreviously learned experiences is referred to as continual or life-\\nlong learning. Such a continuous learning task has represented a\\nlong-standing challenge for machine learning and neural networks\\nand, consequently, for the development of artificial intelligence\\n(Al) systerns (Hassabis, Kumaran, Summerfield, & Botvinick, 2017;\\nThrun & Mitchell, 1995).\\n\\nThe main issue of computational models regarding lifelong\\nlearning is that they are prone to catastrophic forgetting or catas-\\ntrophic interference, i.e., training a model with new information\\ninterferes with previously learned knowledge (McClelland, Mc-\\nNaughton, & O\\'Reilly, 1995; McCloskey & Cohen, 1989}. This phe-\\nnomenon typically leads to an abrupt performance decrease or,\\nin the worst case, to the old knowledge being completely over-\\nwritten by the new one. Current deep neural network learning\\nmodels excel at a number of classification tasks by relying on\\na large batch of (partially) annotated training samples (see Guo\\net al. (2016) and LeCun, Bengio, and Hinton (2015) for reviews).\\nHowever, such a learning scheme assumes that all samples are\\navailable during the training phase and, therefore, requires the\\nretraining of the network parameters on the entire dataset in order\\nto adapt to changes in the data distribution. When trained on\\nsequential tasks with samples becoming progressively available\\nover time, the performance of conventional neural network models\\nsignificantly decreases on previously learned tasks as new tasks\\nare learned (Kemker, McClure, Abitino, Hayes, & Kanan, 2018;\\nMaltoni & Lomonaco, 2018). Although retraining from scratch\\npragmatically addresses catastrophic forgetting, this methodol-\\nogy is very inefficient and hinders the learning of novel data in\\nreal time. For instance, in scenarios of developmental learning\\nwhere autonomous agents learn by actively interacting with the\\nenvironment, there may be no distinction between training and\\ntest phases, requiring the learning model to concurrently adapt\\nand timely trigger behavioural responses (Cangelosi & Schlesinger,\\n2015; Tani, 2016).\\n\\nFor overcoming catastrophic forgetting, learning systems must,\\non the one hand, show the ability to acquire new knowledge and\\nrefine existing knowledge on the basis of the continuous input\\nand, on the other hand, prevent the novel input from significantly\\ninterfering with existing knowledge. The extent to which a sys-\\ntem must be plastic in order to integrate novel information and\\nstable in order not to catastrophically interfere with consolidated\\nknowledge is known as the stability-plasticity dilemma and has\\nbeen widely studied in both biological systems and computational\\nmodels (Ditzler, Roveri, Alippi, & Polikar, 2015; Grossberg, 1980,\\n2012; Mermillod, Bugaiska, & Bonin, 2013). Due to the very chal-\\nlenging but high-impact aspects of lifelong learning, a large body\\nof computational approaches have been proposed that take inspi-\\nration from the biological factors of learning from the mammalian\\nbrain.\\n\\nHumans and other animals excel at learning in a lifelong man-\\nner, making the appropriate decisions on the basis of\\n\\nsensorimotor contingencies learned throughout their lifespan\\n(Bremner, Lewkowicz, & Spence, 2012; Tani, 2016). The ability to\\nincrementally acquire, refine, and transfer knowledge over sus-\\ntained periods of time is mediated by a rich set of neurophysio-\\nlogical processing principles that together contribute to the early\\ndevelopment and experience-driven specialization of perceptual\\nand motor skills (Lewkowicz, 2014; Murray, Lewkowicz, Amedi,\\n& Wallace, 2016; Power & Schlaggar, 2016; Zenke, Gerstner and\\nGanguli, 2017). In Section 2, we introduce a set of widely stud-\\nied biological aspects of lifelong learning and their implications\\nfor the modelling of biologically motivated neural network ar-\\nchitectures. First, we focus on the mechanisms of neurosynaptic\\nplasticity that regulate the stability\\x80\\x94plasticity balance in multiple\\nbrain areas (Sections 2.2 and 2.3}. Plasticity is an essential fea-\\nture of the brain for neural malleability at the level of cells and\\ncircuits (see Power and Schlaggar (2016) a survey). For a stable\\ncontinuous lifelong process, two types of plasticity are required:\\n(i) Hebbian plasticity (Hebb, 1949) for positive feedback instability,\\nand (ii} compensatory homeostatic plasticity which stabilizes neu-\\nral activity. It has been observed experimentally that specialized\\nmechanisms protect knowledge about previously learned tasks\\nfrom interference encountered during the learning of novel tasks\\nby decreasing rates of synaptic plasticity (Cichon & Gan, 2015).\\nTogether, Hebbian learning and homeostatic plasticity stabilize\\nneural circuits to shape optimal patterns of experience-driven\\nconnectivity, integration, and functionality (Abraham & Robins,\\n2005; Zenke, Gerstner et al., 2017).\\n\\nImportantly, the brain must carry out two complementary\\ntasks: generalize across experiences and retain specific memories\\nof episodic-like events. In Section 2.4, we summarize the comple-\\nmentary learning systems (CLS) theory (Kumaran, Hassabis, & Mc-\\nClelland, 2016; McClelland et al., 1995) which holds the means for\\neffectively extracting the statistical structure of perceived events\\n(generalization) while retaining episodic memories, i.e., the collec-\\ntion of experiences at a particular time and place. The CLS theory\\ndefines the complementary contribution of the hippocampus and\\nthe neocortex in learning and memory, suggesting that there are\\nspecialized mechanisms in the human cognitive system for pro-\\ntecting consolidated knowledge. The hippocampal system exhibits\\nshort-term adaptation and allows for the rapid learning of new\\ninformation which will, in turn, be transferred and integrated into\\nthe neocortical system for its long-term storage. The neocortex is\\ncharacterized by a slow learning rate and is responsible for learning\\ngeneralities. However, additional studies in learning tasks with\\nhuman subjects (Mareschal, Johnson, Sirios, Spratling, Thomas,\\n& Westermann, 2007; Pallier et al., 2003) observed that, under\\ncertain circumstances, catastrophic forgetting may still occur (see\\nSection 2.4}.\\n\\nStudies on the neurophysiological aspects of lifelong learning\\nhave inspired a wide range of machine learning and neural network\\napproaches. In Section 3, we introduce and compare computational\\napproaches that address catastrophic forgetting. We focus on re-\\ncent learning models that (i) regulate intrinsic levels of synap-\\ntic plasticity to protect consolidated knowledge (Section 3.2);\\n(ii) allocate additional neural resources to learn new information\\n(Section 3.3), and (iii) use complementary learning systems for\\nmemory consolidation and experience replay (Section 3.4). The\\nvast majority of these approaches are designed to address lifelong\\nsupervised learning on annotated datasets of finite size (e.g., Kirk-\\npatrick et al. (2017), Zenke, Poole and Ganguli et al. (2017)) and\\ndo not naturally extend to more complex scenarios such as the\\n\\x0c56 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\nprocessing of partially unlabelled sequences. Unsupervised\\nlifelong learning, on the other hand, has been proposed mostly\\nthrough the use of self-organizing neural networks (e.g., Parisi,\\nTani, Weber, and Wermter (2017), Parisi, Tani, Weber and Wermter\\n(2018) and Richardson and Thomas (2008}). Although significant\\nadvances have been made in the design of learning methods with\\nstructural regularization or dynamic architectural update, consid-\\nerably less attention has been given to the rigorous evaluation\\nof these algorithms in lifelong and incremental learning tasks.\\nTherefore, in Section 3.5 we discuss the importance of using and\\ndesigning quantitative metrics to measure catastrophic forgetting\\nwith large-scale datasets.\\n\\nLifelong learning has recently received increasing attention due\\nto its implications in autonomous learning agents and robots. Neu-\\nral network approaches are typically designed to incrementally\\nadapt to modality-specific, often synthetic, data samples collected\\nin controlled environments, shown in isolation and random order.\\nThis differs significantly from the more ecological conditions hu-\\nmans and other animals ate exposed to throughout their lifespan\\n(Cangelosi & Schlesinger, 2015; Krueger & Dayan, 2009; Skinner,\\n1958; Wermter, Palm, & Elshaw, 2005}. Agents operating in the real\\nworld must deal with sensory uncertainty, efficiently process con-\\ntinuous streams of multisensory information, and effectively learn\\nmultiple tasks without catastrophically interfering with previously\\nlearned knowledge. Intuitively, there is a huge gap between the\\nabove-mentioned neural network models and more sophisticated\\nlifelong learning agents expected to incrernentally learn from their\\ncontinuous sensorimotor experiences.\\n\\nHumans can easily acquire new skills and transfer knowledge\\nacross domains and tasks (Barnett & Ceci, 2002) while artificial\\nsystems are still in their infancy regarding what is referred to as\\ntransfer learning (Weiss, Khoshgoftaar, & Wang, 2016). Further-\\nmore, and in contrast with the predominant tendency to train\\nneural network approaches with uni-sensory (e.g., visual or au-\\nditory) information, the brain benefits significantly from the in-\\ntegration of multisensory information, providing the means for\\nan efficient interaction also in situations of sensory uncertainty\\n(Bremner et al., 2012: Spence, 2010; Stein, Stanford, & Rowland,\\n2014). The multisensory aspects of early development and senso-\\nrimotor specialization in the brain have inspired a large body of re-\\nsearch on autonomous embodied agents (Cangelosi & Schlesinger,\\n2015; Lewkowicz, 2014). In Section 4, we review computational\\napproaches motivated by biological aspects of learning which\\ninclude critical developmental stages and curriculum learning\\n(Section 4.2), transfer learning for the reuse of knowledge during\\nthe learning of new tasks (Section 4.3), reinforcement learning for\\nthe autonomous exploration of the environment driven by intrinsic\\nmotivation and self-supervision (Section 4.4), and multisensory\\nsystems for crossmodal lifelong learning (Section 4.5}.\\n\\nThis review complements previous surveys on catastrophic for-\\ngetting in connectionist models (French, 1999; Goodfellow, Mirza,\\nXiao, Courville, & Bengio, 2013; Soltoggio, Stanley, & Risi, 2017)\\nthat do not critically compare recent experimental work (e.g., deep\\nlearning) or define clear guidelines on how to train and evalu-\\nate lifelong approaches on the basis of experimentally observed\\ndevelopmental mechanisms. Together, our and previous reviews\\nhighlight lifelong learning as a highly interdisciplinary challenge.\\nAlthough the individual disciplines may have more open questions\\nthan answers, the combination of these findings may provide a\\nbreakthrough with respect to current ad-hoc approaches, with\\nneural networks being the stepping stone towards the increas-\\ningly sophisticated cognitive abilities exhibited by AI systerns. In\\nSection 5, we summarize the key ideas presented in this review\\nand provide a set of ongoing and future research directions.\\n\\n2. Biological aspects of lifelong learning\\n2.1. The Stability-Plasticity Dilemma\\n\\nAs humans, we have an astonishing ability to adapt by effec-\\ntively acquiring knowledge and skills, refining them on the basis of\\nnovel experiences, and transferring ther across multiple domains\\n(Barnett & Ceci, 2002; Bremner et al., 2012; Calvert, Spence, &\\nStein, 2004). While it is true that we tend to gradually forget pre-\\nviously learned information throughout our lifespan, only rarely\\ndoes the learning of novel information catastrophically interfere\\nwith consolidated knowledge (French, 1999}. For instance, the hu-\\nman somatosensory cortex can assimilate new information during\\nmotor learning tasks without disrupting the stability of previously\\nacquired motor skills (Braun et al., 2001). Lifelong learning in the\\nbrain is mediated by a rich set of neurophysiological principles\\nthat regulate the stability\\x80\\x94plasticity balance of the different brain\\nareas and that contribute to the development and specialization of\\nour cognitive system on the basis of our sensorimotor experiences\\n(Lewkowicz, 2014; Murray et al., 2016; Power & Schlaggar, 2016;\\nZenke, Gerstner et al., 2017). The stability\\x80\\x94-plasticity dilemma re-\\ngards the extent to which a system must be prone to integrate and\\nadapt to new knowledge and, importantly, how this adaptation\\nprocess should be compensated by internal mechanisms that stabi-\\nlize and modulate neural activity to prevent catastrophic forgetting\\n(Ditzler et al., 2015; Mermillod et al., 2013)\\n\\nNeurosynaptic plasticity is an essential feature of the brain\\nyielding physical changes in the neural structure and allowing us to\\nlearn, remember, and adapt to dynamic environments (see Power\\nand Schlaggar (2016) for a survey). The brain is particularly plastic\\nduring critical periods of early development in which neural net-\\nworks acquire their overarching structure driven by sensorimotor\\nexperiences. Plasticity becomes less prominent as the biological\\nsystem stabilizes through a well-specified set of developmental\\nstages, preserving a certain degree of plasticity for its adaptation\\nand reorganization at smaller scales (Hensch et al., 1998; Kiyota,\\n2017; Quadrato, Elnaggar, & Di Giovanni, 2014). The specific pro-\\nfiles of plasticity during critical and post-developmental periods\\nvary across biological systems (Uylings, 2006), showing a consis-\\ntent tendency to decreasing levels of plasticity with increasing\\nage (Hensch, 2004). Plasticity plays a crucial role in the emer-\\ngence of sensorimotor behaviour by complementing genetic in-\\nformation which provides a specific evolutionary path (Grossberg,\\n2012). Genes or molecular gradients drive the initial development\\nfor granting a rudimentary level of performance from the start\\nwhereas extrinsic factors such as sensory experience complete\\nthis process for achieving higher structural complexity and perfor-\\nmance (Hirsch & Spinelli, 1970; Shatz, 1996; Sur & Leamey, 2001).\\nIn this review, we focus on the developmental and learning aspects\\nof brain organization while we refer the reader to Soltoggio et al.\\n(2017) for a review of evolutionary imprinting.\\n\\n2.2. Hebbian plasticity and stability\\n\\nThe ability of the brain to adapt to changes in its environment\\nprovides vital insight into how connectivity and function of the\\ncortex are shaped. It has been shown that while rudimentary\\npatterns of connectivity in the visual system are established in\\nearly development, normal visual input is required for the correct\\ndevelopment of the visual cortex. The seminal work of Hubel and\\nWiesel (1967} on the emergence of ocular dominance showed\\nthe importance of timing of experience on the development of\\nnormal patterns of cortical organization. The visual experience of\\nnewborn kittens was experimentally manipulated to study the\\neffects of varied input on brain organization. They observed that\\nthe disruption of cortical organization was more severe when the\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 57\\n\\ndeprivation of visual input began prior to ten weeks of age while no\\nchanges were observed in adult animals. Additional experiments\\nshowed that neural patterns of cortical organization can be driven\\nby external environmental factors at least for a period early in\\ndevelopment (Hubel & Wiesel, 1962, 1970; Hubel, Wiesel, & LeVay,\\n1977).\\n\\nThe most well-known theory describing the mechanisms of\\nsynaptic plasticity for the adaptation of neurons to external stimuli\\nwas first proposed by Hebb (1949), postulating that when one neu-\\nron drives the activity of another neuron, the connection between\\nthem is strengthened. More specifically, the Hebb\\x80\\x99s rule states that\\nthe repeated and persistent stimulation of the postsynaptic cell\\nfrom the presynaptic cell leads to an increased synaptic efficacy.\\nThroughout the process of development, neural systems stabilize\\nto shape optimal functional patterns of neural connectivity. The\\nsimplest form of Hebbian plasticity considers a synaptic strength\\nw which is updated by the product of a pre-synaptic activity x and\\nthe post-synaptic activity y:\\n\\nAw =x-y-n, (1)\\n\\nwhere 7 is a given learning rate. However, Hebbian plasticity alone\\nis unstable and leads to runaway neural activity, thus requiring\\ncompensatory mechanisms to stabilize the learning process (Ab-\\nbott & Nelson, 2000; Bienenstock, Cooper, & Munro, 1982). Stability\\nin Hebbian systems is typically achieved by augmenting Hebbian\\nplasticity with additional constraints such as upper limits on the\\nindividual synaptic weights or average neural activity (Miller &\\nMacKay, 1994; Song, Miller, & Abbott, 2000). Horneostatic mech-\\nanisms of plasticity include synaptic scaling and meta-plasticity\\nwhich directly affect synaptic strengths (Davis, 2006; Turrigiano,\\n2011}. Without loss of generality, homeostatic plasticity can be\\nviewed as a modulatory effect or feedback control signal that\\nregulates the unstable dynamics of Hebbian plasticity (see Fig. 1a).\\nThe feedback controller directly affects synaptic strength on the\\nbasis of the observed neural activity and must be fast in relation to\\nthe timescale of the unstable system (Astrm & Murray, 2010). In\\nits simplest form, modulated Hebbian plasticity can be modelled\\nby introducing an additional modulatory signal m to Eq. (1) such\\nthat the synaptic update is given by\\n\\nAw =m-x-y-7. (2)\\n\\nModulatory feedback in Hebbian neural networks has received\\nincreasing attention, with different approaches proposing biologi-\\ncally plausible learning through modulatory loops (Grant, Tanner,\\n& Itti, 2017; Soltoggio et al. 2017). For a critical review of the\\ntemporal aspects of Hebbian and homeostatic plasticity, we refer\\nthe reader to Zenke, Gerstner et al. (2017).\\n\\nEvidence on cortical function has shown that neural activity in\\nmultiple brain areas results from the combination of bottom-up\\nsensory drive, top-down feedback, and prior knowledge and ex-\\npectations (Heeger, 2017). In this setting, complex neurodynamic\\nbehaviour can emerge from the dense interaction of hierarchically\\narranged neural circuits in a self-organized manner (Tani, 2016).\\nInput-driven self-organization plays a crucial role in the brain\\n(Nelson, 2000}, with topographic maps being a common feature\\nof the cortex for processing sensory input (Willshaw & von der\\nMalsburg, 1976). Different models of neural self-organization have\\nbeen proposed that resemble the dynamics of basic biological\\nfindings on Hebbian-like learning and plasticity (Fritzke, 1992;\\nKohonen, 1982; Marsland, Shapiro, & Nehmzow, 2002; Martinetz,\\nBerkovich, & Schulten, 1993}, demonstrating that neural map or-\\nganization results from unsupervised, statistical learning with\\nnonlinear approximations of the input distribution. To stabilize the\\nunsupervised learning process, neural network self-organization\\ncan be complemented with top-down feedback such as task-\\nrelevant signals that modulate the intrinsic map plasticity (Parisi\\n\\net al., 2018; Soltoggio et al., 2017). In a hierarchical processing\\nregime, neural detectors have increasingly large spatio-temporal\\nreceptive fields to encode information over larger spatial and tem-\\nporal scales (Hasson, Yang, Vallines, Heeger, & Rubin, 2008; Taylor,\\nHobbs, Burroni, & Siegelmann, 2015). Thus, higher-level layers\\ncan provide the top-down context for modulating the bottom-\\nup sensory drive in lower-level layers. For instance, bottom-up\\nprocessing is responsible for encoding the co-occurrence statis-\\ntics of the environment while error-driven signals modulate this\\nfeedforward process according to top-down, task-specific factors\\n(Murray et al., 2016}. Together, these models contribute to a better\\nunderstanding of the underlying neural mechanisms for the devel-\\nopment of hierarchical cortical organization.\\n\\n2.3. The complementary learning systems\\n\\nThe brain learns and memorizes. The former task is charac-\\nterized by the extraction of the statistical structure of the per-\\nceived events with the aim to generalize to novel situations. The\\nlatter, conversely, requires the collection of separated episodic-\\nlike events. Consequently, the brain must comprise a mecha-\\nnism to concurrently generalize across experiences while retaining\\nepisodic memories.\\n\\nSophisticated cognitive functions rely on canonical neural cir-\\ncuits replicated across multiple areas (Douglas, Koch, Mahowald,\\nMartin, & Suarez, 1995). However, although there are shared struc-\\ntural properties, different brain areas operate at multiple timescales\\nand learning rates, thus differing significantly from each other\\nin a functional way (Benna & Fusi, 2016; Fusi, Drew, & Abbott,\\n2005). A prominent example is the complementary contribution\\nof the neocortex and the hippocampus in learning and memory\\nconsolidation (McClelland et al., 1995; O\\'Reilly, 2004; O\\'Reilly &\\nNorman, 2002). The complementary learning systems (CLS) the-\\nory (McClelland et al., 1995} holds that the hippocampal system\\nexhibits short-term adaptation and allows for the rapid learning\\nof novel information which will, in turn, be played back over\\ntime to the neocortical system for its long-term retention (see\\nFig. 1b). More specifically, the hippocampus employs a rapid learn-\\ning rate and encodes sparse representations of events to mini-\\nmize interference. Conversely, the neocortex is characterized by\\na slow learning rate and builds overlapping representations of\\nthe learned knowledge. Therefore, the interplay of hippocampal\\nand neocortical functionality is crucial to concurrently learn reg-\\nularities (statistics of the environment) and specifics (episodic\\nmemories). Both brain areas are known to learn via Hebbian and\\nerror-driven mechanisms (O\\'Reilly & Rudy, 2000). In the neocortex,\\nfeedback signals will yield task-relevant representations while, in\\nthe case of the hippocampus, error-driven modulation can switch\\nits functionally between pattern discrimination and completion for\\nrecalling information (O\\'Reilly, 2004).\\n\\nStudies show that adult neurogenesis contributes to the forma-\\ntion of new memories (Altman, 1963; Cameron, Woolley, McEwen,\\n& Gould, 1993; Eriksson et al., 1998; Gage, 2000}. It has been\\ndebated whether human adults grow significant amounts of new\\nneurons. Recent research has suggested that hippocampal neuro-\\ngenesis drops sharply in children to undetectable levels in adult-\\nhood (Sorrells et al., 20 18). On the other hand, other studies suggest\\nthat hippocampal neurogenesis sustains human-specific cogni-\\ntive function throughout life (Boldrini, Fulmore, Tartt, Simeon, &\\nPavlova, 2018). During neurogenesis, the hippocampus\\x80\\x99 dentate\\ngyrus uses new neural units to quickly assimilate and immediately\\nrecall new information (Altman, 1963; Eriksson et al., 1998). Dur-\\ning initial memory formation, the new neural progenitor cells ex-\\nhibit high levels of plasticity; and as time progresses, the plasticity\\ndecreases to make the new memory more stable (Deng, Aimone,\\n& Gage, 2010}. In addition to neurogenesis, neurophysiological\\n\\x0c58 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\n@) Hebbian and Homeostatic Plasticity\\n\\nControl\\nsignal | r] Observations\\n\\nSynaptic strength\\n\\n| { Plasticity\\n\\nNeural activity\\n\\n}\\n\\nExternal stimuli\\n\\n \\n\\nController\\n\\n \\n\\n \\n\\n \\n\\n \\n\\nSystem\\n\\n \\n\\n \\n\\n \\n\\nb) Complementary Learning Systems (CLS) theory\\n\\n \\n\\n \\n\\n \\n\\nHippocampus Neocortex\\nEpisodic a\\nMemory Generalization\\n\\nStorage,\\nretrieval,\\n\\nFast learning replay Slow learning\\n\\nof arbitrary of structured\\ninformation knowledge\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nFig. 1. Schematic view of two aspects of neurosynaptic adaptation: (a) Hebbian learning with homeostatic plasticity as a compensatory mechanism that uses observations\\nto compute a feedback control signal (Adapted with permission from Zenke, Gerstner et al. (2017}). (b) The complementary learning systems (CLS) theory (McClelland et al.,\\n1995} comprising the hippocampus for the fast learning of episodic information and the neocortex for the slow learning of structured knowledge.\\n\\nstudies evidence the contribution of synaptic rewiring by struc-\\ntural plasticity on memory formation in adults (Knoblauch, 2017;\\nKnoblauch, Krner, Krner, & Sommer, 2014), with a major role of\\nstructural plasticity in increasing information storage efficiency in\\nterms of space and energy demands.\\n\\nWhile the hippocampus is normally associated with the im-\\nmediate recall of recent memories (ie., short-term memories),\\nthe prefrontal cortex (PFC) is usually associated with the preser-\\nvation and recall of remote memories (i.e., long-term memories;\\nBontempi, Laurent-Demir, Destrade, and Jaffard (1999)). Kitamura\\net al. (2017) showed that, when the brain learns something new,\\nthe hippocampus and PFC are both initially encoded with the\\ncorresponding memory; however, the hippocampus is primarily\\nresponsible for the recent recall of new information. Over time,\\nthey showed that the corresponding memory is consolidated over\\nto PFC, which will then take over responsibility for recall of the\\n(now) remote memory. It is believed that the consolidation of\\nrecent memories into long-term storage occurs during rapid eye\\nmovement (REM) sleep (Gais et al., 2007; Taupin & Gage, 2002}.\\n\\nRecently, the CLS theory was updated to incorporate additional\\nfindings from neuroscience (Kumaran et al., 2016). The first set of\\nfindings regards the role of the replaying of memories stored in the\\nhippocampus as a mechanism that, in addition to the integration\\nof new information, also supports the goal-oriented manipula-\\ntion of experience statistics (O\\'Neill, Pleydell-Bouverie, Dupret, &\\nCsicsvari, 2010}. The hippocampus rapidly encodes episodic-like\\nevents that can be reactivated during sleep or unconscious and\\nconscious memory recall (Gelbard-Sagiv, Mukamel, Harel, Malach,\\n& Fried, 2008), thus consolidating information in the neocortex via\\nthe reactivation of encoded experiences in terms of multiple in-\\nternally generated replays (Ratcliff, 1990). Furthermore, evidence\\nsuggests that (i) the hippocampus supports additional forms of\\ngeneralization through the recurrent interaction of episodic mem-\\nories (Kumaran & McClelland, 2012) and (ii) if the new information\\nis consistent with existing knowledge, then its integration into\\nthe neocortex is faster than originally suggested (Tse et al., 2011).\\nOverall, the CLS theory holds the means for effectively generalizing\\nacross experiences while retaining specific memories in a lifelong\\nmanner. However, the exact neural mechanisms remain poorly\\nunderstood.\\n\\n2.4, Learning without forgetting\\n\\nThe neuroscience findings described in Section 2.3 demon-\\nstrate the existence of specialized neurocognitive mechanisms for\\nacquiring and protecting knowledge. Nevertheless, it has been\\nobserved that catastrophic forgetting may occur under specific cir-\\ncumstances. For instance, Mareschal et al. (2007) found an asym-\\nmetric interference effect in a sequential category learning task\\n\\nwith 3- and 4-month-old infants. The infants had to learn two\\ncategories, dog and cat, from a series of pictures and would have\\nto later distinguish a novel animal in a subsequent preferential\\nlooking task. Surprisingly, it was observed that infants were able\\nto retain the category dog only if it was learned before cat. This\\nasymmetric effect is thought to reflect the relative similarity of the\\ntwo categories in terms of perceptual structure.\\n\\nAdditional interference effects were observed for long-term\\nknowledge. Pallier et al. (2003) studied the word recognition abil-\\nities of Korean-born adults whose language environment shifted\\ncompletely from Korean to French after being adopted between\\nthe ages of 3 and 8 by French families. Behavioural tests showed\\nthat these subjects had no residual knowledge of the previously\\nlearned Korean vocabulary. Functional brain imaging data showed\\nthat the response of these subjects while listening to Korean was\\nno different from the response while listening to other foreign\\nlanguages that they had been exposed to, suggesting that their\\nprevious knowledge of Korean was completely overwritten. Inter-\\nestingly, brain activations showed that Korean-born subjects pro-\\nduced weaker responses to French with respect to native French\\nspeakers. It was hypothesized that, while the adopted subjects\\ndid not show strong responses to transient exposures to the Ko-\\nrean vocabulary, prior knowledge of Korean may have had an\\nimpact during the formulation of language skills to facilitate the\\nre-acquisition of the Korean language should the individuals be re-\\nexposed to it in an immersive way.\\n\\nHumans do not typically exhibit strong events of catastrophic\\nforgetting because the kind of experiences we ate exposed to are\\nvery often interleaved (Seidenberg & Zevin, 2006). Nevertheless,\\nforgetting effects may be observed when new experiences are\\nstrongly immersive such as in the case of children drastically\\nshifting from Korean to French. Together, these findings reveal a\\nwell-regulated balance in which, on the one hand, consolidated\\nknowledge must be protected to ensure its long-term durability\\nand avoid catastrophic interference during the learning of novel\\ntasks and skills over long periods of time. On the other hand, under\\ncertain circumstances such as immersive long-term experiences,\\nold knowledge can be overwritten in favour of the acquisition and\\nrefinement of new knowledge.\\n\\nTaken together, the biological aspects of lifelong learning sum-\\nmarized in this section provide insights into how artificial mod-\\nels and agents could prevent catastrophic forgetting and model\\neraceful forgetting. In the next sections, we describe and compare\\nan extensive set of neural network models and AI approaches\\nthat have taken inspiration from such principles. In the case of\\ncomputational systems, however, additional challenges must be\\nfaced due to the limitations of learning in restricted scenarios that\\ntypically capture very few components of the processing richness\\nof biological systems.\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 59\\n\\n3. Lifelong learning and catastrophic forgetting in neural net-\\nworks\\n\\n3.1. Lifelong machine learning\\n\\nLifelong learning represents a long-standing challenge for ma-\\nchine learning and neural network systems (French, 1999; Hass-\\nabis et al., 2017). This is due to the tendency of learning models\\nto catastrophically forget existing knowledge when learning from\\nnovel observations (Thrun & Mitchell, 1995). A lifelong learning\\nsystem is defined as an adaptive algorithm capable of learning\\nfrom a continuous stream of information, with such information\\nbecoming progressively available over time and where the number\\nof tasks to be learned (e.g., membership classes in a classification\\ntask) are not predefined. Critically, the accommodation of new\\ninformation should occur without catastrophic forgetting or inter-\\nference.\\n\\nIn connectionist models, catastrophic forgetting occurs when\\nthe new instances to be learned differ significantly from previ-\\nously observed examples because this causes the new informa-\\ntion to overwrite previously learned knowledge in the shared\\nrepresentational resources in the neural network (French, 1999;\\nMcCloskey & Cohen, 1989). When learning offline, this loss of\\nknowledge can be recovered because the agent sees the same\\npseudo-randomly shuffled examples over and over, but this is not\\npossible when the data cannot be shuffled and is observed as\\na continuous stream. The effects of catastrophic forgetting have\\nbeen widely studied for over two decades, especially in networks\\nlearned using back-propagation (Lewandowsky & Li, 1994; Ratcliff,\\n1990) and in the Hopfield networks (Burgess, Shapiro, & Moore,\\n1991; Nadal, Toulouse, Changeux, & Dehaene, 1986).\\n\\nEarly attempts to mitigate catastrophic forgetting typically con-\\nsisted of memory systems that store previous data and that regu-\\nlarly replay old samples interleaved with samples drawn frorn the\\nnew data (Robins, 1993, 1995}, and these methods are still used\\ntoday (Gepperth & Karaoguz, 2015; Rebuffi, Kolesnikov, Sperl, &\\nLampert, 2016). However, a general drawback of memory-based\\nsystems is that they require explicit storage of old information,\\nleading to large working memory requirements. Furthermore, in\\nthe case of a fixed amount of neural resources, specialized mech-\\nanisms should be designed that protect consolidated knowledge\\nfrom being overwritten by the learning of novel information (e..,\\nKarkpatrick et al. (2017) and Zenke, Poole et al. (2017)). Intuitively,\\ncatastrophic forgetting can be strongly alleviated by allocating ad-\\nditional neural resources whenever they are required (e.g., Hertz,\\nKrogh, and Palmer (1991), Parisi et al. (2017, 2018) and Rusu\\net al. (2016)). This approach, however, may lead to scalability\\nissues with significantly increased computational efforts for neu-\\nral architectures that become very large. Conversely, since in a\\nlifelong learning scenario the number of tasks and samples per\\ntask cannot be known a priori, it is non-trivial to predefine a suf-\\nficient amount of neural resources that will prevent catastrophic\\nforgetting without strong assumptions on the distribution of the\\ninput. In this setting, three key aspects have been identified for\\navoiding catastrophic forgetting in connectionist models (Richard-\\nson & Thomas, 2008}: (i) allocating additional neural resources\\nfor new knowledge; (ii) using non-overlapping representations if\\nresources are fixed: and (iii) interleaving the old knowledge as the\\nnew information is represented.\\n\\nThe brain has evolved mechanisms of neurosynaptic plasticity\\nand complex neurocognitive functions that process continuous\\nstreams of information in response to both short- and long-term\\nchanges in the environment (Lewkowicz, 2014; Murray et al,\\n2016; Power & Schlaggar, 2016; Zenke, Gerstner et al., 2017). Con-\\nsequently, the differences between biological and artificial systems\\ngo beyond architectural differences, and also include the way in\\n\\nwhich these artificial systems are exposed to external stimuli.\\nSince birth, humans are immersed in a highly dynamic world and,\\nin response to this rich perceptual experience, our neurocogni-\\ntive functions progressively develop to make sense of increasingly\\nmore complex events. Infants start with relatively limited capabil-\\nities for processing low-level features and incrementally develop\\ntowards the learning of higher-level perceptual, cognitive, and\\nbehavioural functions. Humans and animals make massive use of\\nthe spatio-temporal relations and increasingly richer high-order\\nassociations of the sensory input to learn and trigger meaningful\\nbehavioural responses. Conversely, artificial systems are typically\\ntrained in batches, exposing the learning algorithm to multiple\\niterations of the same training samples in a (pseudo-)random\\norder, After a fixed number of training epochs, it is expected that\\nthe learning algorithm has tuned its internal representations and\\ncan predict novel samples that follow a similar distribution with\\nrespect to the training dataset. Clearly, this approach can be effec-\\ntive (and this is supported by the state-of-the-art performance of\\ndeep learning architectures for visual classification tasks; see Guo\\net al. (2016) and LeCun et al. (2015) for reviews), but it does not\\nreflect the characteristics of lifelong learning tasks.\\n\\nIn the next sections, we introduce and compare different neural\\nnetwork approaches for lifelong learning that mitigate, to different\\nextents, catastrophic forgetting. Conceptually, these approaches\\ncan be divided into methods that retrain the whole network while\\nregularizing to prevent catastrophic forgetting with previously\\nlearned tasks (Fig. 2a; Section 3.2), methods that selectively train\\nthe network and expand it if necessary to represent new tasks\\n(Fig. 2b, c; Section 3.3}, and methods that model complementary\\nlearning systems for memory consolidation, e.g. by using memory\\nreplay to consolidate internal representations (Section 3.4). Since\\nconsiderably less attention has been given to the rigorous evalu-\\nation of these algorithms in lifelong learning tasks, in Section 3.5\\nwe highlight the importance of using and designing new metrics\\nto measure catastrophic forgetting with large-scale datasets.\\n\\n3.2. Regularization approaches\\n\\nRegularization approaches alleviate catastrophic forgetting by\\nimposing constraints on the update of the neural weights. Such ap-\\nproaches are typically inspired by theoretical neuroscience models\\nsuggesting that consolidated knowledge can be protected from for-\\ngetting through synapses with a cascade of states yielding different\\nlevels of plasticity (Benna & Fusi, 2016; Fusi et al., 2005}. From\\na computational perspective, this is generally modelled via addi-\\ntional regularization terms that penalize changes in the mapping\\nfunction of a neural network.\\n\\nLi and Hoiem (2016) proposed the learning without forgetting\\n(LWF) approach composed of convolutional neural networks (CNN}\\nin which the network with predictions of the previously learned\\ntasks is enforced to be similar to the network with the current\\ntask by using knowledge distillation, i.e., the transferring of knowl-\\nedge from a large, highly regularized model into a smaller model\\n(Hinton, Vinyals, & Dean, 2014). According to the LwF algorithm,\\ngiven a set of shared parameters @, across all tasks, it optimizes\\nthe parameters of the new task @, together with 6, imposing the\\nadditional constraint that the predictions on the samples of the\\nnovel task using @, and the parameters of old tasks 6, do not\\nshift significantly in order to remember @,. Given the training\\ndata on the new task (Xp, Y,), the output of old tasks for the new\\ndata Y,, and randomly initialized new parameters 6,, the updated\\nparameters 62, 0, 67 are given by:\\n\\na, ae, ar _\\x80\\x94 argmin (Ao2o(o, Yo) + Lnewl Yn n)\\nBs, B0 En\\n\\n+R(8,,85.0n)) 3)\\n\\x0c60 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\n \\n\\n \\n\\n\\x80\\x94 x(t1) \\x80\\x94 x(t) -+t\\n\\n\\x80\\x94 x(t1) 4\\n\\na) Retraining with\\nregularization\\n\\nx(t)\\n\\nb) Training with network\\nexpansion\\n\\n>t \\x80\\x94 x(t1) \\x80\\x94 x(t) \\x80\\x94+t\\n\\nC) Selective network\\nretraining and expansion\\n\\nFig. 2. Schematic view of neural network approaches for lifelong learning: (a} retraining while regularizing to prevent catastrophic forgetting with previously learned tasks,\\n(b} unchanged parameters with network extension for representing new tasks, and (c) selective retraining with possible expansion.\\n\\nwhere Lota(Yo, ,) and Lnew(Yns Yn) minimize the difference be-\\ntween the predicted values Y and the ground-truth values Y of\\nthe new and old tasks respectively using 6,, 65,05, Ao is used to\\nbalance new/old tasks, and  is a regularization term to prevent\\noverfitting. However, this approach has the drawbacks of highly\\ndepending on the relevance of the tasks and that the training\\ntime for one task linearly increases with the number of learned\\ntasks. Additionally, while distillation provides a potential solution\\nto multi-task learning, it requires a reservoir of persistent data\\nfor each learned task. Jung, Ju, Jung, and Kim (2018) proposed to\\nregularize the f, distance between the final hidden activations,\\npreserving the previously learned input-output mappings by com-\\nputing additional activations with the parameters of the old tasks.\\nThese approaches, however, are computationally expensive since\\nthey require to compute the old tasks\\x80\\x99 parameters for each novel\\ndata sample. Other approaches opt to either completely prevent\\nthe update of weights trained on old tasks (Razavian, Azizpour,\\nSullivan, & Carlsson, 2014) or to reduce the learning rate in order\\nto prevent significant changes in the network parameters while\\ntraining with new data (Donahue et al., 2014).\\n\\nKirkpatrick et al. (2017) proposed the elastic weight consol-\\nidation (EWC) model in supervised and reinforcement learning\\nscenarios. The approach consists of a quadratic penalty on the\\ndifference between the parameters for the old and the new tasks\\nthat slows down the learning for task-relevant weights coding for\\npreviously learned knowledge. The relevance of the parameter @\\nwith respect to a task\\x80\\x99s training data D is modelled as the posterior\\ndistribution p(@ | D). Assuming a scenario with two independent\\ntasks A with D4 and B with Dz, the log value of the posterior\\nprobability given by the Bayes\\x80\\x99 rule is:\\n\\nlogp(@ | D) = logp(Hz | @) + logp(@ | Da) \\x80\\x94 logp(Pp), (4)\\n\\nwhere the posterior probability logp(@ | Da) embeds all the\\ninformation about the previous task. However, since this term is\\nintractable, EWC approximates it as a Gaussian distribution with\\nmean given by the parameters @7 and a diagonal precision given\\nby the diagonal of the fisher information matrix F. Therefore, the\\nloss function of EWC is given by\\n\\nA\\n(8) = Lal0) + DT SFU \\x80\\x94 850 (5)\\n\\nwhere z is the loss of B, A sets the relevance of the old tasks\\nwith respect to the new one, and ij denotes the indexes of the pa-\\nrameters. Therefore, this approach requires a diagonal weighting\\nover the parameters of the learned tasks which is proportional to\\nthe diagonal of the Fisher information metric, with the synaptic\\nimportance being computed offline and limiting its computational\\napplication to low-dimensional output spaces. Furthermore, ad-\\nditional experiments by Kemker et al. (2018) have shown that,\\nalthough EWC outperforms other methods for permutation tasks,\\nitis not capable of learning new categories incrementally.\\n\\nZenke, Poole et al. (2017) proposed to alleviate catastrophic\\nforgetting by allowing individual synapses to estimate their impor-\\ntance for solving a learned task. Similar to Kirkpatrick et al. (2017),\\nthis approach penalizes changes to the most relevant synapses so\\nthat new tasks can be learned with minimal forgetting. To reduce\\nlarge changes in important parameters 0, when learning a new\\ntask, the authors use a modified cost function * with a surrogate\\nloss which approximates the summed loss functions of all previous\\ntasks 3:\\n\\nCh = La bo Qf \\x80\\x94 &Y, (6)\\n\\nk\\n\\nwhere c is a weighting parameter to balance new and old tasks, 0;\\nare the parameters at the end of the previous task, and <2? is a per-\\nparameter regulation strength. Similar to EWC, this approach pulls\\nback the more influential parameters towards a reference weight\\nwith good performance on previous tasks. In this case, however,\\nsynaptic relevance is computed in an online fashion over the entire\\nlearning trajectory in the parameter space. The two approaches\\nhave shown similar results on the Permuted MNIST benchmark\\n(LeCun, Bottou, Bengio, & Haffner, 1998).\\n\\nMaltoni and Lomonaco (2018) proposed the AR1 model for\\nsingle-incremental-task scenarios which combines architectural\\nand regularization strategies. Regularization approaches tend to\\nprogressively reduce the magnitude of weight changes batch by\\nbatch, with most of the changes occurring in the top layers. In-\\nstead, in AR1 intermediate layers weights are adapted without\\nnegative impact in terms of forgetting. Reported results on CORe50\\n(Lomonaco & Maltoni, 2017) and iCIFAR-100 (Krizhevsky, 2009)\\nshow that AR1 allows the training of deep convolutional models\\nwith less forgetting, outperforming LwF, EWC, and SI.\\n\\nEnsemble methods have been proposed to alleviate\\ncatastrophic forgetting by training multiple classifiers and com-\\nbine them to generate a prediction. Early attempts showed a disad-\\nvantage linked to the intense use of storage memory which scales\\nup with the number of sessions (Dai, Yang, Xue, & Yu, 2007; Polikar,\\nUpda, Upda, & Honavar, 2001}, while more recent approaches\\nrestrict the size of the models through multiple strategies. For\\ninstance, Ren, Wang, Li, and Gao (2017) proposed to adaptively\\nadjust to the changing data distribution by combining sub-models\\nafter a new training phase, learning new tasks without referring to\\nprevious training data. Coop, Mishtal, and Are] (2013) introduced a\\nmulti-layer perceptron (MLP} augmented with a fixed expansion\\nlayer (FEL) which embeds a sparsely encoding hidden layer to\\nmitigate the interference of previously learned representations.\\nEnsembles of FEL networks were used to control levels of plasticity,\\nyielding incremental learning capabilities while requiring minimal\\nstorage memory. Fernando et al. (2017) proposed an ensemble\\nmethod in which a genetic algorithm is used to find the opti-\\nmal path through a neural network of fixed size for replication\\nand mutation. This approach, referred to as PathNet, uses agents\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 61\\n\\nembedded in a neural network to discover which parts of the\\nnetwork can be reused for the learning of new tasks while freezing\\ntask-relevant paths for avoiding catastrophic forgetting. PathNet\\x80\\x99s\\nauthors showed that incrementally learning new tasks sped up\\nthe training of subsequently learned supervised and reinforcement\\nlearning tasks; however, they did not measure performance on the\\noriginal task to determine if catastrophic forgetting occurred. In\\naddition, PathNet requires an independent output layer for each\\nnew task, which prevents it from learning new classes incremen-\\ntally (Kemker et al., 2018).\\n\\nIn summary, regularization approaches provide a way to alle-\\nviate catastrophic forgetting under certain conditions. However,\\nthey comprise additional loss terms for protecting consolidated\\nknowledge which, with a limited amount of neural resources, may\\nlead to a trade-off on the performance of old and novel tasks.\\n\\n3.3. Dynamic architectures\\n\\nThe approaches introduced here change architectural proper-\\nties in response to new information by dynamically accommo-\\ndating novel neural resources, e.g., re-training with an increased\\nnumber of neurons or network layers.\\n\\nFor instance, Rusu et al. (2016) proposed to block any changes\\nto the network trained on previous knowledge and expand the\\narchitecture by allocating novel sub-networks with fixed capacity\\nto be trained with the new information. This approach, referred to\\nas progressive networks, retains a pool of pre-trained models (one\\nfor each learned task 7;,). Given N existing tasks, when a new task\\nis 7y+1 is given, a new neural network is created and the lateral\\nconnections with the existing tasks are learned. To avoid catas-\\ntrophic forgetting, the learned parameters 9\" for existing tasks 7;,\\nare left unchanged while the new parameter set 0+! js learned\\nfor 7y41. Experiments reported good results on a wide variety\\nof reinforcement learning tasks, outperforming common baseline\\napproaches that either pre-train or incrementally fine-tune the\\nmodels by incorporating prior knowledge only at initialization. In-\\ntuitively, this approach prevents catastrophic forgetting but leads\\nthe complexity of the architecture to grow with the number of\\nlearned tasks.\\n\\nZhou, Sohn, and Lee (2012) proposed the incremental training\\nof a denoising autoencoder that adds neurons for samples with\\nhigh loss and subsequently merges these neurons with existing\\nones to prevent redundancy. More specifically, the algorithm is\\ncomposed of two processes for (i) adding new features to minimize\\nthe residual of the objective function and (ii) merging similar\\nfeatures to obtain a compact feature representation and in this\\nway prevent overfitting. This model was shown to outperform non-\\nincremental denoising autoencoders in classification tasks with\\nthe MNIST (LeCun et al., 1998) and the CIFAR- 10 (Krizhevsky, 2009)\\ndatasets. Cortes, Gonzalvo, Kuznetsov, Mohri, and Yang (2016) pro-\\nposed to adapt both the structure of the network and its weights by\\nbalancing the model complexity and empirical risk minimization.\\nIn contrast to enforcing a pre-defined architecture, the algorithm\\nlearns the required model complexity in an adaptive fashion. The\\nauthors reported good results on several binary classification tasks\\nextracted from the CIFAR-10 dataset. In contrast to previously\\nintroduced approaches that do not consider multi-task scenarios,\\nXiao, Zhang, Yang, Peng, and Zhang (2014) proposed a training\\nalgorithm with a network that incrementally grows in capacity and\\nalso in hierarchical fashion. Classes are grouped according to their\\nsimilarity and self-organized into multiple levels, with models\\ninheriting features from existing ones to speed up the learning.\\nIn this case, however, only the topmost layers can grow and the\\nvanilla back-propagation training procedure is inefficient.\\n\\nDraelos et al. (2017) incrementally trained an autoencoder on\\nnew MNIST digits using the reconstruction error to show whether\\n\\nthe older digits were retained. Their neurogenesis deep learning\\n(NDL) model adds new neural units to the autoencoder to facilitate\\nthe addition of new MNIST digits, and it uses intrinsic replay (a gen-\\nerative model used for pseudo-rehearsal) to preserve the weights\\nrequired to retain older information. Yoon, Yang, Lee, and Hwang\\n(2018) took this concept to the supervised learning paradigm and\\nproposed a dynarnically expanding network (DEN) that increases\\nthe number of trainable parameters to incrementally learn new\\ntasks. DEN is trained in an online manner by performing selective\\nretraining which expands the network capacity using group sparse\\nregularization to decide how many neurons to add at each layer.\\n\\nPart and Lemon (2016, 2017) proposed the combination of a\\npre-trained CNN with a self-organizing incremental neural\\nnetwork (SOINN) in order to take advantage of the good rep-\\nresentational power of CNNs and, at the same time, allow the\\nclassification network to grow according to the task requirements\\nin a continuous object recognition scenario. An issue that arises\\nfrom these types of approaches is scalability since the classification\\nnetwork grows with the number of classes that have been learned.\\nAnother problem that was identified through this approach is that\\nby relying on fixed representations, e.g., pre-trained CNNs, the\\ndiscrimination power will be conditioned by the dataset used to\\ntrain the feature extractor. Rebuffi et al. (2016) deal with this\\nproblem by storing example data points that are used along with\\nnew data to dynamically adapt the weights of the feature extractor,\\na technique that is referred to as rehearsal. By combining new and\\nold data, they prevent catastrophic forgetting but at the expense of\\na higher memory footprint.\\n\\nSo far, we have considered approaches designed for (or at least\\nstrictly evaluated on) the classification of static images. However,\\nin more natural learning scenarios, sequential input underlying\\nspatio-temporal relations such as in the case of videos must be\\naccounted for. Parisi et al. (2017) showed that lifelong learning of\\nhuman action sequences can be achieved in terms of prediction-\\ndriven neural dynamics with internal representations emerging\\nin a hierarchy of recurrent self-organizing networks. The self-\\norganizing networks can dynamically allocate neural resources\\nand update connectivity patterns according to competitive Heb-\\nbian learning. Each neuron of the neural map consists of a weight\\nvector w; anda number K of context descriptors cj; with wy, (kj \\x82\\nR\". Asa result, recurrent neurons in the map will encode prototype\\nsequence-selective snapshots of the input. Given a set N of recur-\\nrent neurons, the best-matching unit (BMU) wy, with respect to the\\ninput x(t) \\x82 R\" is computed as:\\n\\nk=1\\n\\nK\\nb= argmin (soe \\x80\\x94wyll? + $2 aelix(t) \\x80\\x94 cal)   @)\\n\\nwhere {ajti\\x80\\x94o.... are constant values that modulate the influence\\nof the current input with respect to previous neural activity and\\nC,(t) \\x82 R\\x80\\x9d is the global context of the network. Each neuron is\\nequipped with a habituation counter h; expressing how frequently\\nit has fired based on a simplified model of how the efficacy of a\\nhabituating synapse reduces over time. The network is initialized\\nwith two neurons and, at each learning iteration, it inserts a new\\nneuron whenever the activity of the network of a habituated neu-\\nron is smaller than a given threshold. The neural update rule is\\ngiven by:\\n\\nAw; = + hj - (x(t) \\x80\\x94 wi), (8)\\n\\nwhere ; is a constant learning rate and h; acts as a modulatory\\nfactor (see Eq. (2)) that decreases the magnitude of learning over\\ntime to protect consolidated knowledge. This approach has shown\\ncompetitive results with batch learning methods on the Weiz-\\nmann (Gorelick, Blank, Shechtman, Irani, & Basri, 2005) and the\\nKTH (Schuldt, Laptev, & Caputo, 2004) action benchmark datasets.\\n\\x0c62 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\nFurthermore, it learns robust action-label mappings also in the\\ncase of occasionally missing or corrupted class labels. Parisi, Ji\\nand Wermter (2018) showed that self-organizing networks with\\nadditive neurogenesis show a better performance than a static\\nnetwork with the same number of neurons, thereby providing\\ninsights into the design of neural architectures in incremental\\nlearning scenarios when the total number of neurons is fixed.\\n\\nSimilar GWR-based approaches have been proposed for the\\nincremental learning of body motion patterns (Elfaramawy, Barros,\\nParisi, & Wermter, 2017; Mici, Parisi, & Wermter, 2017; Parisi,\\nMage, & Wermter, 2016) and human-object interaction (Mici,\\nParisi, & Wermter, 2018}. However, these unsupervised learning\\napproaches do not take into account top-down task-relevant sig-\\nnals that can regulate the stability\\x80\\x94plasticity balance, potentially\\nleading to scalability issues for large-scale datasets. To address this\\nissue, task-relevant modulatory signals were modelled by Parisi\\net al. (2018) which regulate the process of neurogenesis and neural\\nupdate (see Section 3.4}. This model shares a number of conceptual\\nsimilarities with the adaptive resonance theory (ART; see Gross-\\nberg (2012) for a review) in which neurons are iteratively adapted\\nto a non-stationary input distribution in an unsupervised fashion\\nand new neurons can be created in correspondence of dissimilar in-\\nput data. In the ART model, learning occurs through the interaction\\nof top-down and bottom-up processes: top-down expectations\\nact as memory templates (or prototypes) which are compared to\\nbottom-up sensory observations. Similar to the GWR\\'\\x80\\x99s activation\\nthreshold, the ART model uses a vigilance parameter to produce\\nfine-grained or more general memories. Despite its inherent ability\\nto mitigate catastrophic forgetting during incremental learning, an\\nextensive evaluation with recent lifelong learning benchmarks has\\nnot been reported for continual learning tasks. However, it has\\nbeen noted that the results of some variants of the ART model\\ndepend significantly upon the order in which the training data are\\nprocessed.\\n\\nWhile the mechanisms for creating new neurons and connec-\\ntions in the GWR do not resemble biologically plausible mecha-\\nnisms (e.g., Eriksson et al. (1998), Knoblauch (2017) and Ming and\\nSong (2011}), the GWR learning algorithm represents an efficient\\ncorn putational model that incrementally adapts to non-stationary\\ninput. Crucially, the GWR model creates new neurons whenever\\nthey are required and only after the training of existing ones.\\nThe neural update rate decreases as the neurons become more\\nhabituated, which has the effect of preventing that noisy input\\ninterferes with consolidated neural representations. Alternative\\ntheories suggest that an additional function of hippocampal neuro-\\ngenesis is the encoding of time for the formation of temporal asso-\\nciations in memory (Aimone, Wiles, & Gage, 2006, 2009), e.g., in\\nterms of temporal clusters of long-term episodic memories. Al-\\nthough the underlying mechanisms of neurogenesis and structural\\nplasticity remain to be further investigated in biological systems,\\nthese results reinforce that growing neural models with plasticity\\nconstitute effective mitigation of catastrophic forgetting in non-\\nstationary environments.\\n\\n3.4. Complementary learning systems and memory replay\\n\\nThe CLS theory (Kumaran et al., 2016; McClelland et al, 1995)\\nprovides the basis for acomputational framework modelling mem-\\nory consolidation and retrieval in which the complementary tasks\\nof memorization and generalization are mediated by the interplay\\nof the mammalian hippocampus and neocortex (see Section 2.3).\\nImportantly, the interplay of an episodic memory (specific expe-\\nrience) and a semantic memory (general structured knowledge}\\nprovides important insights into the mechanisms of knowledge\\nconsolidation in the absence of sensory input.\\n\\nDual-memory learning systems have taken inspiration, to dif-\\nferent extents, from the CLS theory to address catastrophic forget-\\nting. An early computational example of this concept was proposed\\nby Hinton and Plaut (1987) in which each synaptic connection has\\ntwo weights: a plastic weight with slow change rate which stores\\nlong-term knowledge and a fast-changing weight for temporary\\nknowledge. This dual-weight method reflects the properties of\\ncomplementary learning systems to mitigate catastrophic forget-\\nting during sequential task learning. French (1997) developed a\\npseudo-recurrent dual-memory framework, one for early process-\\ning and the other for long-term storage, that used pseudo-rehearsal\\n(Robins, 1995) to transfer memories between memory centres.\\nIn pseudo-rehearsal, training samples are not explicitly kept in\\nmemory but drawn from a probabilistic model. During the next\\ntwo decades, numerous neural network approaches based on CLS\\nprinciples were used to explain and predict results in different\\nlearning and memory domains (see O\\'Reilly and Norman (2002)\\nfor a review). However, there is no empirical evidence that shows\\nthat these approaches can scale up to a large number of tasks or\\ncurrent image and video benchmark datasets (see Section 3.5).\\n\\nMore recently, Soltoggio (2015} proposed the use of short- and\\nlong-term plasticity for consolidating new information on the basis\\nof a cause-effect hypothesis testing when learning with delayed\\nrewards. In this case, the difference between the short- and long-\\nterm plasticity is not related to the duration of the memory but\\nrather to the confidence of consistency of cause-effect relation-\\nships. This meta-plasticity rule, referred to as hypothesis testing\\nplasticity (HTP), shows that such relationships can be extracted\\nfrom ambiguous information flows, thus towards explaining the\\nlearning in more complex environments (see Section 4).\\n\\nGepperth and Karaoguz(2015} proposed two approaches for in-\\ncremental learning using (1) a modified self-organizing map (SOM)\\nand (ii) a SOM extended with a short-term memory (STM). We\\nrefer to these two approaches as GeppNet and GeppNet+STM\\nrespectively. In the case of the GeppNet, task-relevant feedback\\nfrom a regression layer is used to select whether learning in the\\nself-organizing hidden layer should occur. In the GeppNet+STM\\ncase, the STM is used to store novel knowledge which is occa-\\nsionally played back to the GeppNet layer during sleep phases\\ninterleaved with training phases. This latter approach yielded bet-\\nter performance and faster convergence in incremental learning\\ntasks with the MNIST dataset. However, the STM has a limited\\ncapacity, thus learning new knowledge can overwrite old one. In\\nboth cases, the learning process is divided into two phases: one\\nfor initialization and the other for actual incremental learning.\\nAdditional experiments showed that this approach performs sig-\\nnificantly worse than EWC (rkpatrick et al., 2017) on different\\npermutation tasks (see Section 3.5). Both GeppNet and GeppNet+\\nSTM require storing the entire training dataset during training.\\n\\nInspired by the generative role of the hippocarnpus for the\\nreplay of previously encoded experiences, Shin, Lee, Kim, and Kim\\n(2017) proposed a dual-model architecture consisting of a deep\\ngenerative model and a task solver. In this way, training data from\\npreviously learned tasks can be sampled in terms of generated\\npseudo-data and interleaved with information from the new tasks.\\nThus, it is not necessary to explicitly revise old training samples for\\nexperience replay, reducing the requirements of working memory.\\nThis approach is conceptually similar to previous ones using a\\npseudo-rehearsal method, i.e., interleaving information of a new\\ntask with internally generated samples from previously learned\\ntasks. Robins (1995) showed that interleaving information of new\\nexperiences with internally generated patterns of previous ex-\\nperiences help consolidate existing knowledge without explicitly\\nstoring training samples. Pseudo-rehearsal was also used by Drae-\\nlos et al. (2017) for the incremental training of an autoencoder,\\nusing the output statistics of the encoder to generate input for the\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 63\\n\\ndecoder during the replay. However, similar to most of the above-\\ndescribed approaches, the use of pseudo-rehearsal methods was\\nstrictly evaluated on two datasets of relatively low complexity,\\ne.g. the MNIST and the Street View House Number (SVHN) (Netzer\\net al., 2011). Consequently, the question arises whether this gen-\\nerative approach can scale up to more complex domains.\\n\\nLiders, Schlager, and Risi (2016) proposed an evolvable Neural\\nTuring Machine (ENTM) that enables agents to store long-term\\nmemories by progressively allocating additional external memory\\ncomponents. The optimal structure for a continually learning net-\\nwork is found from an initially minimal configuration by evolving\\nnetwork\\'s topology and weights. The ENTM configurations can per-\\nform one-shot learning of new associations and mitigate the effects\\nof catastrophic forgetting during incremental learning tasks. A set\\nof reported experiments in reinforcement learning tasks showed\\nthat the dynamic nature of the ENTM approach will cause the\\nagents to continually expand its memory over time. This can lead\\nto an unnecessary memory expansion that would slow down the\\nlearning process significantly. A possible solution to address this\\nissue can be the introduction of cost functions for a more efficient\\nmemory allocation and use.\\n\\nLopez-Paz and Ranzato (2017) proposed the Gradient Episodic\\nMemory (GEM) model that yields positive transfer of knowledge to\\nprevious tasks. The main feature of GEM to minimize catastrophic\\nforgetting is an episodic memory used to store a subset of the\\nobserved examples from agiven task. While minimizing the losson\\nthe current task t, GEM treats the losses on the episodic memories\\nof tasks k <  as inequality constraints, avoiding their increase\\nbut allowing their decrease. This method requires considerable\\nmore memory than other regularization approaches such as EWC\\n(cirkpatrick et al., 2017) at training time (with an episodic memory\\nMy for each task k) but can work much better in the single pass\\nsetting.\\n\\nKemker and Kanan (2018) proposed the FearNet model for\\nincremental class learning that is inspired by studies of recall and\\nconsolidation in the mammalian brain during fear conditioning\\n(Kitamura et al., 2017). FearNet uses a hippocampal network ca-\\npable of immediately recalling new examples, a PFC network for\\nlong-term memories, and a third neural network inspired by the\\nbasolateral amygdala for determining whether the system should\\nuse the PFC or hippocampal network for a particular example.\\nFearNet consolidates information from its hippocampal network\\nto its PFC network during sleep phases. FearNet\\x80\\x99s PFC model is a\\ngenerative neural network that creates pseudo-samples that are\\nthen intermixed with recently observed examples stored in its\\nhippocampal network. Kamra, Gupta, and Liu (2018) presented\\na similar dual-memory framework that also uses a variational\\nautoencoder as a generative model for pseudo-rehearsal. Their\\nframework generates a short-term memory module for each new\\ntask; however, prior to consolidation, predictions are made using\\nan oracle (i.e, they know which module contains the associated\\nmemory).\\n\\nParisi et al. (2018) proposed a dual-memory self-organizing ar-\\nchitecture for learning spatiotemporal representations from videos\\nina lifelong fashion. The complementary memories are modelled\\nas recurrent self-organizing neural networks: the episodic memory\\nquickly adapts to incoming novel sensory observations via com-\\npetitive Hebbian Learning, whereas the semantic memory pro-\\ngressively learns compact representations by using task-relevant\\nsignals to regulate intrinsic levels of structural plasticity. For the\\nconsolidation of knowledge in the absence of sensory input, trajec-\\ntories of neural reactivations from the episodic memory are peri-\\nodically replayed to both memories. Reported experiments show\\nthat the described method significantly outperforms previously\\nproposed lifelong learning methods in three different incremental\\nlearning tasks with the CORe50 benchmark dataset (Lomonaco\\nand Maltoni (2017); see Section 3.5). Since the development of\\n\\nthe neural maps is unsupervised, this approach can be used in\\nscenarios where the annotations of training samples are sparse.\\n\\n3.5. Benchmarks and evaluation metrics\\n\\nDespite the large number of proposed methods addressing life-\\nlong learning, there is no established consensus on benchmark\\ndatasets and metrics for their proper evaluation. Typically, a direct\\ncomparison of different methods is hindered by the highly hetero-\\ngeneous and often limited evaluation schemes to assess the over-\\nall performance, levels of catastrophic forgetting, and knowledge\\ntransfer.\\n\\nLopez-Paz and Ranzato (2017) defined training and evaluation\\nprotocols to assess the quality of continual learning models in\\nterms of their accuracy as well as their ability to transfer knowl-\\nedge between tasks. The transfer of knowledge can be forwards\\nor backwards. The former refers to the influence that learning a\\ntask Ja has on the performance of a future task 7g, whereas the\\nlatter refers to the influence of a current task 7g on a previous\\ntask 74. The transfer is positive when learning about 7,4 improves\\nthe performance of another task 7, (forwards or backwards) and\\nnegative otherwise. (See Section 4.3 for an introduction to learning\\nmodels addressing transfer learning.}\\n\\nKemker et al. (2018) suggested a set of guidelines for evaluat-\\ning lifelong learning approaches and performed complementary\\nexperiments that provide a direct quantitative comparison of a\\nnumber of approaches. Such guidelines comprise the use of three\\nbenchmark experiments: (i) data permutation, (ii) incremental class\\nlearning, and (iii) multimodal learning. The data permutation ex-\\nperiment consists in training a model with a dataset along with\\na permuted version of the same dataset, which tests the model\\'s\\nability to incrementally learn new information with similar feature\\nrepresentations. It is then expected that the model prevents catas-\\ntrophic forgetting with the original data during the subsequent\\nlearning of randomly permuted data samples. In the incremental\\nclass learning experiment, the model performance reflects its abil-\\nity to retain previously learned information while incrementally\\nlearning one class at a time. Finally, in the multimodal learning\\nexperiment, the same model is sequentially trained with datasets\\nof different modalities, which tests the model\\'s ability to incremen-\\ntally learn new information with dramatically different feature\\nrepresentations (e.., first learn an image classification dataset and\\nthen learn an audio classification dataset).\\n\\nIn contrast to the datasets typically proposed in the litera-\\nture to evaluate lifelong learning approaches (e.g., MNIST con-\\ntaining 10 digit classes with low-resolution images; Fig. 3a}, the\\nabove-mentioned experimental conditions were conducted us-\\ning the Caltech-UCSD Birds-200 (CUB-200)} dataset composed of\\n200 different bird species (Wah et al. (2011); Fig. 3b) and the\\nAudioSet dataset, which is built from YouTube videos with 10-s\\nsound clips from 632 classes and over 2 million annotations (Gem-\\nmeke et al., 2017). The approaches considered were supervised: a\\nstandard MLP trained online as a baseline, the EWC (drkpatrick\\net al., 2017), the PathNet (Fernando et al., 2017), the GeppNet\\nand GeppNet+STM (Gepperth & Karaoguz, 2015), and the FEL\\n(Coop et al., 2013}. For the data permutation experiment, best\\nresults were obtained by PathNet followed by EWC, suggesting\\nthat models that use the ensembling and regularization mecha-\\nnisms will work best at incrementally learning new tasks/datasets\\nwith similar feature distributions. In contrast, EWC performed\\nbetter than PathNet on the multi-modal experiment because EWC\\ndoes a better job on separating non-redundant (ie., dissimilar}\\ndata. For the incremental learning task, best results were ob-\\ntained with a combination of rehearsal and dual-memory systems\\n(i.e. GeppNet+STM), yielding gradual adaptation and knowledge\\nconsolidation (see Fig. 4). However, since rehearsal requires the\\n\\x0c64 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\n     \\n  \\n\\nMNIST b)\\n\\nHBABe Bn\\nSede Par ALY\\n\\n     \\n\\nCUB-200 c)\\n\\nCORe50\\n\\nFig. 3. Example images from benchmark datasets used for the evaluation of lifelong learning approaches: (a) the MNIST dataset with 10 digit classes (LeCun et al, 1998),\\n(b} the Caltech-UCSD Birds-200 (CUB-200} dataset composed of 200 different bird species (Wah et al., 2011), and (c} the CORe50 containing 50 objects with variations in\\n\\nbackground, illumination, blurring, occlusion, pose, and scale.\\nSource: Adapted with permission from Lomonaco and Maltoni (2017).\\n\\n \\n\\nEWC\\n\\x80\\x94e\\x80\\x94 FEL\\nMLP\\n\\x80\\x94\\x80\\x94 GeppNet\\n_\\x80\\x94 GeppNet\\n+STM\\n\\n \\n\\nOffline\\n60) \\x80\\x947\" Model\\n\\n40)\\n\\nAccuracy (%) for Classes\\nTrained on so Far\\n\\n \\n\\n10\\nNumber of Classes Trained\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n(a) MNIST\\n70 EWC\\n8 \\x80\\x94\\x80\\x94 FEL\\n$--------------- --- 5-5-5 ee. MLP\\non\\n4 5, 0 \\x80\\x94\\x80\\x94 GeppNet\\n& & \\x80\\x94\\x80\\x94 GeppNet\\nO50 +STM\\n& 8 uu, Offline\\nga Model\\nes\\nA\\nss\\n5 i 30\\nBe\\x80\\x9d\\no\\n2 10\\n0\\n100 110 120 130 140 150 160 170 180 190 200\\nNumber of Classes Trained\\n(b) CUB-200\\nEWC\\n\\x80\\x94\\x80\\x94 FEL\\n50 MLP\\n\\x80\\x94\\x80\\x94 GoppNet\\n\\nGeppNet\\n\\x80\\x94\\x80\\x94 +STM\\n\\n \\n\\nOffline\\nModel\\n\\n30.\\n\\ney\\nS\\n\\nAccuracy (%) for Classes\\nTrained on so Far\\nS\\n\\n50 60 70 80 90 100\\nNumber of Classes Trained\\n\\n(c) AudioSet\\n\\nFig. 4. Results of several lifelong learning approaches for the incremental class\\nlearning experiment. The mean-class test accuracy evaluated on the MNIST {a},\\nCUB-200 (b}, and AudioSet (c}is shown for the following approaches: FEL (red), MLP\\n(yellow), GeppNet (green}, GeppNet--STM (blue), EWC (pink), and offline model\\n(dashed line). (For interpretation of the references to colour in this figure legend,\\nthe reader is referred to the web version of this article.)\\n\\nSource: Adapted with permission from Kemker et al.(2013).\\n\\nstorage of raw training examples, pseudo-rehearsal may be a better\\nstrategy for future work.\\n\\nLomonaco and Maltoni (2017) proposed the CORe50, a novel\\ndataset for continuous object recognition that includes 50 classes\\nof objects observed from different perspectives and includes vari-\\nations in background, illumination, blurring, occlusion, pose, and\\nscale (Fig. 3c). With respect to the above-discussed datasets,\\nCOReSO provides samples collected in experimental conditions\\ncloser to what autonomous agents and robots are exposed to in\\nthe real world (see Section 4). Along with the dataset, the authors\\npropose three incremental learning scenarios: (1} new instances (NI)\\nwhere all classes are shown in the first batch while subsequent\\ninstances of known classes become available over time, new classes\\n(NC} where, for each sequential batch, new object classes are\\navailable so that the model must deal with the learning of new\\nclasses without forgetting previously learned ones, and (iii) new\\ninstances and classes (NIC) where both new classes and instances\\nare presented in each training batch. According to the reported\\nresults, EWC (iMirkpatrick et al., 2017) and LwF (Li & Hoiem, 2016}\\nperform significantly worse in NC and NIC than in NI.\\n\\nPerhaps not surprisingly, overall performance generally drops\\nwhen using datasets of higher complexity such as CUB-200 and\\nCOReSO than when tested on the MNIST. Such results indicate\\nthat lifelong learning is a very challenging task and, importantly,\\nthat the performance of most approaches can differ significantly\\naccording to the specific learning strategy. This suggests that while\\nthere is a large number of approaches capable of alleviating catas-\\ntrophic forgetting in highly controlled experimental conditions,\\nlifelong learning has not been tackled for more complex scenar-\\nios. Therefore, additional research efforts are required to develop\\nrobust and flexible approaches subject to more exhaustive, bench-\\nmark evaluation schemes.\\n\\n4. Developmental approaches and autonomous agents\\n4.1. Towards autonomous agents\\n\\nHumans have the extraordinary ability to learn and progres-\\nsively fine-tune their sensorimotor skills in a lifelong manner\\n(Bremner et al., 2012; Calvert et al., 2004; Tani, 2016). Since the\\nmoment of birth, humans are immersed in a highly dynamic cross-\\nmodal environment which provides a wealth of experiences for\\nshaping perception, cognition, and behaviour (Lewkowicz, 2014;\\nMurray et al., 2016). A crucial component of lifelong learning in\\ninfants is their spontaneous capacity of autonomously generating\\ngoals and exploring their environment driven by intrinsic moti-\\nvation (Cangelosi & Schlesinger, 2015; Gopnik, Meltzoff, & Kuhl,\\n1999}. Consequently, the ability of learning new tasks and skills\\nautonomously through intrinsically motivated exploration is one\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 65\\n\\nof the main factors that differentiate biological lifelong learning\\nfrom current continual neural networks models of classification.\\n\\nWhile there has been significant progress in the development\\nof models addressing incremental learning tasks (see Section 3),\\nsuch models are designed to alleviate catastrophic forgetting from\\na set of annotated data samples. Typically, the complexity of the\\ndatasets used for the evaluation of lifelong learning tasks is very\\nlimited and does not reflect the richness and level of uncertainty\\nof the stimuli that artificial agents can be exposed to in the real\\nworld. Furthermore, neural models are often trained with data\\nsamples shown in isolation or presented in a random order. This\\nsignificantly differs from the highly organized manner in which\\nhumans and animals efficiently learn from samples presented ina\\nmeaningful order for the shaping of increasingly complex concepts\\nand skills (Krueger & Dayan, 2009; Skinner, 1958). Therefore, learn-\\ning in alifelong manner goes beyond the incremental accumulation\\nof domain-specific knowledge, enabling to transfer generalized\\nknowledge and skills across multiple tasks and domains (Barnett\\n& Ceci, 2002) and, importantly, benefiting from the interplay of\\nmultisensory information for the development and specialization\\nof complex neurocognitive functions (Lewkowicz, 2014; Murray\\net al., 2016; Tani, 2016}.\\n\\nIntuitively, it is unrealistic to provide an artificial agent with all\\nthe necessary prior knowledge to effectively operate in real-world\\nconditions (Thrun & Mitchell, 1995). Consequently, artificial agents\\nmust exhibit a richer set of learning capabilities enabling them\\nto interact in complex environments with the aim to process and\\nmake sense of continuous streams of (often uncertain) information\\n(Hassabis et al., 2017; Wermter et al., 2005). In the last decade,\\nsignificant advances have been made to embed biological aspects\\nof lifelong learning into neural network models. In this section,\\nwe summarize well-established and emerging neural network ap-\\nproaches driven by interdisciplinary research introducing findings\\nfrom neuroscience, psychology, and cognitive sciences for the de-\\nvelopment of lifelong learning autonomous agents. We focus on\\ndiscussing models of critical developmental stages and curriculum\\nlearning (Section 4.2), transfer learning for the reuse of consoli-\\ndated knowledge during the acquisition of new tasks (Section 4.3),\\nautonomous exploration and choice of goals driven by curiosity\\nand intrinsic motivation (Section 4.4), and the crossmodal aspects\\nof lifelong learning for multisensory systems and embodied agents\\n(Section 4.5). In particular, we discuss on how these components\\n(see Fig. 5) can be used (independently or combined) to improve\\ncurrent approaches addressing lifelong learning.\\n\\n4.2. Developmental and curriculum learning\\n\\nLearning and development interact in a very intricate way\\n(Elman, 1993}. Humans show an exceptional capacity to learn\\nthroughout their lifespan and, with respect to other species, exhibit\\nthe lengthiest developmental process for reaching maturity. There\\nis a limited time window in development in which infants are\\nparticularly sensitive to the effects of their experiences. This period\\nis commonly referred to as the sensitive or critical period of devel-\\nopment (Lenneberg, 1967) in which early experiences are partic-\\nularly influential, sometimes with irreversible effects in behaviour\\n(Senghas, Kita, & Ozyiirek, 2004). During these critical periods, the\\nbrain is particularly plastic (Fig. 5a) and neural networks acquire\\ntheir overarching structure driven by sensorimotor experiences\\n(see Power and Schlaggar (2016) for a survey). Afterwards, plastic-\\nity becomes less prorninent and the system stabilizes, preserving\\na certain degree of plasticity for its subsequent adaptation and\\nreorganization at smaller scales (Hensch et al., 1998; Kiyota, 2017;\\nQuadrato et al., 2014).\\n\\nThe basic mechanisms of critical learning periods have been\\nstudied in connectionist models (Richardson & Thomas, 2008;\\n\\nThomas & Johnson, 2006), in particular with the use of self-\\norganizing learning systems which reduce the levels of functional\\nplasticity through a two-phase training of the topographic neural\\nmap (Kohonen, 1982, 1995; Miikkulainen, 1997). In a first orga-\\nnization phase, the neural map is trained with a high learning\\nrate and large spatial neighbourhood size, allowing the network to\\nreach an initial rough topological organization. In a second tuning\\nphase, the learning rate and the neighbourhood size are iteratively\\nreduced for fine-tuning. Implementations of this kind have been\\nused to develop models of early visual development (Miller, Keller,\\n& Stryker, 1989}, language acquisition (Lambon Ralph & Ehsan,\\n2006; Li, Farkas, & McWhinney, 2004), and recovery from brain\\ninjuries (Marchman, 1993}. Recent studies on critical periods in\\ndeep neural networks showed that the initial rapid learning phase\\nplays a key role in defining the final performance of the networks\\n(Achille, Rovere, & Soatto, 2017). The first few epochs of training\\nare critical for the allocation of resources across different layers\\ndictated by the initial input distribution. After such a critical pe-\\nriod, the initially allocated neural resources can be re-distributed\\nthrough additional learning phases.\\n\\nDevelopmental learning strategies have been experimented\\non with embedded agents to regulate the embodied interaction\\nwith the environment in real time (Cangelosi & Schlesinger, 2015;\\nTani, 2016), In contrast to computational models that are fed\\nwith batches of information, developmental agents acquire an\\nincreasingly complex set of skills based on their sensorimotor\\nexperiences in an autonomous manner. Consequently, staged de-\\nvelopment becomes essential for bootstrapping cognitive skills\\nwith less amount of tutoring experience. However, the use of\\ndevelopmental strategies for artificial learning systems has shown\\nto be a very complex practice. In particular, it is difficult to se-\\nlect a well-defined set of developmental stages that favours the\\noverall learning performance in highly dynamic environments. For\\ninstance, in the predictive coding framework (Adams, Friston, &\\nBastos, 2015; Rao & Ballard, 1999}, the intention towards a goal\\ncan be generated through the prediction of the consequence of\\nan action by means of the error regression with the prediction\\nerror. The use of generative models, which are implicit in predictive\\ncoding, is one component embedded in the framework of active\\ninference (Friston et al., 2015}. Active inference models aim to\\nunderstand how to select the data that best discloses its causes\\nin dynarnic and uncertain environments through the bilateral use\\nof action and perception. Nevertheless, it remains unclear how\\nto systematically define developmental stages on the basis of the\\ninteraction between innate structure, embodiment, and (active)\\ninference.\\n\\nHumans and animals exhibit better learning performance when\\nexamples are organized in a meaningful way, e.g., by making the\\nlearning tasks gradually more difficult (Krueger & Dayan, 2009).\\nFollowing this observation, referred to as curriculum learning, El-\\nman (1993) showed that having a curriculum of progressively\\nharder tasks (Fig. 5a) leads to faster training performance in neural\\nnetwork systems. This has inspired similar approaches in robotics\\n(Sanger, 1994) and more recent machine learning methods study-\\ning the effects of curriculum learning in the performance of learn-\\ning (Bengio, Louradour, Collobert, & Weston, 2009; Graves et al.,\\n2016; Reed & de Freitas, 2015). Experiments on datasets of limited\\ncomplexity (such as MNIST) showed that curriculum learning acts\\nas unsupervised pre-training, leading to improved generalization\\nand faster speed of convergence of the training process towards the\\nglobal minimum. However, the effectiveness of curriculum learn-\\ning is highly sensitive with respect to the modality of progression\\nthrough the tasks. Furthermore, this approach assumes that tasks\\ncan be ordered by a single axis of difficulty. Graves, Bellemare,\\nMenick, Munos, and Kavukcuoglu (2017) proposed to treat the\\ntask selection problem as a stochastic policy over the tasks that\\n\\x0c66 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\na) Developmental & Curriculum Learning\\n\\nTask complexity\\n\\nPlasticity\\n\\n \\n\\nTime\\nc) Curiosity and Intrinsic Motivation\\nEnvironment\\n\\nAgent | External reward\\n\\nStrategy / action selection\\n\\n{ Internal reward\\n\\n( Intrinsic motivation |\\n\\nb) Multi-Task Transfer Learning\\n\\nForward transfer\\n\\n[ _y\\n\\nTask A Task B\\n\\ntd\\n\\nBackward transfer\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nTime\\n\\nd) Crossmodal Learning\\n\\n     \\n\\nIntegration\\n\\nModality A\\n\\nModality B\\n\\nFig.5. Schematic view of the main components for the development of autonomous agents able to learn over long periods of time in complex environments: Developmental\\nand curriculum learning (Section 4.2), transfer learning (Section 4.3), curiosity and intrinsic motivation (Section 4.4}, and crossmodal learning (Section 4.5).\\n\\nmaximizes the learning progress, leading to an improved efficiency\\nin curriculum learning. In this case, itis necessary to introduce ad-\\nditional factors such as intrinsic motivation (Barto, 2013; Oudeyer,\\nKaplan, & Hafner, 2007), where indicators of learning progress are\\nused as reward signals to encourage exploration (see Section 4.4).\\nCurriculum strategies can be seen as a special case of transfer\\nlearning (Weiss et al., 2016), where the knowledge collected during\\nthe initial tasks is used to guide the learning process of more\\nsophisticated ones.\\n\\n4,3. Transfer learning\\n\\nTransfer learning refers to applying previously acquired knowl-\\nedge in one domain to solve a problem ina novel domain (Barnett &\\nCeci, 2002; Holyoak & Thagard, 1997; Pan & Yang, 2010). Forward\\ntransfer refers to the influence that learning a task 74 has on the\\nperformance of a future task 73, whereas backward transfer refers\\nto the influence of a current task 7g on a previous task 74 (Fig. Sb).\\nFor this reason, transfer learning represents a significantly valuable\\nfeature of artificial systems for inferring general laws from (a\\nlimited amount of) particular samples, assuming the simultaneous\\navailability of multiple learning tasks with the aim to improve the\\nperformance at one specific task.\\n\\nTransfer learning has remained an open challenge in machine\\nlearning and autonomous agents (see Weiss et al. (2016} for a\\nsurvey). Specific neural mechanisms in the brain mediating the\\nhigh-level transfer learning are poorly understood, although it\\nhas been argued that the transfer of abstract knowledge may\\nbe achieved through the use of conceptual representations that\\nencode relational information invariant to individuals, objects,\\nor scene elements (Doumas, Hummel, & Sandhofer, 2008). Zero-\\nshot learning (Lampert, Nickisch, & Harmeling, 2009; Palatucci,\\nPomerleau, Hinton, & Mitchell, 2009} and one-shot learning (Fei-\\nFei, Fergus, & Perona, 2003; Vinyals, Blundell, Lillicrap, & Wierstra,\\n2016) aim at performing well on novel tasks but do not prevent\\ncatastrophic forgetting on previously learned tasks. An early at-\\ntempt to realize lifelong learning through transfer learning was\\nproposed by Ring (1997) through the use of a hierarchical neural\\n\\nnetwork that solves increasingly complex reinforcement learning\\ntasks by incrementally adding neural units and encode a wider\\ntemporal context in which actions take place.\\n\\nMore recent deep learning approaches have attempted to tackle\\nlifelong transfer learning in a variety of domains. For instance, Rusu\\net al.(2017) proposed the use of progressive neural networks(Rusu\\net al., 2016) to transfer learned low-level features and high-level\\npolicies from a simulated to a real environment. The task consists\\nof learning pixel-to-action reinforcement learning policies with\\nsparse rewards from raw visual input to a physical robot manip-\\nulator. Tessler, Givony, Zahavy, Mankowitz, and Mannor (2017)\\nintroduced a hierarchical deep reinforcement learning network\\nthat uses an array of skills and skill distillation to reuse and transfer\\nknowledge between tasks. The approach was evaluated by teach-\\ning an agent to solve tasks in the Minecraft video game. However,\\nskill networks need to be pre-trained and cannot be learned along\\nwith the overarching architecture in an end-to-end fashion. Lopez-\\nPaz and Ranzato (2017) proposed the Gradient Episodic Memory\\n(GEM} model that alleviates catastrophic forgetting and performs\\npositive transfer to previously learned tasks. The model learns the\\nsubset of correlations common to a set of distributions or tasks,\\nable to predict target values associated with previous or novel tasks\\nwithout making use of task descriptors. However, similar to an is-\\nsue shared with most of the approaches discussed in Section 3, the\\nGEM model was evaluated on the MNIST and CIFAR100 datasets.\\nTherefore, the question remains whether GEM scales up to more\\nrealistic scenarios.\\n\\n4.4. Curiosity and intrinsic motivation\\n\\nComputational models of intrinsic motivation have taken inspi-\\nration from the way human infants and children choose their goals\\nand progressively acquire skills to define developmental structures\\nin lifelong learning frameworks (Baldassarre and Mirolli (2013);\\nsee Gottlieb, Oudeyer, Lopes, and Baranes (2013) for a review). In-\\nfants seem to select experiences that maximize an intrinsic learn-\\ning reward through an empirical process of exploration (Gopnik\\net al., 1999). From a modelling perspective, it has been proposed\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 G7\\n\\nthat the intrinsically motivated exploration of the environment,\\ne.g, driven by the maximization of the learning progress (Oudeyer\\net al. (2007) and Schmidhuber (1991), see Fig. 5c for a schematic\\nview), can lead to the self-organization of human-like develop-\\nmental structures where the skills being acquired become progres-\\nsively more complex.\\n\\nComputational models of intrinsic motivation can collect data\\nand acquire skills incrementally through the online (self-}\\ngeneration of a learning curriculum (Baranes & Oudeyer, 2013;\\nForestier & Oudeyer, 2016}. This allows the efficient, stochastic\\nselection of tasks to be learned with an active control of the\\ngrowth of the complexity. Recent work in reinforcement learning\\nhas included mechanisms of curiosity and intrinsic motivation\\nto address scenarios where the rewards are sparse or deceptive\\n(Bellemare et al., 2016; Forestier, Mollard, & Oudeyer, 2017; Kulka-\\nri, Narasimhan, Saeedi, & Tenenbaum, 2016; Pathak, Agrawal,\\nEfros, & Darrell, 2017; Tanneberg, Peters, & Rueckert, 2017). In\\na scenario with very sparse extrinsic rewards, curiosity-driven\\nexploration provides intrinsic reward signals that enable the agent\\nto autonomously and progressively learn tasks of increasing com-\\nplexity.\\n\\nPathak et al. (2017) proposed an approach to curiosity-driven\\nexploration where curiosity is modelled as the error in an agent\\x80\\x99s\\nability to predict the consequences of its own actions. This ap-\\nproach has shown to scale up to high-dimensional visual input,\\nusing the knowledge acquired fromm previous experiences for the\\nfaster exploration of unseen scenarios. However, the method relies\\non interaction episodes that convert unexpected interactions into\\nintrinsic rewards, which does not extend to scenarios where inter-\\nactions are rare. In this case, internally generated representations\\nof the previous sparse interactions could be replayed and used\\nto guide exploration (in a similar way to generative systems for\\nmemory replay; see Section 3.4).\\n\\n4,5, Multisensory learning\\n\\nThe ability to integrate multisensory information is a crucial\\nfeature of the brain that yields a coherent, robust, and efficient\\ninteraction with the environment (Ernst & Biilthoff, 2004; Spence,\\n2014; Stein & Meredith, 1993), Information from different sensor\\nmodalities (e.g. vision, audio, proprioception) can be integrated\\ninto multisensory representations or be used to enhance unisen-\\nsory ones (see Fig. 5d).\\n\\nMultisensory processing functions are the result of the interplay\\nof the physical properties of the crossmodal stimuli and prior\\nknowledge and expectations (e.g., in terms of learned associa-\\ntions), scaffolding perception, cognition, and behaviour (see Mur-\\nray et al. (2016) and Stein et al. (2014) for reviews). The process\\nof multisensory learning is dynamic across the lifespan and is\\nsubject to both short- and long-term changes. It consists of the\\ndynamic reweighting of exogenous and endogenous factors that\\ndictate to which extent multiple modalities interact with each\\nother. Low-level stimulus characteristics (e.g., spatial proximity\\nand temporal coincidence) are available before the formation of\\nlearned perceptual representations that bind increasingly complex\\nhigher-level characteristics (e.g., semantic congruency)}. Sophisti-\\ncated perceptual mechanisms of multisensory integration emerge\\nduring development, starting from basic processing capabilities\\nand progressively specializing towards more complex cognitive\\nfunctions on the basis of sensorimotor experience (Lewkowicz,\\n2014; Spence, 2014).\\n\\nFrom a computational perspective, modelling multisensory\\nlearning can be useful for a number of reasons. First, multisensory\\nfunctions aim at yielding robust responses in the case of uncertain\\nand ambiguous sensory input. Models of causal inference have\\nbeen applied to scenarios comprising the exposure to incongruent\\n\\naudio-visual information for solving multisensory conflicts (Parisi,\\nBarros and Fu et al., 2018; Parisi, Barros and Kerze] et al., 2017).\\nSecond, if trained with multisensory information, one modality can\\nbe reconstructed from available information in another modality.\\nMoon, Kim, and Wang (2015) proposed multisensory processing\\nfor an audio-visual recognition task in which knowledge in a\\nsource modality can be transferred to a target modality. Abstract\\nrepresentations obtained from a network encoding the source\\nmodality can be used to fine-tune the network in the target modal-\\nity, thereby relaxing the imbalance of the available data in the tar-\\nget modality. Barros, Parisi, Fu, Liu, and Wermter (2017) proposed\\na deep architecture modelling crossmodal expectation learning.\\nAfter a training phase with multisensory audio-visual information,\\nunisensory network channels can reconstruct the expected output\\nfrom the other modality. Finally, mechanisms of attention are\\nessential in lifelong learning scenarios for processing relevant\\ninformation in complex environments and efficiently triggering\\ngoal-directed behaviour from continuous streams of multisensory\\ninformation (Spence, 2014}. Such mechanisms may be modelled\\nvia the combination of the exogenous properties of crossmodal\\ninput, learned associations and crossmodal correspondences, and\\ninternally generated expectations (Chen & Spence, 2017) with the\\naim of continually shaping perception, cognition, and behaviour in\\nautonomous agents.\\n\\n5. Conclusion\\n\\nLifelong learning represents an utterly interesting but chal-\\nlenging component of artificial systems and autonornous agents\\noperating on real-world data, which is typically non-stationary\\nand temporally correlated. The mammalian brain remains the\\nbest model of lifelong learning, which makes biologically-inspired\\nlearning models a compelling approach. The general notion of\\nstructural plasticity (Section 2.2) is widely used across the ma-\\nchine learning literature and represents a promising solution to\\nlifelong learning in its own right, even when disregarding biolog-\\nical desiderata. Proposed computational solutions for mitigating\\ncatastrophic forgetting and interference have focused on regu-\\nlating intrinsic levels of plasticity to protect acquired knowledge\\n(Section 3.2), dynamically allocating new neurons or network\\nlayers to accommodate novel knowledge (Section 3.3), and us-\\ning complementary learning networks with experience replay for\\nmemory consolidation (Section 3.4). However, despite significant\\nadvances, current models of lifelong learning are still far from\\nproviding the flexibility, robustness, and scalability exhibited by\\nbiological systems. The most popular deep and shallow learning\\nmodels of lifelong learning are restricted to the supervised domain,\\nrelying on large amounts of annotated data collected in controlled\\nenvironments (see Section 3.5). Such a domain-specific training\\nscheme cannot be applied directly to autonomous agents that\\noperate in highly dynamic, unstructured environments.\\n\\nAdditional research efforts are required to combine multiple\\nmethodologies that integrate a variety of factors observed in hu-\\nman learners. Basic mechanisms of critical periods of development\\n(Section 4.2) can be modelled to empirically determine convenient\\n(multilayered) neural network architectures and initial patterns of\\nconnectivity that improve the performance of the model for sub-\\nsequent learning tasks. Methods comprising curriculum and trans-\\nfer learning (Section 4.3) are a fundamental feature for reusing\\npreviously acquired knowledge and skills to solve a problem in\\na novel domain by sharing low- and high-level representations.\\nFor agents learning autonomously, approaches using intrinsic mo-\\ntivation (Section 4.4} are crucial for the self-generation of goals,\\nleading to an empirical process of exploration and the progressive\\n\\x0c68 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\nacquisition of increasingly complex skills. Finally, multisensory\\nintegration (Section 4.5) is a key feature of autonomous agents\\noperating in highly dynamic and noisy environment, leading to\\nrobust learning and behaviour also in situations of uncertainty.\\n\\nAcknowledgements\\n\\nThis research was partially supported by the German Research\\nFoundation (DFG) under project Transregio Crossmodal Learning\\n(TRR 169).\\n\\nThe authors would like to thank Sascha Griffiths, Vincenzo\\nLomonaco, Sebastian Risi, and Jun Tani for valuable feedback and\\nsuggestions.\\n\\nReferences\\n\\nAbbott, L. F., & Nelson, S. B. (2000). Synaptic plasticity: taming the beast. Nature\\nNeuroscience, 3, 1178-1133.\\n\\nAbraham, W. C., & Robins, A.(2005). Memory retention and weight plasticity in ANN\\nsimulations. Trends in Neurosciences, 28(2), 73-78.\\n\\nAchille, A., Rovere, M., & Soatto, S. (2017). Critical Learning Periods in Deep Neural\\nNetworks, arXiv:1711.08856.\\n\\nAdams, R.A., Friston, K_J., & Bastos, A. M. (2015). Active inference, predictive coding\\nand cortical architecture. In M. F. Casanova, & I. Opris (Eds.}, Recent advances on\\nthe modular organization of the cortex. Springer Netherlands.\\n\\nAimone, J. B., Wiles, J., & Gage, F. H. (2006). Potential role for adult neurogenesis in\\nthe encoding of time in new memories. Nature Neuroscience, 9, 723-727.\\n\\nAimone, J. B., Wiles, J, & Gage, F. H. (2009). Computational influence of adult\\nneurogenesis on memory encoding.. Neuron, 61, 187-202.\\n\\nAltman, J. (1963). Autoradiographic investigation of cell proliferation in the brains\\nof rats and cats. The Anatomical Record, 145(4), 573-591.\\n\\nAstrom, K.J., & Murray, R. M. (2010). Feedback systems: An introduction for scientists\\nand engineers. Princeton University Press.\\n\\nBaldassarre, G., & Mirolli, M. (2013). Intrinsically motivated learning in natural and\\nartificial systems. Springer-Verlag, Berlin.\\n\\nBaranes, A., & Oudeyer, P. . (2013). Active learning of inverse models with intrin-\\nsically motivated goal exploration in robots. Robotics and Autonomous Systems,\\n61(1), 49-73.\\n\\nBarnett, S., & Ceci, S$. (2002). When and where do we apply what we learn? a\\ntaxonomy for far transfer. Psychological Bulletin, 128, 612-637.\\n\\nBarros, P., Parisi, G. I., Fu, D., Liu, X., & Wermter, S. (2017). Expectation learning for\\nadaptive crossmodal stimuli association. In FUCog Meeting Proceedings. Zurich,\\nSwitzerland.\\n\\nBarto, A. (2013). Intrinsic motivation and reinforcement learning. In G. Baldassarre,\\n& M. Mirolli(Eds.}, intrinsically motivated learning in natural and artificial systems\\n(pp. 17-47). Springer.\\n\\nBellemare, M., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., & Munos, R.\\n(2016). Unifying count-based exploration and intrinsic motivation. In NIPS\\x80\\x9916.\\nBarcelona, Spain.\\n\\nBengio, Y., Louradour, J., Collobert, R., & Weston, J. (2009). Curriculum learning. In\\nICML\\x80\\x990$ (pp. 41-48). Montreal, Canada.\\n\\nBenna, M. K., & Fusi, S. (2016). Computational principles of synaptic memory\\nconsolidation. Nature Neuroscience, 19(12), 1697-1708.\\n\\nBienenstock, E., Cooper, L., & Munro, P. (1982). Theory for the development of\\nneuron selectivity: orientation specificity and binocular interaction in visual\\ncortex. The Journal of Neuroscience, 2, 32-48.\\n\\nBoldrini, M., Fulmore, C., Tartt, A. Simeon, L. & Pavlova, I. e. a. (2018). Human\\nhippocampal neurogenesis persists throughout aging. Cell Stem Cell, 22(4),\\n589-599.\\n\\nBontempi, B., Laurent-Demir, C., Destrade, C., & Jaffard, R. (1999). Time-dependent\\nreorganization of brain circuitry underlying long-term memory storage. Nature,\\n400, 671-675.\\n\\nBraun, C., Heinz, U., Schweizer, R., Weich, K., Birbaumer, N., & Topka, H. (2001).\\nDynamic organization of the somato-sensory cortex induced by motor activity.\\nBrain, 124, 2259-2267.\\n\\nBremner, A., Lewkowicz, D., & Spence, C. (2012). Muttisensory development. Oxford\\nUniversity Press, Oxford, UK.\\n\\nBurgess, N., Shapiro, J. L, & Moore, M. A. (1991). Neural network models of list\\nlearning. Networks, 2, 399-422.\\n\\nCalvert, G., Spence, C., & Stein, B. (2004). The handbook of multisensory processes.\\nCambridge, MA: The MIT Press.\\n\\nCameron, H. A., Woolley, C. S., McEwen, B. S., & Gould, E. (1993). Differentiation of\\nnewly born neurons and glia in the dentate gyrus of the adult rat. Neuroscience,\\n56(2), 337-344.\\n\\nCangelosi, A., & Schlesinger, M. (2015). Developmental robotics: From babies to robots.\\nMIT Press.\\n\\nChen, Y. C. & Spence, C. (2017). Assessing the role of the unity assumption on\\nmultisensory integration: a review. Frontiers in Psychology, 8(445).\\n\\nCichon,J..& Gan, W.(2015). Branch-specific dendritic Ca(2+) spikes cause persistent\\nsynaptic plasticity. Nature, 520, 180-185.\\n\\nCoop, R., Mishtal, A., & Arel, 1. (2013). Ensemble learning in fixed expansion layer\\nnetworks for mitigating catastrophic forgetting. IEEE Transactions on Neural\\nNetworks & Learning Systems, 24(10), 1623-1634.\\n\\nCortes, C.,Gonzalvo, X., Kuznetsov, V., Mohri, M., & Yang, S. (2016). AdaNet: Adaptive\\nstructural learning of artificial neural networks, arXiv: 1607.01097.\\n\\nDai, W., Yang, Q., Xue, G. R., & Yu, Y. (2007 ). Boosting for transfer learning. In ICML\\x80\\x9917\\n(pp. 193-200}. Sydney, Australia.\\n\\nDavis, G. W. {2006}. Homeostatic control of neural activity: from phenomenology\\nto molecular design. Annual Review of Neuroscience, 29, 307-323.\\n\\nDeng, W., Aimone, J. B., & Gage, F. H. (2010). New neurons and new memories:\\nhow does adult hippocampal neurogenesis affect learning and memory?. Nature\\nReviews Neuroscience, 11(5), 339-350.\\n\\nDitzler, G., Roveri, M., Alippi, C., & Polikar, R. (2015). Learning in nonstationary\\nenvironments: A survey. IEEE Computational Intelligence Magazine, 10(4), 12-25.\\n\\nDonahue, J., Jia, ., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., et al. (2014). Decaf: A\\ndeep convolutional activation feature for generic visual recognition. In ICML\\x80\\x99/4.\\nBeijing, China.\\n\\nDouglas, R. J., Koch, C., Mahowald, M., Martin, K. A, & Suarez, H. H. (1995). Recurrent\\nexcitation in neocortical circuits. Science, 269, 981-985.\\n\\nDoumas, L., Hummel, J., & Sandhofer, C. (2008). A theory of the discovery and\\npredication of relational concepts. Psychological Review, 115, 1-43.\\n\\nDraelos, T.J., Miner, N. E., Lamb, C. C., Vineyard, C. M., Carlson, I. D., James, C. D., et\\nal. (2017). Neurogenesis deep learning. In ]CNN\\x80\\x99I7 (pp. 526-533}. Anchorage,\\nAlaska.\\n\\nElfaramawy, N., Barros, P., Parisi, G. 1, & Wermter, S. (2017). Emotion recognition\\nfrom body expressions with a neural network architecture. In Proceedings of\\nthe international conference on human agent interaction (HAP\\'I7) (pp. 143-149).\\nBielefeld, Germany.\\n\\nElman, J. L. (1993). Learning and development in neural networks: The importance\\nof starting small. Cognition, 48(1), 71-99.\\n\\nEriksson, P. S., Perfilieva, E, Bjork-Eriksson, T., Alborn, A. M., Nordborg, C., Peter-\\nson, D. A, et al. (1998). Neurogenesis in the adult human hippocampus. Nature\\nmedicine, 4(11}, 1313-1317.\\n\\nErnst, M. 0., & Biilthoff, H. (2004}. Merging the senses into a robust percept. Trends\\nin Cognitive Sciences, 8(4}, 162-169.\\n\\nFei-Fei, L., Fergus, R., & Perona, P. (2003). A Bayesian approach to unsupervised one-\\nshot learning of object categories. In ICCV\\x80\\x9903. Nice, France.\\n\\nFernando, C., Banarse, D., Blundell, C., Zwols, Y., Ha, D., Rusu, A. A., et al. (2017).\\nPathnet: Evolution channels gradient descent in super neural networks, arXiv:\\n1701.08734.\\n\\nForestier, S., Mollard, Y., & Oudeyer, P. . (2017). Intrinsically Motivated Goal\\nExploration Processes with Automatic Curriculum Learning, arXiv: 1708.02190.\\n\\nForestier, S. & Oudeyer, P. Y. (2016). Curiosity-driven development of tool use\\nprecursors: a computational model. In Proceedings of the annual conference of\\nthe cognitive science society.\\n\\nFrench, R. M. (1997). Pseudo-recurrent connectionist networks: An approach to the\\nsensitivity-stability dilemma. Connection Science, 9(4), 353-380.\\n\\nFrench, R. M. (1999). CaTastrophic forgetting in connectionist networks. Trends in\\nCognitive Sciences, 3(4), 128-135.\\n\\nFriston, K., Rigoli, F., Ognibene, D., Mathys, D., Fitzgerald, T., & Pezzulo, G. (2015).\\nActive inference and epistemic value. Cognitive neuroscience, 6, 187-214.\\n\\nFritzke, B. (1992). A growing neural gas network learns topologies. In NIPS\\x80\\x9995, vol. 7\\n(pp. 625-632}. Denver, CO.\\n\\nFusi, S., Drew, P.J., & Abbott, L. F. (2005). CaScade models of synaptically stored\\nmemories. Neuron, 45(4), 599-611.\\n\\nGage, F. H. (2006). Mammalian neural stem cells. Science, 287, 1433-1438.\\n\\nGais, S., Albouy, G., Boly, M., Dang-Vu, T. T., Darsaud, A., Desseilles, M., et al. (2007).\\nSleep transforms the cerebral trace of declarative memories. Proceedings of the\\nNational Academy of Sciences, 104(47), 18778-18783.\\n\\nGelbard-Sagiv, H., Mukamel, R., Harel, M., Malach, R., & Fried, I. (2008). Internally\\ngenerated reactivation of single neurons in human hippocampus during free\\nrecall. Science, 322, 96-101.\\n\\nGemmeke, J. F., Ellis, D. P. W., Freedman, D., Jansen, A., Lawrence, W., Moore, R.C., et\\nal. (2017). Audio set: An ontology and human-labeled dataset for audio events.\\nIn ICASSP\\x80\\x9917. New Orleans, LA.\\n\\nGepperth, A., & Karaoguz, C. (2015). A bio-inspired incremental learning architec-\\nture for applied perceptual problems. Cognitive Computation, 8(5), 924-934.\\nGoodfellow, I. J., Mirza, M., Xiao, D., Courville, A. & Bengio, Y. (2013). An empirical\\ninvestigation of catastrophic forgetting in gradient-based neural networks,\\n\\narXiv:1312.6211.\\n\\nGopnik, A., Meltzoff, A. N., & Kuhl, P. K. (1999). The scientist in the crib: Minds, brains,\\nand how children learn. William Morrow & Co.\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 69\\n\\nGorelick, L., Blank, M., Shechtman, E., Irani, M., & Basri, R. (2005). Actions as space-\\ntime shapes. In ICCV\\x80\\x9905 (pp. 1395-1402). Beijing, China.\\n\\nGottlieb, J., Qudeyer, P. Y., Lopes, M., & Baranes, A. (2013). Information seeking,\\ncuriosity and attention: Computational and neural mechanisms. Trends in Cog-\\nnitive Science, 17(11), 585-596.\\n\\nGrant, W. S., Tanner, J., & Itti, L. (2017). Biologically plausible learning in neural\\nnetworks with modulatory feedback. Neural Networks, 88, 32-48.\\n\\nGraves, A. Bellemare, M. G, Menick, J.. Munos, R., & Kavukcuoglu, K. (2017).\\nAutomated curriculum learning for neural networks, arXiv:1704.03003.\\n\\nGraves, A., Wayne, G., Reynolds, M., Harley, T., Danihelka, I, Grabska-Barwinska, A,\\net al. (2016). Hybrid computing using a neural network with dynamic external\\nmemory. Nature, 538, 471-476.\\n\\nGrossberg, S$. (1980). How does a brain build a cognitive code?. Psychology Review,\\n87, 1-51.\\n\\nGrossberg, S. (2012). Adaptive resonance theory: how a brain learns to consciously\\nattend, learn, and recognize a changing world. Neural Networks, 37, 1-41.\\n\\nGuo, Y., Liu, Y., Oerlemans, A. Lao, S., Wu, S., & Lew, M. (2016). Deep learning for\\nvisual understanding: A review. Neurocomputing, 187(8), 27-48.\\n\\nHassabis, D., Kumaran, D., Summerfield, C., & Botvinick, M. (2017). Neuroscience-\\ninspired artificial intelligence. Neuron Review, 95(2)}, 245-258.\\n\\nHasson, U., Yang, E, Vallines, 1, Heeger, D. J. & Rubin, N. (2008). A hierarchy\\nof temporal receptive windows in human cortex. The Journal of Neuroscience,\\n28(10), 2539-2550.\\n\\nHebb, D. (1949). The organization of behavior. John Wiley & Sons.\\n\\nHeeger, D.J. (2017). Theory of cortical function. Proceedings of the National Academy\\nof Sciences of the United States of America, 114(8), 1773-1782.\\n\\nHensch, T. (2004). Critical period regulation. Annual Review of Neuroscience, 27,\\n549-579.\\n\\nHensch, T. K., Fagiolini, M., Mataga, N., Stryker, M. P., Baekkeskov, S., & Kash, $. F.\\n(1998). Local gaba circuit control of experience-dependent plasticity in devel-\\noping visual cortex. Science, 282, 1504-1508.\\n\\nHertz, J., Krogh, A, & Palmer, R. G. (1991). Introduction to the theory of neural\\ncomputation. Redwood City CA: Addison-Wesley.\\n\\nHinton, G. E., & Plaut, D. C. (1987). Using fast weights to deblur old memories. In\\nProceedings of the annual conference of the cognitive science society (pp. 177-186).\\n\\nHinton, G., Vinyals, O., & Dean, J. (2014). Distilling the knowledge in a neural\\nnetwork. In NIPS\\x80\\x9914, workshop on deep learning and representation. Montreal,\\nCanada.\\n\\nHirsch, H., & Spinelli, D. (1970). Visual experience modifies distribution of horizon-\\ntally and vertically oriented receptive fields in cats. Science, 168, 869-871.\\nHolyoak, K., & Thagard, P. (1997). The analogical mind. American Psychologist, 52,\\n\\n35-44.\\n\\nHubel, D. H., & Wiesel, T. H. (1962). Receptive fields, binocular and functional\\narchitecture in the cats visual cortex. Journal Physiology, 160, 106-154.\\n\\nHubel, D.H., & Wiesel, T. H. (1967). Cortical and callosal connections concerned with\\nthe vertical meridian of visual fields in the cat. Journal of Neurophysiology, 30,\\n1561-1573.\\n\\nHubel, D. H., & Wiesel, T. H. (1970). The period of susceptibility to the psychological\\neffects of unilateral eye closure in kittens. Journal Physiology, 206, 419-436.\\nHubel, D.H., Wiesel, T.H., & LeVay, S. (1977). Plasticity of ocular dominance columns\\ninmonkey striate cortex. Philosophical Transactions of the Royal Society of London,\\n\\nSeries B: Biological Sciences, 278, 377-409.\\n\\nJung, H., Ju, J. Jung, M., & Kim, J. (2018). Less-forgetting learning in deep neural\\nnetworks. AAAI\\x80\\x99 18, New Orleans, LA.\\n\\nKamra, N., Gupta, U., & Liu, Y. (2018). Deep Generative Dual Memory Network for\\nContinual Learning, arXiv: 1710.10368.\\n\\nKemker, R, & Kanan, C. (2018). Fearnet: Brain-inspired model for incremental\\nlearning. In ICLR*/8. Vancouver, Canada.\\n\\nKemker, R., McClure, M., Abitino, A. Hayes, T., & Kanan, C. (2018). Measuring\\ncatastrophic forgetting in neural networks. In AAAF\\'78. New Orleans, LA.\\n\\nKirkpatrick, J. Pascanu, R., Rabinowitz, N., Veness, J. Desjardins, G., Rusu, A. A, et\\nal. (2017). Overcoming catastrophic forgetting in neural networks. Proceedings\\nof the National Academy of Sciences, 114(\\x8213), 3521-3526.\\n\\nKitamura, T., Ogawa, S. K., Roy, D. S., Okuyama, T., Morrissey, M. D., Smith, L. M., et\\nal. (2017). Engrams and circuits crucial for systems consolidation of a memory.\\nScience, 356, 73-78.\\n\\nKiyota, T. (2017). Neurogenesis and brain repair (pp. 575-597). Neuroimmune Phar-\\nmacology. Springer.\\n\\nKnoblauch, A. (2017). Impact of structural plasticity on memory formation and\\ndecline. In A. van Ooyen, & M. Butz (Eds.)}, Rewiring the brain: A computational\\napproach to structural plasticity in the adult brain (pp. 361-386). Elsevier, Aca-\\ndemic Press.\\n\\nKnoblauch, A., Korner, E., Krner, U.,& Sommer, F. T. (2014). Structural plasticity has\\nhigh memory capacity and can explain graded amnesia, catastrophic forgetting,\\nand the spacing effect. PLoS ONE, 9:e96485.\\n\\nKohonen, T. (1982}. Self-organized formation of topologically correct feature maps.\\nBiological Cybernetics, 43, 59-69.\\n\\nKohonen, T. (1995). Self- organizing maps. New York: Springer.\\n\\nKrizhevsky, A. (2009). Learning multiple iayers of features from tiny images (Master\\'s\\nthesis), University of Toronto.\\n\\nKrueger, K. A., & Dayan, P. (2009). Flexible shaping: how learning in small steps\\nhelps. Cognition, 110, 380-394.\\n\\nKulkarni, T., Narasimhan, K., Saeedi, A, & Tenenbaum, J. (2016). Hierarchical deep\\nreinforcement learning: integrating temporal abstraction and intrinsic motiva-\\ntion, arXiv:1604.06057.\\n\\nKumaran, D., Hassabis, D., & McClelland, J. L. (2016). What learning systems do\\nintelligent agents need? Complementary learning systems theory updated.\\nTrends in Cognitive Sciences, 20(7}, 512-534.\\n\\nKumaran, D., & McClelland, J. L. (2012). Generalization through the recurrent inter-\\naction of episodic memories: a model of the hippocampal system. Psychological\\nReview, 119, 573-616.\\n\\nLambon Ralph, M., & Ehsan, S. (2006). Age of acquisition effects depend on the\\nmapping between representations and the frequency of occurrence: empirical\\nand computational evidence. Visual Cognition, 13(7-8), 928-948.\\n\\nLampert, C., Nickisch, H., & Harmeling, S. (2009). Learning to detect unseen object\\nclasses by between-class attribute transfer. In CVPR\\'09. Miami Beach, Florida.\\n\\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521, 436-444.\\n\\nLeCun, Y., Bottou, L., Bengio, Y., & Haffner, P.(1998}. Gradient-based learning applied\\nto document recognition. In In Proceedings of the IEFE.\\n\\nLenneberg, E. (1967). Biological foundations of language. New York: Wiley.\\n\\nLewandowsky, S., & Li, S$. (1994). CaTastrophic interference in neural networks:\\nCauses, solutions, and data. In F. N. Dempster, & C. Brainerd (Eds.), New per-\\nspectives on interference and inhibition in cognition. Academic Press, New York.\\n\\nLewkowicz, D. J. (2014). Early experience & multisensory perceptual narrowing.\\nDevelopmental Psychobiology, 56(2), 292-315.\\n\\nLi, P., Farkas, 1, & McWhinney, B. (2004}. Early lexical development in a self-\\norganising neural network. Neural Networks, 17, 1345-1362.\\n\\nLi, Z., & Hoiem, D. (2016). Learning without forgetting (pp. 614-629). ECCV\\'16,\\nAmsterdam, The Netherlands.\\n\\nLomonaco, V., & Maltoni, D. (2017). Core50: A new dataset and benchmark for\\ncontinuous object recognition. In CoRE. Mountain View, CA.\\n\\nLopez-Paz, D., & Ranzato, M. (2017). Gradient episodic memory for continual learn-\\ning. In NIPS\\x80\\x9917. Long Beach, CA.\\n\\nLiiders, B., Schlager, M., & Risi, S. (2016). Continual learning through evolvable\\nneural turing machines. In NIPS\\'16, workshop on continual learning and deep\\nnetworks. Barcelona, Spain.\\n\\nMaltoni, D., & Lamonaco, V. {2018}. Continuous Learning in Single-Incremental-Task\\nScenarios., arXiv: 1806.08568.\\n\\nMarchman, V. A. (1993}. Constraints on plasticity ina connectionist model of english\\npast tense. Journal of Cognitive Neuroscience, 5(2), 215-234.\\n\\nMareschal, D., Johnson, M., Sirios, $., Spratling, M., Thomas, M., & Westermann, G.\\n(2007). Neuroconstructivism: How the brain constructs cognition. Oxford: Oxford\\nUniversity Press.\\n\\nMarsland, S., Shapiro, J., & Nehmzow, U. (2002). A self-organising network that\\ngrows when required. Neural Networks, 15(8-9}, 1041-1658.\\n\\nMartinetz, T., Berkovich, S., & Schulten, K. (1993). Neural-gas network for vector\\nquantization and its application to time-series prediction. JEFE Transactions on\\nNeural Networks, 4(4}, 558-569.\\n\\nMcClelland, J. L, McNaughton, B. L., & O\\'Reilly, RC. (1995). Why there are com-\\nplementary learning systems in the hippocampus and neocortex: Insights from\\nthe successes and failures of connectionist models of learning and memory.\\nPsychological Review, 102, 419-457.\\n\\nMcCloskey, M., & Cohen, N. J. (1989). CaTastrophic interference in connectionist\\nnetworks: The sequential learning problem. The Psychology of Learning & Mo-\\ntivation, 24, 104-169.\\n\\nMermillod, M., Bugaiska, A., & Bonin, P.(2013). The stability-plasticity dilemma: In-\\nvestigating the continuum from Catastrophic forgetting to age-limited learning\\neffects. Frontiers in Psychology, 4(504).\\n\\nMici, L., Parisi, G. I., & Wermiter, S$. (2017). An Incremental Self-Organizing Architec-\\nture for Sensorimotor Learning and Prediction, arXiv:1712.08521.\\n\\nMici, L., Parisi, G. L, & Wermter, S. (2018). A self-organizing neural network archi-\\ntecture for learning human-object interactions. Neurocomputing, 307, 14-24.\\n\\nMiikkulainen, R. (1997). Dyslexic and category-specific aphasic impairments in\\na self-organizing feature map model of the lexicon. Brain & Language, 59,\\n334-366.\\n\\nMiller, K., Keller, J., & Stryker, M. (1989). Occular dominance column development:\\nAnalysis and simulation. Science, 245, 605-615.\\n\\nMiller, K., & MacKay, D. J.(1994). The role of constraints in hebbian learning. Neural\\nComputation, 6, 100-126.\\n\\nMing, G. L., & Song, H. (2011). Adult neurogenesis in the mammalian brain: Signifi-\\ncant answers and significant questions.. Neuron, 70, 687-702.\\n\\nMoon, $., Kim, S$. & Wang, H. (2015). Multimodal transfer deep learning with\\napplications in audio-visual recognition. In NIPS\\x80\\x9915. Montreal, Canada.\\n\\nMurray, M. M., Lewkowicz, D.J., Amedi, A., & Wallace, M. T. (2616). Multisensory\\nprocesses: A balancing act across the lifespan. Trends in Neurosciences, 39,\\n567-579.\\n\\x0c70 GI. Parisi, R. Kemker, .L. Part et al. / Neural Networks 113 (2019) 54-71\\n\\nNadal, J. P., Toulouse, G., Changeux, J. P., & Dehaene, S. (1986). Networks of formal\\nneurons and memory palimpsets. Europhysics Letters, 1, 535-543.\\n\\nNelson, . A. (2000). Neural plasticity and human development: The role of early\\nexperience in sculpting memory systems. Developmental Science, 3(2), 115-136.\\n\\nNetzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., & Ng, A. Y. (2011). Reading digits\\nin natural images with unsupervised feature learning. In NIPS\\x80\\x99T1, Workshop on\\ndeep learning and unsupervised feature learning. Granada, Spain.\\n\\nO\\'Neill, J., Pleydell-Bouverie, B., Dupret, D., & Csicsvari, J. (2010). Play it again:\\nReactivation of waking experience and memory. Trends in Neuroscience, 33,\\n220-229.\\n\\nO\\'Reilly, R. C. (2004). The division of labor berween the neocortex and hippocampus.\\nconnectionist modeling in cognitive (neuro-)science. George Houghton, Ed., Psy-\\nchology Press.\\n\\nO\\'Reilly, R. C., & Norman, K. A.(2002). Hippocampal and neocortical contributions to\\nmemory: Advances in the complementary learning systems framework. Trends\\nin Cagnitive Sciences, 6(12}, 505-510.\\n\\nO\\'Reilly, R. C, & Rudy, J. W. (2000). Computational principles of learning in the\\nneocortex and hippocampus. Hippocampus, 10, 389-397.\\n\\nOudeyer, P. ., Kaplan, F., & Hafner, V. (2007). Intrinsic motivation systems for au-\\ntonomous mental development. IEEE Transactions on Evolutionary Computation,\\n11(2), 265-286.\\n\\nPalatucci,M., Pomerleau, D.A., Hinton, G. E., & Mitchell, T.(2009). Zero-shot learning\\nwith semantic output codes. In NIPS\\x80\\x990S. Vancouver, Canada.\\n\\nPallier, C., Dehaene, S., Poline, J. B., LeBihan, D., Argenti, A. M., Dupoux, E., et al.\\n(2003). Brain imaging of language plasticity in adopted adults: can a second\\nlanguage replace a first?. Cerebral Cortex, 13, 155-161.\\n\\nPan, S. J., & Yang, Q, (2010). A survey on transfer learning. IEEE Transactions on\\nKnowledge and Data Engineering, 22(10), 1345-1359.\\n\\nParisi, G., Barros, P., Fu, D., Mage, S., Wu, H., Liu, X., et al. (2018). A Neurorobotic Ex-\\nperiment for Crossmodal Conflict Resolution in Complex Environments, arXiv:\\n1802.16408.\\n\\nParisi, G.L., Barros, P., Kerzel, M., Wu, H, Yang, G., Li, Z., et al.(2017). A computational\\nmodel of crossmodal processing for conflict resolution. In ICDL-EPIROB\\x80\\x9917 (pp.\\n33-38). Lisbon, Portugal.\\n\\nParisi, G., Ji, X., & Wermter, S. (2018). On the role of neurogenesis in overcoming\\ncatastrophic forgetting.. In NIPS\\x80\\x9918, workshop on continual learning. Montreal,\\nCanada.\\n\\nParisi, G. 1, Magg, S$, & Wermter, $. (2016). Human motion assessment in real\\ntime using recurrent self-organization. In Proceedings of the IEEE international\\nsymposium on robot and hurnan interactive communication (pp. 71-79). New\\nYork, NY.\\n\\nParisi, G. I, Tani, J. Weber, C, & Wermter, S. (2017}. Lifelong learning of hu-\\nmans actions with deep neural network self- organization. Neural Networks, 96,\\n137-149.\\n\\nParisi, G., Tani, J., Weber, C., & Wermter, S. (2018). Lifelong Learning of Spatiotem-\\nporal Representations with Dual-Memory Recurrent Self-Organization, arXiv:\\n1805.16966.\\n\\nPart, J.L., & Lemon, O. (2016). Incremental on-line learning of object classes using a\\ncombination of self-organizing incremental neural networks and deep convolu-\\ntional neural networks. In [ROS\\x80\\x9916, workshop on bio-inspired social robot learning\\nin home scenarios. Daejeon, South Korea.\\n\\nPart, J. L, & Lemon, O. (2017}. Incremental online learning of objects for robots\\noperating in real environments. In ICDI-EPIROB\\x80\\x9917. Lisbon, Portugal.\\n\\nPathak, D., Agrawal, P., Efros, A. A., & Darrell, F. (2017). Curiosity-driven exploration\\nby self-supervised prediction. In JCML\\'17. Sydney, Australia.\\n\\nPolikar, R., Upda, L., Upda, S. S., & Honavar, V. (2001). Learn++: An incremental\\nlearning algorithm for supervised neural networks. JEEE Transactions on Systems,\\nMan, and Cybernetics, Part C (Applications & Reviews), 31(4), 497-508.\\n\\nPower, J. D., & Schlaggar, B. L. (2016). Neural plasticity across the lifespan. Wiley\\nInterdisciplinary Reviews: Developmental Biology, 6(216).\\n\\nQuadrato, G., Elnaggar, M. Y., & Di Giovanni, $. (2014). Adult neurogenesis in brain\\nrepair: Cellular plasticity vs. cellular replacement. Frontiers in Neuroscience,\\n8(17).\\n\\nRao, R. P. N., & Ballard, D. H. (1999). Predictive coding in the visual cortex: A\\nfunctional interpretation of some extra-classical receptive-field effects. Nature\\nNeuroscience, 2(1}, 79-87.\\n\\nRatcliff, R. (1990). Connectionist models of recognition memory: Constraints\\nimposed by learning and forgetting functions. Psychological Review, 97(2),\\n285-308.\\n\\nRazavian, A. S., Azizpour, H., Sullivan, J., & Carlsson, S. (2014). CNN features off-the-\\nshelf: An astounding baseline for recognition (pp. 806-8 13). CVPR\\'14, Columbus,\\nOH.\\n\\nRebuffi, S. A., Kolesnikov, A. Sperl, G., & Lampert, C. H. (2016). iCaRL: Incremental\\nClassifier and Representation Learning, arXiv: 1611.07725.\\n\\nReed, S., & de Freitas, N. (2015 }. Neural programmer interpreters, arXiv: 1511.06279.\\n\\nRen, B., Wang, H., Li, J., & Gao, H. (2017). Life-long learning based on dynamic\\ncombination model. Applied Soft Computing, 56, 398-404.\\n\\nRichardson, F. M., & Thomas, M. S$. C. (2008). Critical periods and catastrophic\\ninterference effects in the development of self-organising feature maps. Devel-\\nopmental Science, 113}, 371-389.\\n\\nRing, M. B. (1997). Child: A first step towards continual learning. Machine Learning,\\n28, 77-104.\\n\\nRobins, A. V. (1993}. CaTastrophic forgetting in neural networks: The role of re-\\nhearsal mechanisms. In Proceedings of the first new zealand international two-\\nstream conference on artificial neural networks and expert systems. IEEE Computer\\nSociety Press.\\n\\nRobins, A. V. (1995). CaTastrophic forgetting, rehearsal and pseudorehearsal. Con-\\nnection Science, 7(2), 123-146.\\n\\nRusu, A. A, Rabinowitz, N. C., Desjardins, G., Soyer, H., Kirkpatrick, J.,\\nKavukcuoglu, K., et al. (2016). Progressive Neural Networks, arXiv: 1606_04671.\\n\\nRusu, A. A., Vecerik, M., Rothdrl, T., Heess, N., Pascanu, R., & Hadsell, R. (2017). Sim-\\nto-real robot learning from pixels with progressive nets. In CoRL\\x80\\x99?7. Mountain\\nView, CA.\\n\\nSanger, T. D. (1994). Neural network learning control of robot manipulators using\\ngradually increasing task difficulty. IEEE Transactions on Robotics and Automa-\\ntion, 10.\\n\\nSchmidhuber, J. (1991). Curious model-building control systems.\\n\\nSchuldt, C., Laptey, L, & Caputo, B. (2004). Recognizing human actions: A local SVM\\napproach. In ICPR\\x80\\x9904 (pp. 32-36). Cambridge, UK.\\n\\nSeidenberg, M., & Zevin, J.(2006). Connectionist models in developmental cognitive\\nneuroscience: Critical periods and the paradox of success. In Y. Munakata, &\\nM. H. Johnson (Eds.), Processes of change in brain and cognitive development:\\nAttention and Performance XX] (pp. 315-347). Oxford: Oxford University Press.\\n\\nSenghas, A., Kita, S$. & Ozytirek, A. (2004). Children creating core properties of\\nlanguage: Evidence from an emerging sign language in nicaragua. Science, 305,\\n1779-1782.\\n\\nShatz, C. J. (1996). Emergence of order in visual system development. Proceedings of\\nthe National Academy of Sciences, 93, 602-608.\\n\\nShin, H., Lee, J. K., Kirn, J., & Kirn, J. (2017}. Continual learning with deep generative\\nreplay. In NIPS\\x80\\x99T7. Long Beach, CA.\\n\\nSkinner, B. F. (1958). Reinforcement today. American Psychologist, 13, 94-99.\\n\\nSoltoggio, A. (2015). Short-term plasticity as cause-effect hypothesis testing is distal\\nreward learning. Biological Cybernetics, 109, 75-94.\\n\\nSoltoggio, A., Stanley, K. O., & Risi, S.(2017}. Born to learn: the inspiration, progress,\\nand future of evolved plastic artificial neural networks, arXiv:1703.10371.\\nSong, S., Miller, K. D., & Abbott, L. F. (2000). Competitive hebbian learning through\\n\\nspike-timing-dependent synaptic plasticity. Nature Neuroscience, 3, 919-926.\\n\\nSorrells, S. F., Paredes, M. F., Arantxa, C. S., Sandoval, I, Dashi, Q., Kelley, K. W.,\\net al. (2018). Human hippocampal neurogenesis drops sharply in children to\\nundetectable levels in adults. Nature, 555, 377-381.\\n\\nSpence, C. (2010}. Crossmodal spatial attention. Annals of the New York Academy of\\nSciences, 1191, 182-200.\\n\\nSpence, C. (2014). Orienting attention: A crossmodal perspective. In The Oxford\\nhandbook of attention (pp. 446-471). Oxford, UK: Oxford University Press.\\n\\nStein, B. E, & Meredith, M. A. (1993). The merging of the senses. The MIT Press,\\nCambridge, MA, US.\\n\\nStein, B. E., Stanford, T. R, & Rowland, B. A. (2014). Development of multisensory\\nintegration from the perspective of the individual neuron. Nature Reviews\\nNeuroscience, 15(8), 520-535.\\n\\nSur, M., & Leamey, C. A. (2001). Development and plasticity of cortical areas and\\nnetworks. Nature Reviews Neuroscience, 2, 251-262.\\n\\nTani, J. (2016}. Exploring rebetic minds: Actions, Symbols, and consciousness a self-\\norganizing dynamic phenomena. Oxford University Press.\\n\\nTanneberg, D., Peters, J.,& Rueckert, E.(2017). Online learning with stochastic recur-\\nrent neural networks using intrinsic motivation signals. In CoRL\\x80\\x991?7. Mountain\\nView, CA.\\n\\nTaupin, P., & Gage, F. H. (2002). Adult neurogenesis and neural stem cells of the\\ncentral nervous system in mammals. Journal of Neuroscience Research, 69(6),\\n745-749.\\n\\nTaylor, P., Hobbs, J. N., Burroni, J.. & Siegelmann, H. T. (2015). The global landscape\\nof cognition: hierarchical aggregation as an organizational principle of human\\ncortical networks and functions. Scientific Reports, 5(18112).\\n\\nTessler, C., Givony, S., Zahavy, T., Mankowitz, D. J. & Mannor, S. (2017). A deep\\nhierarchical approach to lifelong learning in minecraft. In AAAI\\x80\\x99I7. San Francisco,\\nCA.\\n\\nThomas, M., & Johnson, M. (2006). The computational modelling of sensitive peri-\\nods. Developmental Psychobiology, 48(4}, 337-344.\\n\\nThrun, S., & Mitchell, T. (1995). Lifelong robot learning. Robotics and Autonomous\\nSystems, 15, 25-46.\\n\\nTse, D., Takeuchi, T., Kakeyama, M., Kajii, ., Okuno, H., Tohyama, C., et al. (2011).\\nSchema-dependent gene activation and memory encoding in neocortex. Sci-\\nence, 333, 891-895.\\n\\nTurrigiano, G. (2011). Too many cooks? Intrinsic and synaptic homeostatic mecha-\\nnisms in cortical circuit refinement. Annual Review of Neuroscience, 34, 89-103.\\n\\x0cGI Parisi, R. Kemker, J.L. Part et al. / Neural Networks 113 (2019) 54-71 71\\n\\nUylings, H. (2006). Development of the human cortex and the concept of critical or\\nsensitive periods. Language Learning, 56, 59-90.\\n\\nVinyals, O., Blundell, C., Lillicrap, T., & Wierstra, D. (2016). Matching networks for\\none shot learning. In NIPS\\x80\\x9916. Barcelona, Spain.\\n\\nWah, C., Branson, S., Welinder, P., Perona, P., & Belongie, S. (2011}. CaLtech-UCSD\\nbirds-200-2011 dataset. In Tech Report: CNS-TR-2011-007.\\n\\nWeiss, K, Khoshgoftaar, T. M., & Wang, D. D. (2016). A survey of transfer learning.\\nJournal of Big Data, 3(9}.\\n\\nWermiter, S., Palm, G., & Elshaw, M. (2005). Biomimetic neural learning for intelligent\\nrobots. Intelligent Systems, Cognitive Robotics, and Neuroscience. Springer,\\nBerlin, Heidelberg.\\n\\nWillshaw, D_J., & von der Malsburg, C. (1976). How patterned neural connections\\ncan be set up by self-organization. Proceedings of the Royal Society of London B:\\nBiological Sciences, 194(1117), 431-445.\\n\\nXiao, T., Zhang, J., Yang, K., Peng, Y., & Zhang, Z. (2014). Error-driven incremental\\nlearning in deep convolutional neural network for large-scale image classifica-\\ntion. In Proceedings of the ACM International Conference on Multimedia, Orlando,\\nFL (pp. 177-186).\\n\\nYoon, J., Yang, E., Lee, J., & Hwang, S. J. (2018). Lifelong learning with dynamically\\nexpandable networks. In [CLR\\x80\\x9918. Vancouver, Canada.\\n\\nZenke, F., Gerstner, W., & Ganguli, $. (2017). The temporal paradox of hebbian\\nlearning and homeostatic plasticity. Neurobiology, 43, 166-176.\\n\\nZenke, F., Poole, B., & Ganguli, S. (2017). Continual learning through synaptic intelli-\\ngence. ICML\\'17, Sydney, Australia.\\n\\nZhou, G., Sohn, K, & Lee, H. (2012). Online incremental feature learning with\\ndenoising autoencoders. In International conference on artificial intelligence and\\nstatistics (pp. 1453-1461}.\\n\\x0c'] ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "term = input(\"search: \")\n",
    "rank(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-62-5829a3e76f29>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-62-5829a3e76f29>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "term = input(\"search: \")\n",
    "try:\n",
    "    result = rank(term)\n",
    "    result\n",
    "    feedback = input(\"were these articles helpful?, (Y/N): \")\n",
    "    if feedback == \"Y\":\n",
    "        np.save('correct_search.npy', worddic) \n",
    "    elif feedback == \"exit\":\n",
    "    else:\n",
    "        print(\"sorry it was not helpful, try again\")\n",
    "except:\n",
    "    print(\"no results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
